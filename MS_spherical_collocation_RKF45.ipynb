{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phmouras/Projeto_Pos/blob/main/MS_spherical_collocation_RKF45.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "uwHk8h0y8ZBF",
        "outputId": "4d306986-9097-4417-e1ec-6072747f882b",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "N = 60                                                  # Truncation ordem\n",
        "\n",
        "L0 = 2                                               # Map parameter \n",
        "\n",
        "col = np.cos(np.arange(2*N + 4)*math.pi /(2*N + 3))      # collocation points (Verificado)\n",
        "\n",
        "colr = col[1:N+2]\n",
        "\n",
        "r = L0 * colr/(np.sqrt(1-colr**2))                       # physical domain (Verificado)             \n",
        "\n",
        "#out_r = open('r_30_L02.txt', 'a')\n",
        "#out_r.write(' ' +' '.join(str('%.18f'%n) for n in r)+'\\n')\n",
        "#out_r.close()\n",
        "\n",
        "\n",
        "# Base Matrix (Tchebyshev Polinomials): \n",
        "\n",
        "SB = np.zeros([N+2,N+1])\n",
        "rSB = np.zeros([N+2,N+1])\n",
        "rrSB = np.zeros([N+2,N+1])\n",
        "\n",
        "\n",
        "for i in range(N+1+1):\n",
        "  SB[i,] = np.sin((2*i+1)*np.arctan(L0/r))                                                  \n",
        "\n",
        "for i in range(N+1+1):\n",
        "  rSB[i,] = -np.cos((2*i+1)*np.arctan(L0/r))*(2*i+1)*L0/(r**2*(1+L0**2/r**2)) \n",
        "\n",
        "for i in range(N+1+1):\n",
        "  rrSB[i,] = -np.sin((2*i+1)*np.arctan(L0/r))*(2*i+1)**2*L0**2/(r**4*(1+L0**2/r**2)**2)+2*np.cos((2*i+1)*np.arctan(L0/r))*(2*i+1)*L0/(r**3*(1+L0**2/r**2))-2*np.cos((2*i+1)*np.arctan(L0/r))*(2*i+1)*L0**3/(r**5*(1+L0**2/r**2)**2)                     \n",
        "\n",
        "\n",
        "psi = SB[0:N+1,:]        # Base function\n",
        "rpsi = rSB[0:N+1,:]\n",
        "rrpsi = rrSB[0:N+1,:]\n",
        "\n",
        "# Initial conditions of Phi                                     \n",
        "\n",
        "r0 = 2\n",
        "\n",
        "A0 = 0.05\n",
        "\n",
        "sigma = 1\n",
        "\n",
        "Phi_0 = A0*r**2*(np.exp(-(r-r0)**2/sigma**2)+np.exp(-(r+r0)**2/sigma**2))            # Phi initial data (Verificado)\n",
        "\n",
        "inv_psi = np.linalg.inv(psi)\n",
        "  \n",
        "a0 = np.dot(Phi_0, inv_psi)  # coeficients a(0)  (Verificado)\n",
        "\n",
        "#out_a0 = open('a0_30_L02.txt', 'a')\n",
        "#out_a0.write(' ' +' '.join(str('%.18f'%n) for n in a0)+'\\n')\n",
        "#out_a0.close()\n",
        "\n",
        "\n",
        "Phi = np.dot(a0, psi)        # approximative solution in t = 0\n",
        "rPhi= np.dot(a0, rpsi)\n",
        "\n",
        "########################### Plot: Initial Conditions ph Phi\n",
        "\n",
        "M = 3000       # plot truncation\n",
        "\n",
        "rplot = np.linspace(0.000001,10,M)\n",
        "\n",
        "colplot = rplot/np.sqrt(L0**2 + rplot**2)\n",
        "\n",
        "SBplot = np.zeros([N+1,M])\n",
        "rSBplot = np.zeros([N+1,M])\n",
        "rrSBplot = np.zeros([N+1,M])\n",
        "\n",
        "for i in range(N+1):\n",
        "  SBplot[i,] = np.sin((2*i+1)*np.arctan(L0/rplot))\n",
        "\n",
        "for i in range(N+1):\n",
        "  rSBplot[i,] = -np.cos((2*i+1)*np.arctan(L0/rplot))*(2*i+1)*L0/(rplot**2*(1+L0**2/rplot**2)) \n",
        "\n",
        "for i in range(N+1):\n",
        "  rrSBplot[i,] = -np.sin((2*i+1)*np.arctan(L0/rplot))*(2*i+1)**2*L0**2/(rplot**4*(1+L0**2/rplot**2)**2)+2*np.cos((2*i+1)*np.arctan(L0/rplot))*(2*i+1)*L0/(rplot**3*(1+L0**2/rplot**2))-2*np.cos((2*i+1)*np.arctan(L0/rplot))*(2*i+1)*L0**3/(rplot**5*(1+L0**2/rplot**2)**2)                     \n",
        "\n",
        "psiplot = SBplot[0:(N+1),:] \n",
        "rpsiplot = rSBplot[0:(N+1),:]\n",
        "rrpsiplot = rrSBplot[0:(N+1),:]\n",
        "\n",
        "Phi_plot0 = A0*rplot**2*(np.exp(-(rplot-r0)**2/sigma**2)+np.exp(-(rplot+r0)**2/sigma**2))      \n",
        "\n",
        "\n",
        "Phiplot = np.dot(a0, psiplot)\n",
        "\n",
        "\n",
        "erro = Phi_plot0 - Phiplot\n",
        "\n",
        "plt.plot(rplot, Phiplot, rplot, Phi_plot0, \"--r\")   #(Verificado)\n",
        "plt.xlabel('r')\n",
        "plt.xlim(0,8)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "RMLSnl3l2lkH",
        "outputId": "abbfb2a4-f0a5-4978-9ce8-13d8240428e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEGCAYAAABVSfMhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXzcV3Xw/8+Z0b7vu2RJXuIlexRnD5AE4wAPpjxAk5JiKCEPJVCW9tWH5fWDQksfoC0pUJamIZAAJaSBEgOB4MRJCmTzksSOd9myte/7vsz5/THfUWR5ZI2kWb6Sz/v10ksz3/l+Z+4k1py59557rqgqxhhjTLR4Yt0AY4wx5xcLPMYYY6LKAo8xxpiossBjjDEmqizwGGOMiaq4WDfAjfLy8rSysjLWzTDGmGVl7969naqaP995FniCqKysZM+ePbFuhjHGLCsicjqU82yozRhjTFRZ4DHGGBNVFniMMcZElQUeY4wxUWWBxxhjTFRZ4DHGGBNVFniMMcZElQUec15QVXYeauO+35+kpW8k1s0x5rxmC0jNeeEfHzvMf/y+DoBvP32C//rQNazOT4txq4w5P1mPx6x4fzjeyX/8vo47rq7gNx+7AVXlEz99GZ/PNkE0JhZcFXhEZKuIHBWRWhH5VJDHE0Xkp87jL4hI5YzHPu0cPyoib5px/BMiclBEXhWRn4hIUnTejXEDVeWrjx+hLDuZ/++tG9lQnMHn/tdG9jf28fjB1lg3z5jzkmsCj4h4gW8BtwIbgdtFZOOs0z4A9KjqGuAe4CvOtRuB24BNwFbg2yLiFZFS4K+AGlW9EPA655nzxIGmPvY39vF/bqwmMc4LwNsuKaUqL5X7/lAX49YZc35yTeABNgO1qnpSVceBh4Bts87ZBjzg3H4EuFlExDn+kKqOqWodUOs8H/jnsZJFJA5IAZoj/D6Mi/x0dwNJ8R62XVY6fczrEW67spy9p3s40TEYw9YZc35yU+ApBRpm3G90jgU9R1UngT4gd65rVbUJ+GegHmgB+lT1d8FeXETuEpE9IrKno6MjDG/HxJrPp/zuUBs3bygkIyn+jMf+5LJSPAKPvtQUo9YZc/5yU+AJOxHJxt8bqgJKgFQRuSPYuap6r6rWqGpNfv6820mYZeDV5j46Bsa4ZUPBWY8VZCRRsyqHJw63x6Blxpzf3BR4moDyGffLnGNBz3GGzjKBrnNcewtQp6odqjoB/By4NiKtN67z5OF2PAKvW3d24AG4aUMBh1r6ae61dT3GRJObAs9uYK2IVIlIAv4kgB2zztkBbHduvxPYparqHL/NyXqrAtYCL+IfYrtaRFKcuaCbgcNReC/GBf5Y28nFZVnkpCYEfTzQE9p1xHo9xkSTawKPM2fzEeBx/MHhYVU9KCJfFJG3Oad9D8gVkVrgk8CnnGsPAg8Dh4DfAner6pSqvoA/CWEfcAD/+703im/LxMjoxBT7G/vYXJUz5zmr89Mozkzi+ZNdUWyZMcZVlQtU9THgsVnHPjfj9ijwrjmu/RLwpSDHPw98PrwtNW73alMf41M+alZlz3mOiLC5KofnTnShqvg7xcaYSHNNj8eYcNp9qgeAK84ReAA2V+XQPjDG6a7haDTLGIMFHrNC7T3dTXV+Krlpiec87ypnKO7Fuu5oNMsYgwUes0Ltb+zj0vKsec9bnZ9GTmoCu09Z4DEmWizwmBWnY2CM9oExNpVkznuuiHBxWSYHmvqi0DJjDFjgMSvQoZZ+ADYWZ4R0/sWlmRxrG2BkfCqSzTLGOCzwmBXnUPPCAs9FZVn49LWAZYyJLAs8ZsU51NJPaVYymSnx858MXFTqH5I70NgbyWYZYxwWeMyKc7C5j00lofV2AAozEslPT2S/zfMYExUWeMyKMjI+RV3nEBtCHGYDJ8GgNJMDjRZ4jIkGCzxmRTnZOYgqXFCUvqDrNhRnUNc5xNikJRgYE2kWeMyKcqJjCPCvz1mIdUXpTPqUk871xpjIscBjVpQT7YN4BFblpizouvVOD+lo60AkmmWMmcECj1lRTnQMUp6TQlK8d0HXVeWlEu8VjrZZ4DEm0izwmBXlRMfQgofZAOK9Hlbnp1mPx5gosMBjVowpn3KyY5DV+amLun5dYboFHmOiwAKPWTGae0cYm/QtqscD/ky4pt4RBkYnwtwyY8xMrgo8IrJVRI6KSK2IfCrI44ki8lPn8RdEpHLGY592jh8VkTfNOJ4lIo+IyBEROSwi10Tn3Zhoq+0YBGB1wSIDT6E/weBY22DY2mSMOZtrAo+IeIFvAbcCG4HbRWTjrNM+APSo6hrgHuArzrUbgduATcBW4NvO8wF8Hfitqq4HLsG/rbZZgQKp0NV5ixtqW+MErBMdFniMiSTXBB5gM1CrqidVdRx4CNg265xtwAPO7UeAm8W/X/E24CFVHVPVOqAW2CwimcCNwPcAVHVcVa0g1wpV3zVEemIcOakJi7q+LDuZeK/YWh5jIsxNgacUaJhxv9E5FvQcVZ0E+oDcc1xbBXQA3xeRl0TkPhEJ+nVYRO4SkT0isqejoyMc78dEWX33MOU5Kfi/iyxcnNfDqtxUTlqPx5iIclPgiYQ44HLgO6p6GTAEnDV3BKCq96pqjarW5OfnR7ONJkzqu4cXvHB0tuq8VBtqMybC3BR4moDyGffLnGNBzxGROCAT6DrHtY1Ao6q+4Bx/BH8gMiuMz6c09IxQkbO0wLO6II367mEmp3xhapkxZjY3BZ7dwFoRqRKRBPzJAjtmnbMD2O7cfiewS1XVOX6bk/VWBawFXlTVVqBBRC5wrrkZOBTpN2Kir31gjPFJH+VLDDzVealMTPmDmDEmMuJi3YAAVZ0UkY8AjwNe4H5VPSgiXwT2qOoO/EkCPxSRWqAbf3DCOe9h/EFlErhbVQNlhj8K/NgJZieB90f1jZmoON3lTwhYao+n2lkDdLJjkKpFZscZY87NNYEHQFUfAx6bdexzM26PAu+a49ovAV8KcvxloCa8LTVuU989DCw98ASqHpzsGOLmDUtuljEmCDcNtRmzaA3dw3gESrKSl/Q8WSkJ5KQmWIKBMRFkgcesCPXdw5RkJZMQt/R/0qvzU20tjzERZIHHrAj13cNLHmYLqM5L42Sn9XiMiRQLPGZFqO9eeip1wKq8FDoHxxkcmwzL8xljzmSBxyx7w+OTdA6OLTmVOmBVjj/BoL5rOCzPZ4w5kwUes+w1OmtuyrKXllgQEKh+UN9t8zzGRIIFHrPsNfeGN/BUOIHntPV4jIkICzxm2WvuHQWWnkodkJEUT3ZKPKe7LfAYEwkWeMyy19w7gtcjFKQnhe05K3JTbY7HmAixwGOWvebeEYoykvB6FrcdQjCrclI41WVzPMZEggUes+w19Y5QkhW+3g74Ewyae0cYn7Qq1caEmwUes+w1942EbX4noCInBZ/6g5oxJrws8JhlzedTWvtGwx54VuX61/KctuE2Y8LOAo9Z1joHx5iY0ggEnsBaHkswMCbcLPCYeXUOjrl2R87AUFhJZnjneArSE0mK99haHmMiwAKPmZOq8oVfHqTmH57g1q//nu6h8Vg36SzhXsMTICJU5KRY4DEmAlwVeERkq4gcFZFaEflUkMcTReSnzuMviEjljMc+7Rw/KiJvmnWdV0ReEpFfRf5drBy/P97J9/94ils2FHKqa4h/+LX7dg0PVC0Id+ABqMhJtbI5xkSAawKPiHiBbwG3AhuB20Vk46zTPgD0qOoa4B7gK861G/Fvg70J2Ap823m+gI8BhyP7Dlaef3uqlpLMJL71nst47zWVPPpy8/QHvVs09Y6QlhhHRlL4N9NdlZtCffcwqhr25zbmfOaawANsBmpV9aSqjgMPAdtmnbMNeMC5/Qhws4iIc/whVR1T1Tqg1nk+RKQMeAtwXxTew4rR0jfCi3Xd3L65gsQ4L9uvqWTKp/zyleZYN+0Mzc4aHv8/g/CqyElhdMJH56D7hhiNWc7cFHhKgYYZ9xudY0HPUdVJoA/InefafwX+Fjjn7LiI3CUie0RkT0dHx2Lfw4rx21dbAXjzxcWAv3DmppIMHj/YGstmnSUSa3gCAkVHG3psnseYcHJT4Ak7EXkr0K6qe+c7V1XvVdUaVa3Jz8+PQuvcbdeRdtYWpLE6P2362JaNRbzU0EvvsHt6AC29oxRnRirw+FOqA9suGGPCw02Bpwkon3G/zDkW9BwRiQMyga5zXHsd8DYROYV/6O4mEflRJBq/kkxO+dh3uoerq3PPOH51dQ6qsOdUT4xadqbRiSm6hsbDnkodEOjxNFqPx5iwclPg2Q2sFZEqEUnAnyywY9Y5O4Dtzu13ArvUP/O7A7jNyXqrAtYCL6rqp1W1TFUrnefbpap3ROPNLGdHWgcYGp+ipjL7jOOXlGeR4PXw4qnuGLXsTK19/lTq4ggNtaUmxpGTmmA9HmPCLPypQIukqpMi8hHgccAL3K+qB0Xki8AeVd0BfA/4oYjUAt34gwnOeQ8Dh4BJ4G5VnYrJG1kBXqzzB5YrK3POOJ4U7+XS8qzpx2Otrd8feIoyItPjAX+vp8GqFxgTVq4JPACq+hjw2Kxjn5txexR41xzXfgn40jme+2ng6XC0c6XbV99DSWZS0En7Syuy+MGzp5ic8hHnjW2HudUJPIUZiRF7jbLsZI60DETs+Y05H7lpqM24xOGWfjaVZgZ9bGNxBuOTPk50xH5hZXv/GAAFEezxlGen0Ng7gs9na3mMCRcLPOYMoxNT1HUOsaE4I+jjG0v8xw8290WzWUG19o+SHO+NyOLRgLLsZMYnfXQOjkXsNYw531jgMWc41jaAT2FDUXrQx6vzUkmM83CouT/KLTtbW/8ohRmJEVk8GhBIqW6wBANjwsYCjznD4RZ/QJmrxxPn9bC+KJ2DLgg87f1jFEZwmA0spdqYSLDAY85wuGWAlAQvFTkpc56zviiD4+2xn3Bv7R+NeOApnQ481uMxJlws8JgzHGntZ11hOh7P3MNX1fmpdA6Ox7SCgapOD7VFUkpCHHlpCdbjMSaMLPCYM5zsGGJNQdo5zwmU0YllZlvfyARjk76I93gASrNTrMdjTBhZ4DHTBscmaR8Yoyov9ZznrXYC08mOwWg0K6g2J5U6GoGnLDvZAo8xYWSBx0w71envwVTPE3jKs5OJ90pMezzTVQsiVKdtprLsZJp6bC2PMeFigcdMO+kEnqr8cweeOK+HytxUTsSwxzNdtSA9GoEnhfEpH+0DtpbHmHCwwONyoxNTPHeii+HxyYi/Vp3Tg6nMPXfgAf88TywDT7sTeAoinFwA/h4eWEq1MeFigcfFpnzKHfe9wO3/8Tzb/u2PDI1FNvjUdQ5SmpVMUrx33nOr8lOp7xpmKkbDT639o2SlxIfU1qWyfXmMCS8LPC72s72N7Dndw7uuKON4+yAPPnc6oq9X1zk0b2JBQEVOCpM+paUvNh/Gbf1jURlmA1tEaky4WeBxsZ/srueCwnS++s6LuW5NLj96/jT+7YfCT1U5ucDAA9DQHZvA094/SmEUEgvAvx1EXlpizN6rMSuNBR6Xqu8a5qX6Xt5xeSkiwrZLS2nqHeFAU2SKc3YNjTMwOrmIwBObXkBr/yiF6ZGf3wkoz0mmsdd6PMaEgwUel/pDbScAb9xY6P+9oRCPwBOH2iLyevVOAFmVO3epnJmKM5PwemT6umia8ikdA2NRSaUOKLNFpMaEjasCj4hsFZGjIlIrIp8K8niiiPzUefwFEamc8dinneNHReRNzrFyEXlKRA6JyEER+Vj03s3SPHuik8KMxOkeSHZqAhtLMiK27XTgQzUwkT6fOK+H0qzkmASezsExfBrZfXhmK8tOprl3JGbJFMasJK4JPCLiBb4F3ApsBG4XkY2zTvsA0KOqa4B7gK84127Evw32JmAr8G3n+SaBv1bVjcDVwN1BnnPRfr2/hXd991l+8VJTuJ4S8M+3PH+ym2uqc88o+X9lZQ4vN/QyPukL6+sBNDmBJ1AUMxQVOSkxCTxt02t4ojfUVpadzMSU0j4wGrXXNGalck3gATYDtap6UlXHgYeAbbPO2QY84Nx+BLhZ/J/M24CHVHVMVeuAWmCzqrao6j4AVR0ADgOl4Wjsqc4hPvHwy+w+1cMnH36ZY23hq9bc2DNC5+AYNZU5Zxy/sjKH0Qkfr0ZgE7bGnmGyUuJJSwx9U7XynOSYzPEEyuVEe6gNLKXamHCYN/CISEWIP8E3cAldKdAw434jZweJ6XNUdRLoA3JDudYZlrsMeCHYi4vIXSKyR0T2dHR0zNvYHzx7ChQe//iNJMR5+P4fT817TagCe91sKjnzP+nlFdkAHGgMf+Bp6h2hNCv03g5AeU4KXUPjEV9fNNt01YIoD7WBpVQbEw6hfL19AFDgXNs8KvAD4MEwtCnsRCQN+BnwcVUNuoOZqt4L3AtQU1NzzoH8KZ+y45Vm3ripkAuK0nnzRcX86pVmvrhtE/HepXciDzX34RH/vjczFWYkkp0SP71ZWzg19oywep5SObNNZ7b1DJ/V1khq7x/FI5CXFr2htkBQbrSU6gXz+ZT2gTFa+0eZmPIhQG5aIoUZiaQkRG7bcuNe8/5fV9U3RKMhQBNQPuN+mXMs2DmNIhIHZAJd57pWROLxB50fq+rPw9HQV5v66B4aZ4uTcbZlYxE/39fES/W9bK7Kmefq+R1s7md1fhrJCWeuyhcRNhRnhD3wqCpNPSPcuDZ/QdcFAs/prugGnta+UfLTE/GeY8+gcAus5bGhttC094/yi5eb+J9jneyr72F4fCroeWXZyVxUmsnmqhzecEEBlSGm85vlzU1fN3YDa0WkCn/QuA34s1nn7AC2A88B7wR2qaqKyA7gP0Xka0AJsBZ40Zn/+R5wWFW/Fq6GPnOsAxG4fk0eANeszsXrEf7nWEfYAs/V1cGfZ0NxBj9+4TRTPg3bB2/30DgjE1PTw0mhCvQCmnuj+2HcNjBGURSH2QLKsm0tz3xq2we454nj/OZACz6F9UXpvOuKMtYWplOcmURinJcpVboGx2jpG+VQSz/7G3v5zautfOGXh6jOS2XbpaW84/JSys+xC65Z3hYceETkz4C3AVP4h99+qao/WWpDVHVSRD4CPA54gftV9aCIfBHYo6o78AeRH4pILdCNPzjhnPcwcAh/JtvdqjolItcDfw4cEJGXnZf6jKo+tpS27j3dw7qCdHKdoZ7M5HguLM1kdxhSnbsG/UMSm0oygz6+viid0QkfdZ3zb9gWqqbehWe0AeSkJpAY56GlL7qZXm19o1SEuN4onMqyk3k1Qgt4l7vRiSm+tvMY9/3+JMnxXu66cTV/emV5yAuS67uGefpYO7850Mq/PnmMe544xtXVObzv2kreuLEoqr1bE3mL6fG8TlVvC9wRkW8BSw48AE5AeGzWsc/NuD0KvGuOa78EfGnWsT9w7rmpxbSR/Y290ws7Ay4ty+S/9jYuuScS2ONmbWHwoLKh2D+kdbR1IGyB57U1PAsLPCJCSVbydOCKlraBUa6syo7qa4I/s+3xg634fHrOrcHPNyc7Brnrh3upbR/k9s0V/M2WddNfykJVkZvCe6+p5L3XVNLUO8IvXmriJy/W86Ef7aMsO5n3XVvJn15ZTnpSfITehYmmxcyEJ4rIW0TkYhF5M7CwT6tlrrFnhJ7hCS4uyzrj+MVlWQyPTy15q4DAZmxzfVOsdhIAwrn7Z2ANT1nWwnsRJVlJUR1qG52Yond4ImZDbf61PLYvT8CztZ28/Vt/pHtonB9+YDP/7x0XLTjozFaalczdb1jD03/zer57x+UUZybxD78+zPVfeYpvPHmcvpGJMLXexMpiAs+HgWzgzc7vj4S1RS73SmMvAJfMCjyXlPvvv9zQu6Tnr+saIs4jc6Y2pyTEUZyZRF1n+Hb/bOwZJj0xjozkhXeASzKTaemN3lBbu7OGJ5pVCwIspfpM/3Osg/f9YDdFmUk8evd13LDA5JT5xHk9bL2wmP/60LU8evd1XFmZzdd2HuP6r+zinp3H6Bu2ALRcLeiTRkQSAFXVH0WoPa53oKmPBK+HC4rSzzhenZdKSoKXQ81Lyzg73TVERU4KcedIy67OT+VEGANPU+8IpdnJZ1RJCFVxVjJtA/402XCkks+nzakcEJsez2uLSGsqo/7yrvLsiU4++OAeVuen8Z93XkV2akJEX++S8izu234lrzb18c1dx/n6k8f53h/qeP91ldx5fTWZKTYEt5yE/Enh1DlrAWpF5LCI3B25ZrlXbdsgVXmpJMSd+Z/O4xHWFKRxvH1pFQzqOofnLdRZnZfGyY7BsG2R0NgzsuD5nYDSrCRU/SnO0RB4nWguHg2wHo/fyY5BPvTDvazKTeHHUQg6M11Ymsm//3kNj/3VDdywNo9v7qp9rQdkQ3DLRiiVC74uItuBjwEbVLUUuBHYJCJ/H+kGuk1d59D0PMtsawvSOda2+LkXVeV019C8axmq8lIZGJ2kc3B80a818zWbehZetSCgJMop1dN12qKw5fVstpYH+kYmuPOBPcR5PXxv+5XkRDHozLSxJIPv3HEFj/3VDVy7JpevP3mc67+yi68/cZz+UQtAbhdKj+cpYDWQBzwrIvuAfwJOALeJSPTTi2JkYspHfffwnIFnXWEaHQNj9A4vLiC0D4wxPD41bwpq4PXDMc/TPzLJwNhkyFWpZyvO9AeeaKVUtw+MkRjnITM5NkMrZdnJ523gUVU+/fP91HcP8907rnDFOpuNJRn8+5/X8Ou/up6rq3O554ljXP/lXXzzyeMMWAByrXkDj6r+wklpfh5/Mc5b8JfHmQRygF0iciKSjXSL+u5hJn1KdV7wNOZ1hf55n8X2egIZbZW55w48q/P9rx+OzLbAgsjFDrWVZPmHvKKVUt3aN0phRtKi5qPCwR94zs+htkf2NvLYgVb+essFYVkoHU6bSjL5j/fW8KuPXs/mqhz+ZecxbvjqU3zrqVoGo1xL0MxvIbPBdwM/Av4FuBy4EDigqpcBGyLQNtc56ayxmXOozVl7s9hK1ae6Qgs8JVnJJMR5OBmGHk/jIrZDmCklIY7slPioDrXFIrEgoCw7habeEXzn2b48jT3D/N2Og1xVlcNdN1bHujlzurA0k/u2X8mOj1zH5RXZ/NPjR7nhK7v49tO1US9ma+YWcuBR1ePAVfi3I0gC9gN/4jy29MmGZSDQw6jOD97jKc1KJjXBS2374noidZ3DxHtluhcxF69HKM9Opr5r6d+8mxa4AVwwxZnJURtqa+sfpSAG8zsBpefpWp6/23EQBf7l3ZcsiyoCF5dlcf/7ruQXd1/HJeVZfPW3R7nhq0/x3WdOMDxuASjWFpT/qqrjqvprVf1HVf2mqvZEqmFudLJjiLy0hDnnF0SE6vy0RfdETnUOUT5PKnVAuDZha+wZITneS/YS0lFLspKj0uNRVdr6Y1OnLSAwJNl0HtVs+93BVp443M7Hb1m7pC8osXBpeRY/eP9mfv7ha7mwNJMv/+YI13/lKb72u6O2qV8MuWkjONc72Tk478R/ZV7q9FzNQp3qGqJqnmG2gIqcFBq6h5ecUt3UO0zZItfwBJRmJUVljmdgbJKRiamYpFIHlE+nVJ8fCQYj41N84ZeHuKAwnfdfVxXr5iza5RXZPPgXm/nZX17L5RVZfPOpWq778i4++fDLHIzAxorm3BYceETkf0WiIctBXefQnIkFAVW5KTT2DC94e2p/KvUwq0IMPOU5KQyMTdK7xNXbjT0ji57fCSjOSmZgdDLiWURtznBeTIfass6vnUjv/2MdTb0jYdtrKtauWJXNfduvZNdfv573XLWK377aylu+8Qfe/d3n+Pm+Rkbm2L7BhNdi/iV9af5TVp6+kQk6B8fnTCwIqMxLxacseBisrX+MkYkpqvJCG8qYuQnbUjT1Ln7xaECxswV1pOd5pre8jmGPJznBS15awnmR2dYzNM53nz7BLRsKuKo6N9bNCauqvFT+7m2beO7TN/OZN6+nbWCUTz78Cpu/9ASf/e8D7G/sDdsCbXO2xVSndv/MYgTMl1gQEFj8eWqB2xYE1uSEuhFWYFuA+u7hswqWhmrQ6TGVLqI46EwzF5EGUsojIRZbXgdTmp1yXvR4vvPMCQbHJ/mbN10Q66ZETGZyPHfduJoP3lDNC3XdPLy7gZ/ta+THL9RTnZfKmy8q5i0XF7O+KD1mKfwr0WICz3n5NWC+VOqAwBxNIDU6VKdDTKUOKM9+LfAsVtMit0OYLXo9HncEnrLs5CXX5HO7tv5RfvDsKf7kstKo7i4bKyLC1dW5XF2dy99t28SvXmnhV/ub+fbTtfzbU7VU56WyZVMRN67Lo2ZVzlkls84nqkr30Dinu4ep7xrmdNcwp7uHFpRl66YdSF3tZOcgcR6ZHuKaS3aqP+ttoVUF6rqGSPB6pnsP80lNjCMvLYGGJQSewHDRUud4/As6oxN40pPiztoSPNrKspPZebBtRe/Lc9/vTzI55eNjN6+NdVOiLiMpnj+7qoI/u6qCzsExHj/YymMHWrjv9yf57jMnSE3wcs3qXG5Ym09NZTYXFKaHlIm6nIyMT9HYM0xDzzAN3SM0dJ95e2DWmqiijKQFbc7oqsAjIluBr+PfgfQ+Vf3yrMcTgQeBK4Au4E9V9ZTz2KeBD+DfGfWvVPXxUJ4zVCc7/FWjQ5lgrcxLXXCPx59KnbygNRLlS0ypDmSiLbXHE+/1UJCeSEuEM9tivXg0oCw7hfEpHx2DYzHvfUVC7/A4//lCPW+9uCTkZJeVKi8tkfdctYr3XLWKgdEJnjvRxTPHOvif4x08cbgdgNQEL5eUZ3HFqmw2lWSwrjCdVbmprl3vpKr0j07S2jdKa/8oLb0jNPaM0NAzTH23P7h0Dp65Ti0xzkN5Tgrl2cnUVGazKjeVVTkprMpNoTwnhaR4/5dB+VBobVhM4GlbxDXzEhEv8C3gjUAjsFtEdqjqoRmnfQDoUdU1InIb8BXgT0VkI/5tsDcBJcATIrLOuWa+5wzJuYqDzlaVm8LuUwtb4nSqczjkbYIDKnJS2Fe/+KVUjT0jJMR5yEtdepZYURQWkbb1j1GUGfsP+plVqldi4HnwudMMjU/xl69fHeumuP3rOWEAACAASURBVEp6UjxbNhWxZVMRqkpjzwj76nvYd7qHvfU9fPvpE0w5FS0S4zysKUhjTUEaZdnJlGal+H9nJ5Ofnkh6YlzY54xGJ6boHhqf/ukZHqdrcJzOwTFa+0f9gcYJNsOzsve8Hv/C9fLsFG5eX0B5TjLlOSmUZadQnpNMflpiWNu74MCjqm8M26ufaTNQq6onAUTkIfy14WYGiW3A3zm3HwH+Tfz/NbYBD6nqGFAnIrXO8xHCc87L51PqOoe4YW1eSOdX5qXy6CvNjE5MTX8TmO/5T3eH/vwB5dkp/Gp/y6L3wmnqGaEsKzksw0UlmUkcXWSpoFC19Y+yOn9h/40iYeZanitWxbgxYTYyPsUPnj3FTesLprdZN2cTEX8PICeFbZeWAv7/drXtgxxtG+Boaz9H2wbZe7qHX+1vmQ5IAXEeISslgeyUeLJS4kmK95IY5yUx3kNinP8HwOeDKVV8qqjC+KSPofFJhsemGJ7w/x4an2RgdPKsYDLztQozkijKTGJDcQZvWF9AcWYShRlJZ/yO5nChm4baSoGGGfcb8ZfoCXqOqk6KSB+Q6xx/fta1pc7t+Z4TABG5C7gLoKKi4ozHmnpHGJv0zZvRFlCVl4o6KdWhZHm1DYwyOuFj1SJ6PFM+paV3dEHjqwGNPcNLnt8JKM5M5umjHahqRLJ/fD5/mZqizNit4QkIzMOtxMy2/36pie6hcT70OuvtLFRygpeLyjK5qCzzjOOTUz7aBsZo6hmhqXeYrkF/b6R7aILeYf/twbFJugbHGZucYmzSx5izDtArgkf8gc7rEeK8QlpiHCkJXgrTk0jJiyM1wUtaYhzZqQnkpiac8TsnxT/n7La5SDcFnphS1XuBewFqamrO+HoSKIFTHWJgCGSm1XUOhRR4AokIoVYtCAiUpa/vHl5U4GnqHQnbt9qSrCRGJqboH5mMyG6QnUNjTPnUFUNbKQlx5KauvLU8qsqDz51iQ3EGV1aeN7udRFyc10NpVrKz55W7qnrHiptSMZqA8hn3y5xjQc8RkTggE3+SwVzXhvKc8wp1DU9AYC1OqJltpzqHnesWFjxmruVZqJHxKToHx8O2p0pgX57mvsj0AtqdxaNuCDywMvfl2X2qhyOtA2y/ZpWtWTERtZiSOQ+LyH+JyD+JyO0iEq7VZbuBtSJSJSIJ+JMFdsw6Zwew3bn9TmCX+pcX78C/KV2iiFQBa4EXQ3zOeZ3sGCI9yZ++HIrM5Hjy0hKo6wgt8JzuGiIhzkNJ5sKGvYoykoj3Cqe7F14brmmJ+/Cc1ZbptTyR+TCO5ZbXwZRlp0yvg1opHnzuFBlJcdNzFsZEymKSC94NICKrgU8C/w4sebzGmbP5CPA4/tTn+1X1oIh8EdijqjuA7wE/dJIHuvEHEpzzHsafNDAJ3K2qU047z3rOhbbtZOcg1flpC/oWWJWXGnKPp67Tn6q90HFYr0coy05Z1FqehjAtHg0IbOXQ3BuZzLa2gdhteR1MWXYyOw+vnLU87f2j/PbVVrZfWxnzdVJm5Vtw4BGRW4C3ACnA74HPhKsxqvoY8NisY5+bcXsUeNcc136JIHXkgj3nQtV1DC24VlVVXiq7jnSEdO6prqGQKxbMttjtERrDsA/PTAXpSXg9Mt0zCbe2/jFEID/NPYFnfNJH5+AYBS7phS3FT3c3MOlT7rh6haXpGVdazBzP/UAq8Azwoqqu6JriQ2OTNPeNLqjuGvjngzoHx+ifp2LzlE851TXM6hDXCM1WkZPC6a6Fb4/Q2D1MgtcTtg9yr0coTE+M2BxPW98oeWmJrlkhHgjYDStguE1VeWRfI9dU5y54LZkxi7Ggv2JnnmQ98AVgCLhDRH4SiYa5RWC4bKGBIfAHPN88T3PvCOOTvkX/wa/KTWFgdJK+kYVtSRDYDiGcw0RFmUm0RHCozQ1VCwJmLiJd7vac7uF01zDvvKIs1k0x54mQA4+IfAxoAY4BTwDlqvo5Vb09Uo1zgxNORtvqEDPaAqpDzGybTqVeZOAJZKWdXuA22I09w2Gb3wkozkqOaHKBW+Z34LX6dishs+2RPY2kJni59aKiWDfFnCfmDTwi8nUR2Q58DNigqmXAjcBGZ+J/RattH8TrkQWvk6nITcEjzLsN9nTgWeRQ26pFplQ39oyEfRvjkswkWvpGI7KPSfuAu+qivbaWZ3kHnuHxSX61v5m3XFxMSoIt6zPREUqP5ylgNZAHPCsi+4B/Ak4At4vIil5pdqJjkIqcFBLjFpbpkxjnpSw7ZXoN0FxOdgySlhi36LmWxWyPMDw+SdfQePh7PJnJjE366FnirqizjU36a1C5KfBAYC3P8h5q++2rrQyNT/HOK8rnP9mYMJk38KjqL5zMsufx1zm7BfgB/rTlHGCXiJyIZCNj6UT70KIn/kNJqT7ZOURVXuqiF+z5t0dIXNBeGOHah2e211Kqw9sLeG3xqHuG2sA/3Lbc1/I8sreRipwUq1RgomohyQV3Az8C/gW4HLgQOKCqlwEbItC2mJtyioOuXmBGW0Ag8Jxr6KnOCTxLUZGTvKBFpOFOpQ4ochbAhrtKdfuAuxaPBpRlp9DYO4LPtzz3RmzvH+W5k128/bJSq1RgoirkwKOqx/EX2HwESAL2A3/iPDYekdbFWEP3MONTPlbnLS7wrM5PZXh8ivaBsaCPj05M0dQ7EvJ2C3NZlZtKQ3fo37wbnOGh8nD3eCJUvaC1z13lcgJmruVZjh470IIqvO2S4lg3xZxn5p1NFJGKWYcOOD8A6SISqILZq6oraj/gwy3+t7O+eP5Cn8FUOQHrRMdg0A9N//qbxWe0BZTnpPCLl5sYn/SFtCXv9D48YV6MmZeWSLxXwt7jCWx57aZ0apiRUt07siwXkf5qfwvri9JZU7C4f9/GLFYoaSwPAArM7IsHu/8D/LuDrhgHm/vxeiSkCtPBBHoyJ9oHuXb12fvIHGn1B7bFPn/AqpwUVP0p0qEUMm3sGQ7bPjwzeZx9P8K9E2lb/ygJXg9ZEah6vRSBocrGnhEur1hecyTNvSPsOd3D32xZN//JxoTZvIFHVd8QjYa40aGWftbkp4W0mVswxZlJZCbHc6gl+AZpR1sHiPPIgtcIzTazSnUoged013DYqlLPVpyZRHMEejwFGeHdATEcSrOW7yLSxw60APDWi0ti3BJzPnJH/RGXOtjcx8aSxdc/FRE2FKdzqCX4COSR1gFW56eFNDx2LqtyQk+pVlVOhSGhYS7FmeFfRNra766qBQGpiXHkLNO1PL/c38KFpRnTW3gYE00WeObQOThGW/8Ym5YQeAA2FmdytLX/rK1vwd/juaBo6ePr+emJJMV7Qkqp7hgcY2h8ispFbBwXiuKsJNr6xsKa6dXe767FozMtx3156ruGeaWh13o7JmYs8Mxh7+keAC4pz1rS82woTmd0wnfWep6+kQmaekcWnbgwk4j4i4WG0ON5bdO5yHzTLclMZnzKR9dQ+BId2/pHXR54ltdQ26+dYba3XGTZbCY2LPDM4YWT3STGebh41v7pCxUYqjs8a7jt1SZ/Ue+NYdp6uiInJaQez6kl1oabT3GYU6oHRicYGp9y3eLRgMCGcJEoExQpvzvUykWlmRGb5zNmPhZ45vD8yS4uq8hacKmc2dYWpJPg9bC/sfeM44Ee1WVhyoaqzE3lVNdQ0CG9meq6hojzyPTEeLhNb4EdpirVbS7b8nq2smx/maCOZbKWp71/lJcbetmysTDWTTHnMVcEHhHJEZGdInLc+R3001hEtjvnHHcKlwaOXyEiB0SkVkS+IU76k7M99xER2S8i/y0iIY2bjU/6ONTSzxsuKFjye0uI83BJeSYv1nWfcXxffQ9rC9LITA5PivCagjTGJn3zlnA55ex2Gql9bYqzwtvjCTxPYGtttwms5VnIAt5YeuJwO6qwZZNVojax44rAA3wKeFJV1wJPOvfPICI5wOfxV0/YDHx+RoD6DvBBYK3zs9U5vhO4UFUvxr+dw6dDaUyvU+Ty1gvDMwZ+VVUurzb3Mzg2CfhL8bxU38sVq8K39mNtoT+NurYjeOp2QF3nUEQzmXJTE0iI84RtJ9LA/j4lmZHpoS1VxXRGYegli2Lpd4daqchJYV3h0lL4jVkKtwSebfgXquL8fnuQc94E7FTVblXtwR9UtopIMZChqs+rf6D9wcD1qvo7VZ10rn8eCGmnq87BMW5aX7DgrRDmclV1DlM+5cW6LgBebuihb2SCa9ecvah0sdbk+5MUjrfNXQ3b51NOdw0vepvtUIhIWNfyBKogFGa6d45HZOH7IcXC4Ngkz9Z2sWVjoevWRJnzi1sCT6Gqtji3W4FgA9ClQMOM+43OsVLn9uzjs/0F8Ju5GiAid4nIHhHZg/r43Fs3LqT953RlZQ7piXE8dqAVgJ2H2onzCK9blx+218hMiScvLZHa9rkDT1PvCCMTUxH/tlucGb7qBS19I+SlJS55ri1SkuK9lGQmL4vA88zRDsanfDbMZmIuaoFHRJ4QkVeD/GybeZ7TawlripCIfBb/Ng4/nuscVb1XVWtUtWZDaVZYh6OS4r1svbCI377aSsfAGD/b18j1a/PCNr8TsKYgldpz7P9ztNU/DLcuDGuHzsW/iDQ8PZ7mvtHp7RbcqiInhdNd7h9q+92hVnJSE8I6xGvMYkQt8KjqLap6YZCfR4E2Z8gM53d7kKdoAmbuVlXmHGvizCG0wHGc53sf8FbgPRpizmskBiHed10lQ+OTbLnnGToGxvjgDdVhf421BenUtg/Omdp7tG3AOS/yPZ62/tF5M+xC0dI7Mp2i7VaVeSmu7/FMTPnYdaSdm9cX4A1zjT5jFsotQ207gECW2nbg0SDnPA5sEZFsJ6lgC/C4M0TXLyJXO9ls7w1cLyJbgb8F3qaqMf1k2FSSyWffvIE4r4eP3rSG68I4vxOwpiCNgdHJ6RTk2Y61DVCalUx6UmSLbRZnJTPp07BsF9DSNzqdou1WFTmpdA2NMzAa3p1Xw+mFk90MjE7yRkujNi7glk3Wvww8LCIfAE4D7wYQkRrgQ6p6p6p2i8jfA7uda76oqoEc5Q/jr46djH8eJzCX829AIrDTmUx9XlU/FIX3E9SdN1RzZwR6OgEbnMWoh1r6gqYfh6tEz3wC+/I0944saf1N/+gEg2OTrh9qC5QfOt01zIWlS1twHCk7D7WSFO/hhrXhm1c0ZrFcEXhUtQu4OcjxPcCdM+7fD9w/x3kXBjm+JrwtdbdNJRmIwP7GPm5af+Y327HJKU50DPL6MKxNmk/RdPWCUS5bwvMEUqmLXN7jWeVkCbo18KgqTx3t4NrVeSQnuDNJw5xf3DLUZsIgNTGO1flp0+V4ZjrU3M/ElHJpeeQ/GEvCtAV2s7N4tMTlczyBtPuFbD8eTXWdQ9R3D/OGC6y3Y9zBAs8Kc3FpJvsbzw48rzT4S/YstehpKLJS4kmK9yw5pTqwCLU4QuV9wiUtMY68tEROd7ozweCpox0AUentGhMKCzwrzEVlmbQPjJ1Vsublhl4KMxKjMlEvIpSEIaW6pXcEj0BhujsXj85UmZvi2h7P00fbWVOQZkVBjWtY4FlhNlflAPBsbdf0MVVl96keLiuP3vqN4qyk6aGyxWruG6UgPSlideXCqSLXnSnVQ2OTvHCy24bZjKu4/y/aLMiGogxyUhP4Y23n9LG6ziGaeke4fm34U7jnUpSRPJ0csFgtfSPTRUfdrjI3lZa+UUYnpmLdlDM8d6KL8SmfDbMZV7HAs8J4PMK1q3P5fW3n9ALOZ475x/hvjGIqbUlWEu0Do0xO+Rb9HC29o64tDjrbKifBoCGEzfii6amj7aQmeKmptGoFxj0s8KxAWy8somNgjGdP+Hs9O15p5oLC9LAVPQ1FcWYyPoX2gcUtIlVVZ/Ho8ujxBFKqT7louE1VefpoB9etyXNtrTtzfrLAswLdsqGQzOR4vv/HU+w93cNL9b28qyakwtxhs9R9ebqHxhmZmKLE5RltAa8tInVPgsHx9kGaekd4w3obZjPuYoFnBUqK9/KXr1/NriPt3HHfC+SnJ3L75oqotqF4unrB4uZ5GpwN7ZZLJlZWSgKZyfGcclHgefqov+Th6y2xwLiMKyoXmPC78/oqugbHONTSz//dup7UxOj+rw6kbS92Q7jGHv+QVXnO8ujxAFTlpVLX6Z7A89SRDtYXpbu+1p05/1jgWaHivB4++5bw7Sm0UBlJcaQmeBedUh3YSrose3n0eABW56edkU0YSwOjE+w+1R3R2oDGLJYNtZmIEBGKsxafUt3QM0x2SjxpUe6pLcXqglRa+0entziPpT/WdjLpU1u/Y1zJAo+JmOLMpEUnFzT2jCyb+Z2A1fn+fY5OnmMzvmh5+mgH6YlxXG6bvhkXssBjIqY4M4nmxc7xdA9TvoyG2eC1wHMixoHHX426nRvW5RG/DKo+mPOP/as0EVOcmUzn4BjjkwtbROrzKY09I5RlL69J8VW5KcR5hBPtsU0wONwyQFv/mFUrMK5lgcdETElWEqrQ1r+wXk/H4BjjUz7KltlQW7zXQ0VuSsx7PE8F0qjX2fyOcSdXBB4RyRGRnSJy3PkddGBaRLY75xwXke0zjl8hIgdEpFZEvuFsgT3zur8WERWR6BUrM9NzNAstIxM4v3yZ9XgAqvPSYh54njnawYWlGRQsYfdXYyLJFYEH+BTwpKquBZ507p9BRHKAzwNXAZuBz88IUN8BPgisdX62zriuHNgC1EfyDZizVTplZOoWuKiywVnDs5xSqQNWF6RyqnN4STXqlqJvZIK99T28fp0Nsxn3ckvg2QY84Nx+AHh7kHPeBOxU1W5V7QF2AltFpBjIUNXnVVWBB2ddfw/wt4BGrPUmqKKMJBLiPAveLqBxeg3P8uvxrM5PY3zKR2PP0raEWKw/HPcXh7VqBcbN3BJ4ClW1xbndChQGOacUaJhxv9E5Vurcnn0cEdkGNKnqK/M1QETuEpE9IrKno6NjEW/BzObxCKtyUji1wNX8p7qGKcxIJCl++RW2jHVm29NH28lIiuPSKOw0a8xiRW11nog8ARQFeeizM++oqorIknsnIpICfAb/MNu8VPVe4F6Ampoa6x2Fyarc1AX3eOo6B6nOS4tQiyJrdb5/ePFExyA3bwj2/SlyVJVnjnVww7r8ZbF5njl/RS3wqOotcz0mIm0iUqyqLc7QWXuQ05qA18+4XwY87Rwvm3W8CVgNVAGvOLkGZcA+Edmsqq1LeCtmASpzU/hDbQc+n+LxyPwX4N+47taLiiPcssjISkkgLy2B2vbo93gOtfTTPjBm2WzG9dzytWgHEMhS2w48GuScx4EtIpLtJBVsAR53huj6ReRqJ5vtvcCjqnpAVQtUtVJVK/EPwV1uQSe6VuWlMjrhC3lfnp6hcXqGJ6jOS41wyyJndX4ax2MQeJ4+6h8ifp3N7xiXc0vg+TLwRhE5Dtzi3EdEakTkPgBV7Qb+Htjt/HzROQbwYeA+oBY4Afwmus03cwnsUxPqdgEnnfmgqmUceDYUZ3CsdQCfL7ojtk8fbWdTSQYF6ZZGbdzNFRUYVbULuDnI8T3AnTPu3w/cP8d5F87zGpVLbqhZsEBK9emuIa6uzp33/MC2AtX5y3OOB+CConSGxqdo7BmJ2q6vfSMT7Kvv5UOvs2rUxv3c0uMxK1RxZhLxXqGuM7QEg7rOQeI8sixTqQMuKEoH4Ehrf9Re87U0alu/Y9zPAo+JqDivh6q8VGrbB0I6v65ziIqclGVd3PKCwkDgCe09h0MgjfoyS6M2y8Dy/es2y8a6wnSOtYU22X6ifWhZz+8ApCbGUZGTwtEoBR5LozbLjf0rNRG3rjCd+u5hhsfPvUHa+KSPEx2D00NVy9n6ovSoDbVZGrVZbizwmIhb5ww9zbe25UTHIJM+ZX1xRjSaFVHri9Kp6xxidGIq4q9ladRmubHAYyJuXaE/Q22+oadAD2H9SujxFGfg0/mDbThYGrVZbizwmIhblZtKQpxn3kWVR1oHSHCSEZa7wHDh4ZbIDrf1DfvTqK0oqFlOLPCYiPN6hDX5afP3eFoGWF2Qtqwz2gIqc1NJjvdyKMKB5+lj7Uz5NOp14YxZiuX/F26WhQ3FGRxs7sO/c0Vwh1v6V8QwG/iD7aaSDPY39kX0dXYeaiMvLYFLyyyN2iwfFnhMVFxanknn4DhNvcH3qWnuHaF9YIxLyjKj3LLIubgsi4PNfRHbFG580sczRzu4eX1hyAVYjXEDCzwmKi5xFja+0hC8B/BSfS8Al1UE3fV8Wbq4LJPRCV/ECoa+WNfNwNgkt2y0YTazvFjgMVGxviiDhDgPLzf0BH38pfoeEuM8bFgBqdQBFzu9t/2NvRF5/icOt5EY5+H6NXkReX5jIsUCj4mKhDgPm0oy2Fcf/EN4X30PF5VmkhC3cv5JVuamkp4UxysRmOdRVZ443MYNa/NITlh+O7Wa89vK+Ss3rnd1dS6vNPQyOHZmBYPBsUn2N/ZRU5kTo5ZFhscjXFSayYEIBJ6jbQM09oxwi2WzmWXIAo+JmhvW5DHpU54/0XXG8T/WdjLpU163Aku+XFyWxZHWfsYmw1vB4IlDbQDctN6qUZvlxwKPiZorKrNJjvfyzLGOM44/fbSD1AQvV6xaOYkFAZeWZzIxpbzaFN71PL892Mol5VkUZFi1ArP8uCLwiEiOiOwUkePO76CfQCKy3TnnuIhsn3H8ChE5ICK1IvINZwvswGMfFZEjInJQRL4ajfdjgkuM83LT+gJ+faCFCSfFeHzSx+MHW3ndBfkran4nIDB8uPtU9zxnhu501xCvNvXz1ouKw/acxkSTW/7SPwU8qaprgSed+2cQkRzg88BVwGbg8zMC1HeADwJrnZ+tzjVvALYBl6jqJuCfI/w+zDzecXkp3UPj7DrSDsCTh9voHhrnnVeUxbhlkZGXlsjq/FRerAtf4Pn1gRYAbr2oKGzPaUw0uSXwbAMecG4/ALw9yDlvAnaqareq9gA7ga0iUgxkqOrz6l8W/+CM6/8S+LKqjgGoansk34SZ343r8inPSeaenccYGpvk608eZ1VuCjeuXXnzOwGbq3LZfaqbKd/cVRsW4tf7W7i0PIuy7Ohsq21MuLkl8BSqaotzuxUIlqpTCjTMuN/oHCt1bs8+DrAOuEFEXhCRZ0TkyrkaICJ3icgeEdnT0dEx12lmieK9Hj775o0caR3g6v/3JEdaB/jsmzes6A3MrqrKYWB0MiwFQ091DnGwuZ+3XmzDbGb5iovWC4nIE0CwsYHPzryjqioi4flq6H9/OcDVwJXAwyJSrUEKhqnqvcC9ADU1NeF6fRPE1guL+Nq7L+GXrzTztktL2LJpZQ8Zba7yz/O8WNfNhaVLKwn02jCbBR6zfEUt8KjqLXM9JiJtIlKsqi3O0FmwIbEm4PUz7pcBTzvHy2Ydb3JuNwI/dwLNiyLiA/IA69LE2DsuL+Mdl6/MeZ3ZSrKSKc9J5vmTXfzF9VWLfh5V5ZevNHNZRRalWclhbKEx0eWW8Y0dQCBLbTvwaJBzHge2iEi2k1SwBXjcGaLrF5GrnWy29864/hfAGwBEZB2QAHRG7m0YE9z1a/J59kQX45OLLxh6sLmfI60D503ANiuXWwLPl4E3ishx4BbnPiJSIyL3AahqN/D3wG7n54vOMYAPA/cBtcAJ4DfO8fuBahF5FXgI2B5smM2YSLtpfQGDY5PsWUJa9SN7G0mI8/C2i0vC2DJjoi9qQ23noqpdwM1Bju8B7pxx/378wSTYeRcGOT4O3BHWxhqzCNeuziXB62HXkXauXURRz7HJKX7xchNbNhaSmRIfgRYaEz1u6fEYs6KlJsZxVXUOTx1dXEb/rsPt9A5PrNj1Tub8YoHHmCi5eX0BJzqGONGx8P15HnjuFKVZydywgtc7mfOHBR5jouTWi4oRgUdfbl7QdYdb+nn+ZDd/fs0qvLbTqFkBLPAYEyWFGUlctzqPX7zUxEJyXL7/xzqS4j3cdmV5BFtnTPRY4DEmit5+WSn13cPsqw++E+tsbf2j/OLlZt5xeRlZKQkRbp0x0WGBx5go2nphEWmJcTz43OmQzv/2U7X4fMqHblwd4ZYZEz0WeIyJorTEOG67spxf7W+huXfknOc29gzzkxcbeFdNGRW5VhDUrBwWeIyJsvc7ZXO+8/SJc573hV8ewusRPnrT2mg0y5ioscBjTJSVZiXznqsq+M8X6znaOhD0nF/vb2HnoTY+fstaSqwum1lhLPAYEwMfv2UdGUlxfOyhlxgZnzrjsWNtA/zfn+3n0vKsJRUVNcatLPAYEwM5qQnc86eXcrRtgDsf3E3HwBiqyh9rO7n93udJTvDyrfdcTvwK3qfInL/EamaeraamRvfs2RPrZpjzwM/2NvJ/f7YfjwjZqfG09Y9RlZfK97bXUJ2fFuvmGbMgIrJXVWvmO88VRUKNOV/97yvKuKwii4d2N9AxMMblq7J55+VlJCd4Y900YyLGAo8xMVadn8Zn3rwh1s0wJmpsANkYY0xUWeAxxhgTVa4IPCKSIyI7ReS48zt7jvO2O+ccF5HtM45fISIHRKRWRL7hbIGNiFwqIs+LyMsiskdENkfrPRljjAnOFYEH+BTwpKquBZ507p9BRHKAzwNXAZuBz88IUN8BPgisdX62Ose/CnxBVS8FPufcN8YYE0NuCTzbgAec2w8Abw9yzpuAnararao9wE5gq4gUAxmq+rz6c8MfnHG9AhnO7UxgYRuhGGOMCTu3ZLUVqmqLc7sVKAxyTinQMON+o3Os1Lk9+zjAx4HHReSf8QfZa+dqgIjcBdwFUFFRsYi3YIwxJhRR6/GIyBMi8mqQn20zz3N6LeFa1fqXwCdUtRz4BPC9uU5U1XtVtUZVa/LzbXthY4yJlKj1eFT1lrkeE5E2ESlW1RZn6Kw9yGlNwOtn3C8DnnaOkw2GhwAABVpJREFUl8063uTc3g58zLn9X8B9i2q8McaYsHHLUNsO/EHiy87vR4Oc8zjwjzMSCrYAn1bVbhHpF5GrgReA9wLfdM5pBl6HP0DdBBwPpTF79+4dFJGji3wv0ZQHdMa6ESGwdobPcmgjWDvDbbm084JQTnJL4Pky8LCIfAA4DbwbQERqgA+p6p1OgPl7YLdzzRdVtdu5/WHgB0Ay8BvnB/yZbl8XkThgFGcOJwRHQ6k3FGsissfaGT7LoZ3LoY1g7Qy35dTOUM5zReBR1S7g5iDH9wB3zrh/P3D/HOddGOT4H4ArwtpYY4wxS+KWdGpjjDHnCQs8wd0b6waEyNoZXsuhncuhjWDtDLcV1U7bj8cYY0xUWY/HGGNMVFngMcYYE1UWeGYQka0ictSpcn1WoVK3EJH7RaRdRF6NdVvmIiLlIvKUiBwSkYMi8rH5r4o+EUkSkRdF5BWnnV+IdZvORUS8IvKSiPwq1m2Zi4iccqrFvxxqem0siEiWiDwiIkdE5LCIXBPrNs0mIhc4/x0DP/0i8vFYt2s2EfmE8/fzqoj8RESSznm+zfH4iYgXOAa8EX+9t93A7ap6KKYNC0JEbgQGgQdV9aw0cjdwKlAUq+o+EUkH9gJvd9t/T2cLjVRVHRSReOAPwMdU9fkYNy0oEfkkUIO/MO5bY92eYETkFFCjqq5e8CgiDwC/V9X7RCQBSFHV3li3ay7OZ1QTcJWqno51ewJEpBT/381GVR0RkYeBx1T1B3NdYz2e12wGalX1pKqOAw/hr5rtOqr6P0D3vCfGkKq2qOo+5/YAcJjXire6hvoNOnfjnR9XfhsTkTLgLVjppyUTkUzgRpz6jao67uag47gZOOGmoDNDHJDsLNZPYZ6dACzwvGau6tdmiUSkErgMf0kj13GGr17GXyNwp6q6sp3AvwJ/C/hi3ZB5KPA7EdnrVH13oyqgA/i+M3R5n4ikxrpR87gN+EmsGzGbqjYB/wzUAy1An6r+7lzXWOAxESUiacDPgI+ran+s2xOMqk45mwWWAZtFxHXDlyLyVqBdVffGui0huF5VLwduBe52hobdJg64HPiOql4GDBFkA0q3cIYC34a/2LGrOPUzt+EP5iVAqojcca5rLPC8pgkon3F/ZpVrswjOnMnPgB+r6s9j3Z75OEMtT/HaDrZuch3wNmf+5CHgJhH5UWybFJzzDRhVbQf+G/8wtts0Ao0zereP4A9EbnUrsE9V22LdkCBuAepUtUNVJ4Cfc469z8ACz0y7gbUiUuV8u7gNf9VsswjOpP33gMOq+rVYt2cuIpIvIlnO7WT8ySVHYtuqs6nqp1W1TFUr8f/b3KWq5/xWGQsikuokk+AMXW0BXJd9qaqtQIOIBKop3wy4KvFllttx4TCbox64WkRSnL/7m/HP6c7JFUVC3UBVJ0XkI/i3X/AC96vqwRg3KygR+Qn+vYnyRKQR+LyqzrnJXYxcB/w5cMCZPwH4jKo+FsM2BVMMPOBkDHmAh1XVtanKy0Ah8N/+zx/igP9U1d/Gtklz+ijwY+eL5kng/TFuT1BOAH8j8H9i3ZZgVPUFEXkE2AdMAi8xT+kcS6c2xhgTVTbUZowxJqos8BhjjIkqCzzGGGOiygKPMcaYqLLAY4wxJqos8BhjjIkqCzzGLEPiZ3+//397d28CIAyFUTQZRHAOx3UwwSHsLUyvIHz64Jw+kCJwCeSHkixcKKL3Po//otZ2vQYw3Y2BP3KBFIoYr3xvrbXlr/8FwRN2PFDLLjpUJzxQy/H1BOAt4QEgSngAiHK4AIAoOx4AooQHgCjhASBKeACIEh4AooQHgCjhASDqBHBwf9+qASgPAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(rplot, erro)\n",
        "plt.xlabel('r')\n",
        "plt.xlim(0,8)\n",
        "plt.ylabel(\"$|\\phi_N - \\phi_0|$\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N73F-WBYjYIN",
        "outputId": "5db7d1ce-1aa4-42fb-f40a-9f4cededd140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0009868837167067743 9.828277009169038e-08 1.865555191361013e-09 2.699943025077681e-10 1.2107569372199174e-11 4.47603546818641e-13 1.533242328695407e-14 5.095675308184934e-16 1.672417011404803e-17 5.467797296472772e-19 "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.90046550e-02,  3.94802873e-03, -4.78238491e-04, -6.57441465e-04,\n",
              "       -2.36843159e-04, -1.75113556e-05,  1.21539696e-04,  1.35292458e-04,\n",
              "        9.30972911e-06, -8.63297347e-05, -5.48528705e-05,  2.13301850e-05,\n",
              "        4.31657045e-05,  1.23980991e-05, -1.60669361e-05, -1.58196719e-05,\n",
              "       -1.08351829e-06,  7.44102949e-06,  5.22973757e-06, -3.50826370e-07,\n",
              "       -2.80985089e-06, -1.69282349e-06,  2.37030821e-07,  1.00447041e-06,\n",
              "        6.05700042e-07, -4.45358689e-08, -3.20823776e-07, -2.12021086e-07,\n",
              "        1.27019607e-10,  1.07281281e-07,  8.72131699e-08,  1.99858446e-08,\n",
              "       -2.35388534e-08, -2.62282859e-08, -7.77557617e-09,  8.30861347e-09,\n",
              "        1.24685751e-08,  8.00633841e-09,  2.09374300e-09, -9.03895258e-10,\n",
              "       -7.35226101e-10,  7.53766207e-10,  1.87013482e-09,  2.04164895e-09,\n",
              "        1.57122381e-09,  9.98978224e-10,  6.49298400e-10,  5.56096464e-10,\n",
              "        5.89006481e-10,  6.19236912e-10,  5.87182664e-10,  5.05073525e-10,\n",
              "        4.07325864e-10,  3.24653977e-10,  2.63560594e-10,  2.20239669e-10,\n",
              "        1.82696681e-10,  1.46555730e-10,  1.08037883e-10,  7.05028681e-11,\n",
              "        3.35173154e-11])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "Pi_0 = np.zeros(N+1)\n",
        "b0 = np.dot(Pi_0, psi)\n",
        "Pi = np.dot(b0, psi)\n",
        "\n",
        "c0 = np.zeros([N+1])     # guess value\n",
        "for i in range(N+1):\n",
        "  c0[i]  =   0.001\n",
        "  \n",
        "Chi=np.dot(c0,psi)    \n",
        "rChi=np.dot(c0,rpsi)\n",
        "rrChi=np.dot(c0,rrpsi)     \n",
        "\n",
        "H0 = 4*rChi**2 + 4*rrChi + 8/r*rChi + 1/2*(rPhi)**2\n",
        "\n",
        "JH = 8*np.dot(c0,rpsi)*rpsi + 4*rrpsi + 8/r*rpsi     # Jacobian Matrix\n",
        "\n",
        "inv_JH = np.linalg.inv(JH)\n",
        "\n",
        "N_int = 50\n",
        "\n",
        "tolerance = 1e-40    # tolerance\n",
        "\n",
        "N_int = 10\n",
        "\n",
        "#tol = 1e-29     # tolerance\n",
        "#while min(abs(np.dot(H0, inv_JH))) >= tol:\n",
        "\n",
        "# Newton Raphson loop\n",
        "for i in range(N_int):\n",
        "  Chi=np.dot(c0,psi)\n",
        "  rChi=np.dot(c0,rpsi)\n",
        "  rrChi=np.dot(c0,rrpsi)\n",
        "  H0 = 4*rChi**2 + 4*rrChi + 8/r*rChi + 1/2*(rPhi)**2\n",
        "  JH = 8*np.dot(c0,rpsi)*rpsi + 4*rrpsi + 8/r*rpsi\n",
        "  cnew = c0 - np.dot(H0, inv_JH)\n",
        "  if min(abs(cnew-c0)) < tolerance:\n",
        "    break\n",
        "  print(min(abs(cnew-c0)), end=' ')\n",
        "  c0 = cnew\n",
        "\n",
        "#out_c0 = open('c0_30_L02.txt', 'a')\n",
        "#out_c0.write(' ' +' '.join(str('%.18f'%n) for n in c0)+'\\n')\n",
        "#out_c0.close()\n",
        "\n",
        "\n",
        "c0    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_B1C2AB5TiO"
      },
      "source": [
        "Field equations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xUP2_j8OoEWy"
      },
      "outputs": [],
      "source": [
        "# Equation for Krr: momentum constraint\n",
        "\n",
        "# Initial values of Krr: Base functions of Krr\n",
        "\n",
        "SB1 = 1/2*(SB[1:(N+2),:] + SB[0:(N+1),:])          # VERIFICADO\n",
        "rSB1 = 1/2*(rSB[1:(N+2),:] + rSB[0:(N+1),:])\n",
        "rrSB1 = 1/2*(rrSB[1:(N+2),:] + rrSB[0:(N+1),:])\n",
        "\n",
        "\n",
        "# Base functions for Beta\n",
        "\n",
        "SB2 = np.zeros([N+1,N+1])      \n",
        "rSB2 = np.zeros([N+1,N+1])\n",
        "rrSB2 = np.zeros([N+1,N+1])\n",
        "\n",
        "for i in range(N+1):                                                   # VERIFICADO\n",
        "  SB2[i,] = np.sin((2*(i+1/2)+1)*np.arctan(L0/r))                                                  \n",
        "\n",
        "for i in range(N+1):\n",
        "  rSB2[i,] = -np.cos((2*i+2)*np.arctan(L0/r))*(2*i+2)*L0/(r**2*(1+L0**2/r**2))\n",
        "\n",
        "for i in range(N+1):\n",
        "  rrSB2[i,] = -np.sin((2*i+2)*np.arctan(L0/r))*(2*i+2)**2*L0**2/(r**4*(1+L0**2/r**2)**2)+2*np.cos((2*i+2)*np.arctan(L0/r))*(2*i+2)*L0/(r**3*(1+L0**2/r**2))-2*np.cos((2*i+2)*np.arctan(L0/r))*(2*i+2)*L0**3/(r**5*(1+L0**2/r**2)**2)\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbh3ulv0VeDU"
      },
      "source": [
        "Quadrature Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fK3MiMX3CeQE"
      },
      "outputs": [],
      "source": [
        "Nq = int(3/2*N)           # Quadrature truncation\n",
        "\n",
        "gauss_quadrature = np.polynomial.legendre.leggauss(Nq + 1) \n",
        "\n",
        "new_col = gauss_quadrature[0]            # Legendre quadrature points\n",
        "\n",
        "\n",
        "# Legendre Polinomials\n",
        "\n",
        "P = np.zeros([Nq+3,Nq+1])\n",
        "colP = np.zeros([Nq+3,Nq+1])\n",
        "\n",
        "P[0,] = 1\n",
        "P[1,] = new_col\n",
        "\n",
        "colP[0,] = 0\n",
        "colP[1,] = 1\n",
        "\n",
        "for i in range(2,Nq+3):\n",
        "  P[i,] = ((2*i-1)*new_col*P[i-1,] - (i-1)*P[i-2,])/(i)   \n",
        "\n",
        "for i in range(2,Nq+3):\n",
        "  colP[i,] = i*P[i-1] + new_col*colP[i-1]\n",
        "\n",
        "P_max = P[Nq+1]\n",
        "\n",
        "colP_max = colP[Nq+1]\n",
        "\n",
        "wq_col = 2/((1-new_col**2)*colP_max**2)    # Legendre weight (Verificado)\n",
        "\n",
        "rq = L0*(1+new_col)/(1-new_col)            # Physical quadrature domain\n",
        "\n",
        "qSB = np.zeros([Nq+3,Nq+1])                # Base function in quadrature points\n",
        "qrSB = np.zeros([Nq+3,Nq+1])\n",
        "qrrSB = np.zeros([Nq+3,Nq+1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(Nq+1+1+1):\n",
        "  qSB[i,] = np.sin((2*i+1)*np.arctan(L0/rq))                                                  \n",
        "\n",
        "for i in range(Nq+1+1+1):\n",
        "  qrSB[i,] = -np.cos((2*i+1)*np.arctan(L0/rq))*(2*i+1)*L0/(rq**2*(1+L0**2/rq**2))\n",
        "\n",
        "for i in range(Nq+1+1+1):\n",
        "  qrrSB[i,] = -np.sin((2*i+1)*np.arctan(L0/rq))*(2*i+1)**2*L0**2/(rq**4*(1+L0**2/rq**2)**2)+2*np.cos((2*i+1)*np.arctan(L0/rq))*(2*i+1)*L0/(rq**3*(1+L0**2/rq**2))-2*np.cos((2*i+1)*np.arctan(L0/rq))*(2*i+1)*L0**3/(rq**5*(1+L0**2/rq**2)**2)                                         \n",
        "\n",
        "\n",
        "qpsi = qSB[0:N+1,:]\n",
        "rqpsi = qrSB[0:N+1,:]\n",
        "rrqpsi = qrrSB[0:N+1,:]\n",
        "\n",
        "# Initial values of Krr:\n",
        "\n",
        "\n",
        "qSB1 = 1/2*(qSB[1:(N+2),:] + qSB[0:(N+1),:])          # VERIFICADO\n",
        "qrSB1 = 1/2*(qrSB[1:(N+2),:] + qrSB[0:(N+1),:])\n",
        "qrrSB1 = 1/2*(qrrSB[1:(N+2),:] + qrrSB[0:(N+1),:])\n",
        "\n",
        "\n",
        "#qKrr = np.dot(ck0, qSB1) \n",
        "\n",
        "# Alpha na origem\n",
        "\n",
        "psi_0 = np.zeros(N+1)\n",
        "\n",
        "for i in range(N+1):\n",
        "  psi_0[i,] = np.sin((2*i+1)*math.pi/2)     # arccot(0) = Pi/2  \n",
        "\n",
        "#Alpha_0 = 1 + np.dot(al0, psi_0) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXpGHAGL1Fww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1256433-9699-401c-f89e-ce5800b84936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "a = [ 0.15954928  0.00323114 -0.05399845  0.01961493 -0.00481969 -0.01514212\n",
            "  0.00584239  0.01516115  0.00117814 -0.00714835 -0.00603162]\n",
            "1.1611000009998886\n",
            "Error_max =  3.2310876397500443e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15956697  0.00321373 -0.05399196  0.01962119 -0.004823   -0.01514595\n",
            "  0.00584449  0.01516029  0.00117857 -0.00714751 -0.00603076]\n",
            "1.1612000009998886\n",
            "Error_max =  3.2302379196331165e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15958465  0.00319632 -0.05398546  0.01962744 -0.00482631 -0.01514979\n",
            "  0.00584658  0.01515943  0.00117899 -0.00714668 -0.00602989]\n",
            "1.1613000009998886\n",
            "Error_max =  3.2293876119897843e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15960234  0.0031789  -0.05397896  0.01963369 -0.00482961 -0.01515362\n",
            "  0.00584868  0.01515857  0.00117942 -0.00714585 -0.00602902]\n",
            "1.1614000009998886\n",
            "Error_max =  3.2285367172065064e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15962003  0.00316149 -0.05397246  0.01963993 -0.00483292 -0.01515745\n",
            "  0.00585077  0.0151577   0.00117984 -0.00714502 -0.00602815]\n",
            "1.1615000009998886\n",
            "Error_max =  3.227685235678212e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15963772  0.00314407 -0.05396596  0.01964618 -0.00483622 -0.01516128\n",
            "  0.00585287  0.01515684  0.00118027 -0.00714419 -0.00602728]\n",
            "1.1616000009998886\n",
            "Error_max =  3.2268331677977127e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15965542  0.00312664 -0.05395945  0.01965242 -0.00483953 -0.01516511\n",
            "  0.00585497  0.01515597  0.0011807  -0.00714335 -0.00602641]\n",
            "1.1617000009998886\n",
            "Error_max =  3.2259805139482907e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15967311  0.00310922 -0.05395294  0.01965867 -0.00484283 -0.01516894\n",
            "  0.00585707  0.0151551   0.00118113 -0.00714252 -0.00602554]\n",
            "1.1618000009998886\n",
            "Error_max =  3.2251272745396984e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15969081  0.00309179 -0.05394643  0.01966491 -0.00484614 -0.01517277\n",
            "  0.00585917  0.01515423  0.00118156 -0.00714169 -0.00602467]\n",
            "1.1619000009998885\n",
            "Error_max =  3.224273449960512e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15970851  0.00307436 -0.05393991  0.01967114 -0.00484944 -0.0151766\n",
            "  0.00586126  0.01515335  0.00118198 -0.00714086 -0.00602379]\n",
            "1.1620000009998885\n",
            "Error_max =  3.2234190405918964e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15972621  0.00305692 -0.05393339  0.01967738 -0.00485275 -0.01518043\n",
            "  0.00586336  0.01515248  0.00118241 -0.00714002 -0.00602292]\n",
            "1.1621000009998885\n",
            "Error_max =  3.2225640468393687e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15974392  0.00303949 -0.05392687  0.01968362 -0.00485605 -0.01518426\n",
            "  0.00586546  0.0151516   0.00118284 -0.00713919 -0.00602205]\n",
            "1.1622000009998885\n",
            "Error_max =  3.2217084690936227e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15976162  0.00302205 -0.05392035  0.01968985 -0.00485936 -0.01518808\n",
            "  0.00586757  0.01515073  0.00118328 -0.00713836 -0.00602117]\n",
            "1.1623000009998885\n",
            "Error_max =  3.220852307748529e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15977933  0.00300461 -0.05391382  0.01969608 -0.00486266 -0.01519191\n",
            "  0.00586967  0.01514985  0.00118371 -0.00713753 -0.0060203 ]\n",
            "1.1624000009998885\n",
            "Error_max =  3.2199955632064276e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15979704  0.00298716 -0.05390729  0.01970231 -0.00486597 -0.01519573\n",
            "  0.00587177  0.01514896  0.00118414 -0.00713669 -0.00601943]\n",
            "1.1625000009998885\n",
            "Error_max =  3.2191382358506016e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15981476  0.00296972 -0.05390076  0.01970854 -0.00486927 -0.01519956\n",
            "  0.00587387  0.01514808  0.00118457 -0.00713586 -0.00601855]\n",
            "1.1626000009998885\n",
            "Error_max =  3.218280326085509e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15983247  0.00295227 -0.05389423  0.01971476 -0.00487257 -0.01520338\n",
            "  0.00587598  0.0151472   0.001185   -0.00713503 -0.00601767]\n",
            "1.1627000009998885\n",
            "Error_max =  3.2174218343029025e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15985019  0.00293482 -0.05388769  0.01972099 -0.00487588 -0.01520721\n",
            "  0.00587808  0.01514631  0.00118544 -0.00713419 -0.0060168 ]\n",
            "1.1628000009998885\n",
            "Error_max =  3.2165627608955936e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15986791  0.00291736 -0.05388115  0.01972721 -0.00487918 -0.01521103\n",
            "  0.00588018  0.01514542  0.00118587 -0.00713336 -0.00601592]\n",
            "1.1629000009998884\n",
            "Error_max =  3.215703106265923e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15988563  0.00289991 -0.05387461  0.01973343 -0.00488249 -0.01521485\n",
            "  0.00588229  0.01514453  0.0011863  -0.00713252 -0.00601504]\n",
            "1.1630000009998884\n",
            "Error_max =  3.214842870803526e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15990335  0.00288245 -0.05386806  0.01973965 -0.00488579 -0.01521867\n",
            "  0.0058844   0.01514364  0.00118674 -0.00713169 -0.00601417]\n",
            "1.1631000009998884\n",
            "Error_max =  3.213982054914978e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15992107  0.00286498 -0.05386151  0.01974587 -0.0048891  -0.01522249\n",
            "  0.0058865   0.01514275  0.00118717 -0.00713086 -0.00601329]\n",
            "1.1632000009998884\n",
            "Error_max =  3.2131206589867383e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1599388   0.00284752 -0.05385496  0.01975208 -0.0048924  -0.01522631\n",
            "  0.00588861  0.01514185  0.00118761 -0.00713002 -0.00601241]\n",
            "1.1633000009998884\n",
            "Error_max =  3.2122586834200884e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15995653  0.00283005 -0.05384841  0.01975829 -0.0048957  -0.01523013\n",
            "  0.00589072  0.01514096  0.00118805 -0.00712919 -0.00601153]\n",
            "1.1634000009998884\n",
            "Error_max =  3.2113961286194867e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15997426  0.00281258 -0.05384185  0.01976451 -0.00489901 -0.01523395\n",
            "  0.00589282  0.01514006  0.00118848 -0.00712835 -0.00601065]\n",
            "1.1635000009998884\n",
            "Error_max =  3.210532994970333e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.15999199  0.00279511 -0.05383529  0.01977072 -0.00490231 -0.01523777\n",
            "  0.00589493  0.01513916  0.00118892 -0.00712752 -0.00600977]\n",
            "1.1636000009998884\n",
            "Error_max =  3.209669282874968e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16000973  0.00277763 -0.05382873  0.01977692 -0.00490561 -0.01524158\n",
            "  0.00589704  0.01513826  0.00118936 -0.00712668 -0.00600889]\n",
            "1.1637000009998884\n",
            "Error_max =  3.208804992730439e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16002746  0.00276016 -0.05382216  0.01978313 -0.00490892 -0.0152454\n",
            "  0.00589915  0.01513735  0.0011898  -0.00712585 -0.00600801]\n",
            "1.1638000009998883\n",
            "Error_max =  3.207940124941203e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1600452   0.00274268 -0.05381559  0.01978934 -0.00491222 -0.01524921\n",
            "  0.00590126  0.01513645  0.00119024 -0.00712501 -0.00600712]\n",
            "1.1639000009998883\n",
            "Error_max =  3.207074679899014e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16006294  0.00272519 -0.05380902  0.01979554 -0.00491553 -0.01525303\n",
            "  0.00590337  0.01513554  0.00119068 -0.00712418 -0.00600624]\n",
            "1.1640000009998883\n",
            "Error_max =  3.206208658006212e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16008069  0.00270771 -0.05380245  0.01980174 -0.00491883 -0.01525684\n",
            "  0.00590549  0.01513464  0.00119112 -0.00712334 -0.00600536]\n",
            "1.1641000009998883\n",
            "Error_max =  3.205342059656667e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16009843  0.00269022 -0.05379587  0.01980794 -0.00492213 -0.01526066\n",
            "  0.0059076   0.01513373  0.00119156 -0.00712251 -0.00600447]\n",
            "1.1642000009998883\n",
            "Error_max =  3.2044748852633085e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16011618  0.00267273 -0.05378929  0.01981414 -0.00492544 -0.01526447\n",
            "  0.00590971  0.01513281  0.001192   -0.00712167 -0.00600359]\n",
            "1.1643000009998883\n",
            "Error_max =  3.203607135206242e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16013393  0.00265524 -0.05378271  0.01982033 -0.00492874 -0.01526828\n",
            "  0.00591182  0.0151319   0.00119244 -0.00712084 -0.0060027 ]\n",
            "1.1644000009998883\n",
            "Error_max =  3.202738809900513e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16015168  0.00263774 -0.05377613  0.01982652 -0.00493204 -0.01527209\n",
            "  0.00591394  0.01513099  0.00119288 -0.00712    -0.00600182]\n",
            "1.1645000009998883\n",
            "Error_max =  3.2018699097389344e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16016943  0.00262024 -0.05376954  0.01983272 -0.00493535 -0.0152759\n",
            "  0.00591605  0.01513007  0.00119332 -0.00711916 -0.00600093]\n",
            "1.1646000009998883\n",
            "Error_max =  3.201000435132316e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16018719  0.00260274 -0.05376295  0.01983891 -0.00493865 -0.01527971\n",
            "  0.00591817  0.01512915  0.00119377 -0.00711833 -0.00600005]\n",
            "1.1647000009998882\n",
            "Error_max =  3.200130386463941e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16020495  0.00258524 -0.05375636  0.0198451  -0.00494195 -0.01528352\n",
            "  0.00592028  0.01512823  0.00119421 -0.00711749 -0.00599916]\n",
            "1.1648000009998882\n",
            "Error_max =  3.199259764150973e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1602227   0.00256773 -0.05374976  0.01985128 -0.00494525 -0.01528733\n",
            "  0.0059224   0.01512731  0.00119465 -0.00711666 -0.00599827]\n",
            "1.1649000009998882\n",
            "Error_max =  3.198388568585164e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16024047  0.00255022 -0.05374317  0.01985747 -0.00494856 -0.01529114\n",
            "  0.00592452  0.01512639  0.0011951  -0.00711582 -0.00599738]\n",
            "1.1650000009998882\n",
            "Error_max =  3.197516800172032e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16025823  0.00253271 -0.05373656  0.01986365 -0.00495186 -0.01529494\n",
            "  0.00592664  0.01512547  0.00119554 -0.00711498 -0.0059965 ]\n",
            "1.1651000009998882\n",
            "Error_max =  3.196644459311799e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16027599  0.0025152  -0.05372996  0.01986983 -0.00495516 -0.01529875\n",
            "  0.00592875  0.01512454  0.00119599 -0.00711415 -0.00599561]\n",
            "1.1652000009998882\n",
            "Error_max =  3.1957715464036306e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16029376  0.00249768 -0.05372335  0.01987601 -0.00495846 -0.01530255\n",
            "  0.00593087  0.01512361  0.00119644 -0.00711331 -0.00599472]\n",
            "1.1653000009998882\n",
            "Error_max =  3.194898061853043e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16031153  0.00248016 -0.05371674  0.01988219 -0.00496177 -0.01530636\n",
            "  0.00593299  0.01512268  0.00119688 -0.00711247 -0.00599383]\n",
            "1.1654000009998882\n",
            "Error_max =  3.1940240060623767e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1603293   0.00246264 -0.05371013  0.01988836 -0.00496507 -0.01531016\n",
            "  0.00593511  0.01512175  0.00119733 -0.00711163 -0.00599294]\n",
            "1.1655000009998882\n",
            "Error_max =  3.1931493794350315e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16034708  0.00244512 -0.05370352  0.01989454 -0.00496837 -0.01531397\n",
            "  0.00593723  0.01512082  0.00119778 -0.0071108  -0.00599204]\n",
            "1.1656000009998881\n",
            "Error_max =  3.1922741823754656e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16036485  0.00242759 -0.0536969   0.01990071 -0.00497167 -0.01531777\n",
            "  0.00593935  0.01511988  0.00119823 -0.00710996 -0.00599115]\n",
            "1.1657000009998881\n",
            "Error_max =  3.1913984152775493e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16038263  0.00241006 -0.05369028  0.01990688 -0.00497498 -0.01532157\n",
            "  0.00594147  0.01511895  0.00119868 -0.00710912 -0.00599026]\n",
            "1.1658000009998881\n",
            "Error_max =  3.1905220785584463e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16040041  0.00239253 -0.05368366  0.01991305 -0.00497828 -0.01532537\n",
            "  0.0059436   0.01511801  0.00119912 -0.00710828 -0.00598937]\n",
            "1.165900000999888\n",
            "Error_max =  3.189645172597204e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16041819  0.002375   -0.05367703  0.01991922 -0.00498158 -0.01532917\n",
            "  0.00594572  0.01511707  0.00119957 -0.00710745 -0.00598847]\n",
            "1.166000000999888\n",
            "Error_max =  3.1887676978332203e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16043597  0.00235746 -0.0536704   0.01992538 -0.00498488 -0.01533297\n",
            "  0.00594784  0.01511613  0.00120002 -0.00710661 -0.00598758]\n",
            "1.166100000999888\n",
            "Error_max =  3.187889654648719e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16045376  0.00233992 -0.05366377  0.01993155 -0.00498819 -0.01533677\n",
            "  0.00594997  0.01511519  0.00120048 -0.00710577 -0.00598669]\n",
            "1.166200000999888\n",
            "Error_max =  3.1870110434492177e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16047155  0.00232238 -0.05365714  0.01993771 -0.00499149 -0.01534057\n",
            "  0.00595209  0.01511424  0.00120093 -0.00710493 -0.00598579]\n",
            "1.166300000999888\n",
            "Error_max =  3.1861318646455266e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16048934  0.00230483 -0.0536505   0.01994387 -0.00499479 -0.01534437\n",
            "  0.00595422  0.0151133   0.00120138 -0.00710409 -0.00598489]\n",
            "1.166400000999888\n",
            "Error_max =  3.185252118634693e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16050713  0.00228728 -0.05364386  0.01995003 -0.00499809 -0.01534816\n",
            "  0.00595634  0.01511235  0.00120183 -0.00710325 -0.005984  ]\n",
            "1.166500000999888\n",
            "Error_max =  3.1843718058307035e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16052492  0.00226973 -0.05363722  0.01995618 -0.00500139 -0.01535196\n",
            "  0.00595847  0.0151114   0.00120228 -0.00710242 -0.0059831 ]\n",
            "1.166600000999888\n",
            "Error_max =  3.1834909266306054e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16054272  0.00225218 -0.05363058  0.01996234 -0.0050047  -0.01535575\n",
            "  0.00596059  0.01511045  0.00120274 -0.00710158 -0.00598221]\n",
            "1.166700000999888\n",
            "Error_max =  3.182609481447327e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16056051  0.00223463 -0.05362393  0.01996849 -0.005008   -0.01535955\n",
            "  0.00596272  0.0151095   0.00120319 -0.00710074 -0.00598131]\n",
            "1.166800000999888\n",
            "Error_max =  3.181727470675798e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16057831  0.00221707 -0.05361728  0.01997464 -0.0050113  -0.01536334\n",
            "  0.00596485  0.01510855  0.00120365 -0.0070999  -0.00598041]\n",
            "1.166900000999888\n",
            "Error_max =  3.18084489473424e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16059612  0.00219951 -0.05361062  0.01998079 -0.0050146  -0.01536714\n",
            "  0.00596698  0.01510759  0.0012041  -0.00709906 -0.00597951]\n",
            "1.167000000999888\n",
            "Error_max =  3.1799617540249943e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16061392  0.00218195 -0.05360397  0.01998694 -0.0050179  -0.01537093\n",
            "  0.00596911  0.01510663  0.00120456 -0.00709822 -0.00597861]\n",
            "1.167100000999888\n",
            "Error_max =  3.179078048956754e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16063172  0.00216438 -0.05359731  0.01999308 -0.0050212  -0.01537472\n",
            "  0.00597124  0.01510567  0.00120501 -0.00709738 -0.00597771]\n",
            "1.167200000999888\n",
            "Error_max =  3.178193779925507e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16064953  0.00214681 -0.05359065  0.01999923 -0.00502451 -0.01537851\n",
            "  0.00597337  0.01510471  0.00120547 -0.00709654 -0.00597681]\n",
            "1.167300000999888\n",
            "Error_max =  3.177308947359005e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16066734  0.00212924 -0.05358398  0.02000537 -0.00502781 -0.0153823\n",
            "  0.0059755   0.01510375  0.00120593 -0.0070957  -0.00597591]\n",
            "1.167400000999888\n",
            "Error_max =  3.1764235516479423e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16068515  0.00211167 -0.05357732  0.02001151 -0.00503111 -0.01538609\n",
            "  0.00597763  0.01510279  0.00120638 -0.00709486 -0.00597501]\n",
            "1.167500000999888\n",
            "Error_max =  3.175537593194659e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16070297  0.00209409 -0.05357065  0.02001765 -0.00503441 -0.01538988\n",
            "  0.00597976  0.01510182  0.00120684 -0.00709402 -0.00597411]\n",
            "1.167600000999888\n",
            "Error_max =  3.174651072425848e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16072078  0.00207652 -0.05356398  0.02002378 -0.00503771 -0.01539367\n",
            "  0.00598189  0.01510086  0.0012073  -0.00709318 -0.0059732 ]\n",
            "1.167700000999888\n",
            "Error_max =  3.1737639897343214e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1607386   0.00205894 -0.0535573   0.02002992 -0.00504101 -0.01539745\n",
            "  0.00598403  0.01509989  0.00120776 -0.00709234 -0.0059723 ]\n",
            "1.167800000999888\n",
            "Error_max =  3.172876345534066e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16075642  0.00204135 -0.05355062  0.02003605 -0.00504431 -0.01540124\n",
            "  0.00598616  0.01509892  0.00120822 -0.0070915  -0.0059714 ]\n",
            "1.1679000009998879\n",
            "Error_max =  3.1719881402422455e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16077424  0.00202377 -0.05354394  0.02004218 -0.00504761 -0.01540503\n",
            "  0.00598829  0.01509795  0.00120868 -0.00709066 -0.00597049]\n",
            "1.1680000009998879\n",
            "Error_max =  3.1710993742527306e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16079207  0.00200618 -0.05353726  0.02004831 -0.00505092 -0.01540881\n",
            "  0.00599043  0.01509697  0.00120914 -0.00708982 -0.00596959]\n",
            "1.1681000009998879\n",
            "Error_max =  3.1702100479848023e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16080989  0.00198859 -0.05353057  0.02005444 -0.00505422 -0.0154126\n",
            "  0.00599256  0.015096    0.0012096  -0.00708898 -0.00596869]\n",
            "1.1682000009998879\n",
            "Error_max =  3.1693201618355074e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16082772  0.00197099 -0.05352388  0.02006057 -0.00505752 -0.01541638\n",
            "  0.0059947   0.01509502  0.00121006 -0.00708814 -0.00596778]\n",
            "1.1683000009998878\n",
            "Error_max =  3.16842971623048e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16084555  0.0019534  -0.05351719  0.02006669 -0.00506082 -0.01542016\n",
            "  0.00599683  0.01509404  0.00121052 -0.00708729 -0.00596687]\n",
            "1.1684000009998878\n",
            "Error_max =  3.1675387115688844e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16086338  0.0019358  -0.0535105   0.02007281 -0.00506412 -0.01542394\n",
            "  0.00599897  0.01509306  0.00121099 -0.00708645 -0.00596597]\n",
            "1.1685000009998878\n",
            "Error_max =  3.166647148263649e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16088121  0.0019182  -0.0535038   0.02007894 -0.00506742 -0.01542773\n",
            "  0.00600111  0.01509208  0.00121145 -0.00708561 -0.00596506]\n",
            "1.1686000009998878\n",
            "Error_max =  3.1657550267287613e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16089905  0.0019006  -0.0534971   0.02008505 -0.00507072 -0.01543151\n",
            "  0.00600325  0.0150911   0.00121191 -0.00708477 -0.00596415]\n",
            "1.1687000009998878\n",
            "Error_max =  3.1648623473686794e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16091689  0.00188299 -0.0534904   0.02009117 -0.00507402 -0.01543529\n",
            "  0.00600539  0.01509011  0.00121238 -0.00708393 -0.00596324]\n",
            "1.1688000009998878\n",
            "Error_max =  3.1639691105931557e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16093473  0.00186538 -0.05348369  0.02009729 -0.00507732 -0.01543907\n",
            "  0.00600752  0.01508912  0.00121284 -0.00708309 -0.00596234]\n",
            "1.1689000009998878\n",
            "Error_max =  3.1630753168204125e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16095257  0.00184777 -0.05347699  0.0201034  -0.00508062 -0.01544284\n",
            "  0.00600966  0.01508814  0.00121331 -0.00708224 -0.00596143]\n",
            "1.1690000009998878\n",
            "Error_max =  3.162180966451732e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16097041  0.00183015 -0.05347028  0.02010951 -0.00508392 -0.01544662\n",
            "  0.0060118   0.01508715  0.00121377 -0.0070814  -0.00596052]\n",
            "1.1691000009998878\n",
            "Error_max =  3.1612860599127475e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16098826  0.00181254 -0.05346356  0.02011562 -0.00508722 -0.0154504\n",
            "  0.00601394  0.01508616  0.00121424 -0.00708056 -0.00595961]\n",
            "1.1692000009998877\n",
            "Error_max =  3.160390597602624e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16100611  0.00179492 -0.05345685  0.02012173 -0.00509052 -0.01545417\n",
            "  0.00601609  0.01508516  0.00121471 -0.00707972 -0.0059587 ]\n",
            "1.1693000009998877\n",
            "Error_max =  3.15949457993429e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16102395  0.0017773  -0.05345013  0.02012784 -0.00509382 -0.01545795\n",
            "  0.00601823  0.01508417  0.00121517 -0.00707887 -0.00595778]\n",
            "1.1694000009998877\n",
            "Error_max =  3.1585980073280853e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16104181  0.00175967 -0.05344341  0.02013394 -0.00509712 -0.01546172\n",
            "  0.00602037  0.01508317  0.00121564 -0.00707803 -0.00595687]\n",
            "1.1695000009998877\n",
            "Error_max =  3.157700880190586e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16105966  0.00174205 -0.05343668  0.02014005 -0.00510042 -0.0154655\n",
            "  0.00602251  0.01508217  0.00121611 -0.00707719 -0.00595596]\n",
            "1.1696000009998877\n",
            "Error_max =  3.1568031989347203e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16107752  0.00172442 -0.05342996  0.02014615 -0.00510373 -0.01546927\n",
            "  0.00602466  0.01508117  0.00121658 -0.00707634 -0.00595505]\n",
            "1.1697000009998877\n",
            "Error_max =  3.155904963968123e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16109537  0.00170679 -0.05342323  0.02015225 -0.00510703 -0.01547304\n",
            "  0.0060268   0.01508017  0.00121705 -0.0070755  -0.00595413]\n",
            "1.1698000009998877\n",
            "Error_max =  3.155006175714311e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16111323  0.00168915 -0.05341649  0.02015834 -0.00511033 -0.01547682\n",
            "  0.00602894  0.01507917  0.00121752 -0.00707466 -0.00595322]\n",
            "1.1699000009998877\n",
            "Error_max =  3.154106834581977e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16113109  0.00167151 -0.05340976  0.02016444 -0.00511363 -0.01548059\n",
            "  0.00603109  0.01507817  0.00121799 -0.00707381 -0.0059523 ]\n",
            "1.1700000009998877\n",
            "Error_max =  3.1532069409893437e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16114896  0.00165388 -0.05340302  0.02017053 -0.00511693 -0.01548436\n",
            "  0.00603323  0.01507716  0.00121846 -0.00707297 -0.00595139]\n",
            "1.1701000009998876\n",
            "Error_max =  3.1523064953419284e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16116682  0.00163623 -0.05339628  0.02017663 -0.00512023 -0.01548813\n",
            "  0.00603538  0.01507615  0.00121893 -0.00707213 -0.00595047]\n",
            "1.1702000009998876\n",
            "Error_max =  3.151405498050542e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16118469  0.00161859 -0.05338954  0.02018272 -0.00512353 -0.01549189\n",
            "  0.00603753  0.01507514  0.0012194  -0.00707128 -0.00594956]\n",
            "1.1703000009998876\n",
            "Error_max =  3.1505039495387007e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16120256  0.00160094 -0.05338279  0.02018881 -0.00512683 -0.01549566\n",
            "  0.00603967  0.01507413  0.00121987 -0.00707044 -0.00594864]\n",
            "1.1704000009998876\n",
            "Error_max =  3.149601850220392e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16122043  0.00158329 -0.05337604  0.02019489 -0.00513013 -0.01549943\n",
            "  0.00604182  0.01507312  0.00122035 -0.0070696  -0.00594772]\n",
            "1.1705000009998876\n",
            "Error_max =  3.1486992005085447e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1612383   0.00156564 -0.05336929  0.02020098 -0.00513343 -0.0155032\n",
            "  0.00604397  0.01507211  0.00122082 -0.00706875 -0.00594681]\n",
            "1.1706000009998876\n",
            "Error_max =  3.1477960008150283e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16125618  0.00154799 -0.05336254  0.02020706 -0.00513672 -0.01550696\n",
            "  0.00604612  0.01507109  0.00122129 -0.00706791 -0.00594589]\n",
            "1.1707000009998876\n",
            "Error_max =  3.146892251561242e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16127406  0.00153033 -0.05335578  0.02021314 -0.00514002 -0.01551073\n",
            "  0.00604827  0.01507007  0.00122177 -0.00706706 -0.00594497]\n",
            "1.1708000009998876\n",
            "Error_max =  3.1459879531558785e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16129194  0.00151267 -0.05334902  0.02021922 -0.00514332 -0.01551449\n",
            "  0.00605042  0.01506905  0.00122224 -0.00706622 -0.00594405]\n",
            "1.1709000009998876\n",
            "Error_max =  3.14508310601822e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16130982  0.00149501 -0.05334226  0.0202253  -0.00514662 -0.01551825\n",
            "  0.00605257  0.01506803  0.00122272 -0.00706537 -0.00594313]\n",
            "1.1710000009998875\n",
            "Error_max =  3.1441777105686057e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1613277   0.00147734 -0.05333549  0.02023138 -0.00514992 -0.01552202\n",
            "  0.00605472  0.01506701  0.00122319 -0.00706453 -0.00594221]\n",
            "1.1711000009998875\n",
            "Error_max =  3.14327176721573e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16134559  0.00145967 -0.05332872  0.02023745 -0.00515322 -0.01552578\n",
            "  0.00605687  0.01506599  0.00122367 -0.00706368 -0.00594129]\n",
            "1.1712000009998875\n",
            "Error_max =  3.142365276373579e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16136347  0.001442   -0.05332195  0.02024352 -0.00515652 -0.01552954\n",
            "  0.00605902  0.01506496  0.00122415 -0.00706284 -0.00594037]\n",
            "1.1713000009998875\n",
            "Error_max =  3.141458238467788e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16138136  0.00142433 -0.05331518  0.0202496  -0.00515982 -0.0155333\n",
            "  0.00606118  0.01506394  0.00122462 -0.00706199 -0.00593945]\n",
            "1.1714000009998875\n",
            "Error_max =  3.140550653912344e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16139925  0.00140666 -0.0533084   0.02025567 -0.00516312 -0.01553706\n",
            "  0.00606333  0.01506291  0.0012251  -0.00706114 -0.00593852]\n",
            "1.1715000009998875\n",
            "Error_max =  3.1396425231180575e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16141715  0.00138898 -0.05330162  0.02026173 -0.00516642 -0.01554082\n",
            "  0.00606548  0.01506188  0.00122558 -0.0070603  -0.0059376 ]\n",
            "1.1716000009998875\n",
            "Error_max =  3.1387338465137393e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16143504  0.0013713  -0.05329484  0.0202678  -0.00516972 -0.01554458\n",
            "  0.00606764  0.01506084  0.00122606 -0.00705945 -0.00593668]\n",
            "1.1717000009998875\n",
            "Error_max =  3.1378246245038476e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16145294  0.00135362 -0.05328806  0.02027386 -0.00517302 -0.01554833\n",
            "  0.00606979  0.01505981  0.00122654 -0.00705861 -0.00593575]\n",
            "1.1718000009998875\n",
            "Error_max =  3.136914857515075e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16147084  0.00133593 -0.05328127  0.02027992 -0.00517632 -0.01555209\n",
            "  0.00607195  0.01505878  0.00122702 -0.00705776 -0.00593483]\n",
            "1.1719000009998874\n",
            "Error_max =  3.1360045459624683e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16148874  0.00131824 -0.05327448  0.02028599 -0.00517962 -0.01555584\n",
            "  0.0060741   0.01505774  0.0012275  -0.00705691 -0.0059339 ]\n",
            "1.1720000009998874\n",
            "Error_max =  3.135093690260014e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16150664  0.00130055 -0.05326769  0.02029204 -0.00518292 -0.0155596\n",
            "  0.00607626  0.0150567   0.00122798 -0.00705607 -0.00593298]\n",
            "1.1721000009998874\n",
            "Error_max =  3.134182290837582e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16152455  0.00128286 -0.05326089  0.0202981  -0.00518622 -0.01556335\n",
            "  0.00607842  0.01505566  0.00122846 -0.00705522 -0.00593205]\n",
            "1.1722000009998874\n",
            "Error_max =  3.133270348104924e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16154245  0.00126517 -0.0532541   0.02030416 -0.00518952 -0.01556711\n",
            "  0.00608057  0.01505462  0.00122894 -0.00705437 -0.00593113]\n",
            "1.1723000009998874\n",
            "Error_max =  3.1323578624834395e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16156036  0.00124747 -0.0532473   0.02031021 -0.00519282 -0.01557086\n",
            "  0.00608273  0.01505358  0.00122943 -0.00705353 -0.0059302 ]\n",
            "1.1724000009998874\n",
            "Error_max =  3.131444834383939e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16157827  0.00122977 -0.05324049  0.02031626 -0.00519611 -0.01557461\n",
            "  0.00608489  0.01505253  0.00122991 -0.00705268 -0.00592927]\n",
            "1.1725000009998874\n",
            "Error_max =  3.1305312642415855e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16159619  0.00121207 -0.05323369  0.02032231 -0.00519941 -0.01557836\n",
            "  0.00608705  0.01505149  0.00123039 -0.00705183 -0.00592834]\n",
            "1.1726000009998874\n",
            "Error_max =  3.129617152464014e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1616141   0.00119436 -0.05322688  0.02032836 -0.00520271 -0.01558211\n",
            "  0.00608921  0.01505044  0.00123088 -0.00705099 -0.00592742]\n",
            "1.1727000009998874\n",
            "Error_max =  3.1287024994757997e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16163202  0.00117665 -0.05322007  0.02033441 -0.00520601 -0.01558586\n",
            "  0.00609137  0.01504939  0.00123136 -0.00705014 -0.00592649]\n",
            "1.1728000009998873\n",
            "Error_max =  3.12778730569093e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16164994  0.00115894 -0.05321325  0.02034045 -0.00520931 -0.01558961\n",
            "  0.00609353  0.01504834  0.00123185 -0.00704929 -0.00592556]\n",
            "1.1729000009998873\n",
            "Error_max =  3.126871571546685e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16166786  0.00114123 -0.05320643  0.02034649 -0.00521261 -0.01559336\n",
            "  0.00609569  0.01504728  0.00123233 -0.00704844 -0.00592463]\n",
            "1.1730000009998873\n",
            "Error_max =  3.12595529744223e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16168578  0.00112351 -0.05319962  0.02035253 -0.00521591 -0.01559711\n",
            "  0.00609785  0.01504623  0.00123282 -0.00704759 -0.0059237 ]\n",
            "1.1731000009998873\n",
            "Error_max =  3.1250384838031987e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1617037   0.0011058  -0.05319279  0.02035857 -0.00521921 -0.01560085\n",
            "  0.00610001  0.01504517  0.0012333  -0.00704675 -0.00592276]\n",
            "1.1732000009998873\n",
            "Error_max =  3.124121131060519e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16172163  0.00108808 -0.05318597  0.02036461 -0.00522251 -0.0156046\n",
            "  0.00610217  0.01504412  0.00123379 -0.0070459  -0.00592183]\n",
            "1.1733000009998873\n",
            "Error_max =  3.1232032396292366e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16173956  0.00107035 -0.05317914  0.02037065 -0.0052258  -0.01560834\n",
            "  0.00610434  0.01504306  0.00123428 -0.00704505 -0.0059209 ]\n",
            "1.1734000009998873\n",
            "Error_max =  3.122284809927575e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16175749  0.00105263 -0.05317231  0.02037668 -0.0052291  -0.01561209\n",
            "  0.0061065   0.015042    0.00123477 -0.0070442  -0.00591997]\n",
            "1.1735000009998873\n",
            "Error_max =  3.1213658423801084e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16177542  0.0010349  -0.05316548  0.02038271 -0.0052324  -0.01561583\n",
            "  0.00610866  0.01504093  0.00123525 -0.00704335 -0.00591903]\n",
            "1.1736000009998873\n",
            "Error_max =  3.120446337415648e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16179336  0.00101717 -0.05315864  0.02038874 -0.0052357  -0.01561957\n",
            "  0.00611083  0.01503987  0.00123574 -0.0070425  -0.0059181 ]\n",
            "1.1737000009998872\n",
            "Error_max =  3.119526295443946e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16181129  0.00099944 -0.0531518   0.02039477 -0.005239   -0.01562331\n",
            "  0.00611299  0.0150388   0.00123623 -0.00704165 -0.00591717]\n",
            "1.1738000009998872\n",
            "Error_max =  3.118605716893812e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16182923  0.0009817  -0.05314496  0.0204008  -0.0052423  -0.01562706\n",
            "  0.00611516  0.01503774  0.00123672 -0.00704081 -0.00591623]\n",
            "1.1739000009998872\n",
            "Error_max =  3.117684602181352e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16184717  0.00096396 -0.05313812  0.02040682 -0.0052456  -0.0156308\n",
            "  0.00611733  0.01503667  0.00123721 -0.00703996 -0.0059153 ]\n",
            "1.1740000009998872\n",
            "Error_max =  3.1167629517406697e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16186511  0.00094622 -0.05313127  0.02041285 -0.00524889 -0.01563454\n",
            "  0.00611949  0.0150356   0.0012377  -0.00703911 -0.00591436]\n",
            "1.1741000009998872\n",
            "Error_max =  3.11584076598787e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16188306  0.00092848 -0.05312442  0.02041887 -0.00525219 -0.01563827\n",
            "  0.00612166  0.01503453  0.00123819 -0.00703826 -0.00591342]\n",
            "1.1742000009998872\n",
            "Error_max =  3.1149180453401173e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.161901    0.00091073 -0.05311757  0.02042489 -0.00525549 -0.01564201\n",
            "  0.00612383  0.01503345  0.00123869 -0.00703741 -0.00591249]\n",
            "1.1743000009998872\n",
            "Error_max =  3.1139947902315154e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16191895  0.00089299 -0.05311071  0.0204309  -0.00525879 -0.01564575\n",
            "  0.00612599  0.01503238  0.00123918 -0.00703656 -0.00591155]\n",
            "1.1744000009998872\n",
            "Error_max =  3.113071001079228e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1619369   0.00087523 -0.05310386  0.02043692 -0.00526209 -0.01564948\n",
            "  0.00612816  0.0150313   0.00123967 -0.00703571 -0.00591061]\n",
            "1.1745000009998872\n",
            "Error_max =  3.1121466783152423e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16195485  0.00085748 -0.053097    0.02044294 -0.00526539 -0.01565322\n",
            "  0.00613033  0.01503022  0.00124017 -0.00703486 -0.00590967]\n",
            "1.1746000009998872\n",
            "Error_max =  3.1112218223482514e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16197281  0.00083973 -0.05309013  0.02044895 -0.00526869 -0.01565696\n",
            "  0.0061325   0.01502914  0.00124066 -0.00703401 -0.00590873]\n",
            "1.1747000009998871\n",
            "Error_max =  3.1102964336229476e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16199076  0.00082197 -0.05308327  0.02045496 -0.00527198 -0.01566069\n",
            "  0.00613467  0.01502806  0.00124115 -0.00703316 -0.00590779]\n",
            "1.1748000009998871\n",
            "Error_max =  3.109370512539554e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16200872  0.00080421 -0.0530764   0.02046097 -0.00527528 -0.01566442\n",
            "  0.00613684  0.01502698  0.00124165 -0.00703231 -0.00590685]\n",
            "1.1749000009998871\n",
            "Error_max =  3.108444059543822e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16202668  0.00078644 -0.05306953  0.02046698 -0.00527858 -0.01566815\n",
            "  0.00613901  0.01502589  0.00124214 -0.00703146 -0.00590591]\n",
            "1.175000000999887\n",
            "Error_max =  3.107517075046562e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16204464  0.00076868 -0.05306265  0.02047298 -0.00528188 -0.01567189\n",
            "  0.00614119  0.01502481  0.00124264 -0.0070306  -0.00590497]\n",
            "1.175100000999887\n",
            "Error_max =  3.1065895594776435e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1620626   0.00075091 -0.05305578  0.02047899 -0.00528518 -0.01567562\n",
            "  0.00614336  0.01502372  0.00124314 -0.00702975 -0.00590403]\n",
            "1.175200000999887\n",
            "Error_max =  3.1056615132690535e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16208057  0.00073314 -0.0530489   0.02048499 -0.00528847 -0.01567935\n",
            "  0.00614553  0.01502263  0.00124363 -0.0070289  -0.00590309]\n",
            "1.175300000999887\n",
            "Error_max =  3.104732936835838e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16209854  0.00071537 -0.05304202  0.02049099 -0.00529177 -0.01568308\n",
            "  0.0061477   0.01502154  0.00124413 -0.00702805 -0.00590215]\n",
            "1.175400000999887\n",
            "Error_max =  3.1038038306099835e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16211651  0.00069759 -0.05303513  0.02049699 -0.00529507 -0.0156868\n",
            "  0.00614988  0.01502044  0.00124463 -0.0070272  -0.0059012 ]\n",
            "1.175500000999887\n",
            "Error_max =  3.1028741950224185e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16213448  0.00067981 -0.05302824  0.02050298 -0.00529837 -0.01569053\n",
            "  0.00615205  0.01501935  0.00124513 -0.00702635 -0.00590026]\n",
            "1.175600000999887\n",
            "Error_max =  3.10194403047866e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16215245  0.00066203 -0.05302135  0.02050898 -0.00530167 -0.01569426\n",
            "  0.00615423  0.01501825  0.00124563 -0.0070255  -0.00589932]\n",
            "1.175700000999887\n",
            "Error_max =  3.10101333743187e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16217043  0.00064425 -0.05301446  0.02051497 -0.00530497 -0.01569798\n",
            "  0.0061564   0.01501716  0.00124612 -0.00702464 -0.00589837]\n",
            "1.175800000999887\n",
            "Error_max =  3.100082116288625e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1621884   0.00062646 -0.05300756  0.02052096 -0.00530826 -0.01570171\n",
            "  0.00615858  0.01501606  0.00124662 -0.00702379 -0.00589743]\n",
            "1.175900000999887\n",
            "Error_max =  3.099150367483029e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16220638  0.00060867 -0.05300067  0.02052695 -0.00531156 -0.01570543\n",
            "  0.00616075  0.01501496  0.00124712 -0.00702294 -0.00589648]\n",
            "1.176000000999887\n",
            "Error_max =  3.098218091442834e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16222436  0.00059088 -0.05299377  0.02053294 -0.00531486 -0.01570916\n",
            "  0.00616293  0.01501386  0.00124763 -0.00702209 -0.00589553]\n",
            "1.176100000999887\n",
            "Error_max =  3.097285288591556e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16224235  0.00057309 -0.05298686  0.02053893 -0.00531816 -0.01571288\n",
            "  0.00616511  0.01501275  0.00124813 -0.00702123 -0.00589459]\n",
            "1.176200000999887\n",
            "Error_max =  3.096351959366476e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16226033  0.00055529 -0.05297996  0.02054491 -0.00532146 -0.0157166\n",
            "  0.00616728  0.01501165  0.00124863 -0.00702038 -0.00589364]\n",
            "1.176300000999887\n",
            "Error_max =  3.0954181041826403e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16227832  0.0005375  -0.05297305  0.02055089 -0.00532475 -0.01572032\n",
            "  0.00616946  0.01501054  0.00124913 -0.00701953 -0.00589269]\n",
            "1.176400000999887\n",
            "Error_max =  3.0944837234815646e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16229631  0.0005197  -0.05296613  0.02055687 -0.00532805 -0.01572404\n",
            "  0.00617164  0.01500943  0.00124963 -0.00701868 -0.00589174]\n",
            "1.176500000999887\n",
            "Error_max =  3.093548817673001e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1623143   0.00050189 -0.05295922  0.02056285 -0.00533135 -0.01572776\n",
            "  0.00617382  0.01500832  0.00125014 -0.00701782 -0.0058908 ]\n",
            "1.176600000999887\n",
            "Error_max =  3.0926133872048187e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16233229  0.00048409 -0.0529523   0.02056883 -0.00533465 -0.01573148\n",
            "  0.006176    0.01500721  0.00125064 -0.00701697 -0.00588985]\n",
            "1.176700000999887\n",
            "Error_max =  3.091677432487828e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16235028  0.00046628 -0.05294538  0.02057481 -0.00533795 -0.0157352\n",
            "  0.00617818  0.01500609  0.00125115 -0.00701612 -0.0058889 ]\n",
            "1.176800000999887\n",
            "Error_max =  3.0907409539582515e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16236828  0.00044847 -0.05293846  0.02058078 -0.00534124 -0.01573892\n",
            "  0.00618036  0.01500498  0.00125165 -0.00701526 -0.00588795]\n",
            "1.176900000999887\n",
            "Error_max =  3.0898039520576046e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16238628  0.00043065 -0.05293154  0.02058675 -0.00534454 -0.01574263\n",
            "  0.00618254  0.01500386  0.00125216 -0.00701441 -0.005887  ]\n",
            "1.1770000009998869\n",
            "Error_max =  3.088866427193522e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16240428  0.00041284 -0.05292461  0.02059272 -0.00534784 -0.01574635\n",
            "  0.00618472  0.01500275  0.00125266 -0.00701355 -0.00588604]\n",
            "1.1771000009998869\n",
            "Error_max =  3.0879283798054024e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16242228  0.00039502 -0.05291768  0.02059869 -0.00535114 -0.01575006\n",
            "  0.0061869   0.01500163  0.00125317 -0.0070127  -0.00588509]\n",
            "1.1772000009998869\n",
            "Error_max =  3.0869898103241734e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16244028  0.0003772  -0.05291074  0.02060466 -0.00535443 -0.01575378\n",
            "  0.00618909  0.0150005   0.00125367 -0.00701185 -0.00588414]\n",
            "1.1773000009998869\n",
            "Error_max =  3.0860507191797044e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16245829  0.00035938 -0.05290381  0.02061062 -0.00535773 -0.01575749\n",
            "  0.00619127  0.01499938  0.00125418 -0.00701099 -0.00588319]\n",
            "1.1774000009998868\n",
            "Error_max =  3.085111106799747e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1624763   0.00034155 -0.05289687  0.02061659 -0.00536103 -0.0157612\n",
            "  0.00619345  0.01499826  0.00125469 -0.00701014 -0.00588223]\n",
            "1.1775000009998868\n",
            "Error_max =  3.084170973616288e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16249431  0.00032372 -0.05288993  0.02062255 -0.00536433 -0.01576492\n",
            "  0.00619564  0.01499713  0.0012552  -0.00700928 -0.00588128]\n",
            "1.1776000009998868\n",
            "Error_max =  3.083230320059197e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16251232  0.00030589 -0.05288298  0.02062851 -0.00536762 -0.01576863\n",
            "  0.00619782  0.014996    0.00125571 -0.00700843 -0.00588032]\n",
            "1.1777000009998868\n",
            "Error_max =  3.0822891465572836e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16253033  0.00028806 -0.05287604  0.02063447 -0.00537092 -0.01577234\n",
            "  0.00620001  0.01499487  0.00125622 -0.00700757 -0.00587937]\n",
            "1.1778000009998868\n",
            "Error_max =  3.0813474535372414e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16254835  0.00027022 -0.05286909  0.02064042 -0.00537422 -0.01577604\n",
            "  0.00620219  0.01499374  0.00125673 -0.00700672 -0.00587841]\n",
            "1.1779000009998868\n",
            "Error_max =  3.0804052414416447e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16256637  0.00025239 -0.05286214  0.02064638 -0.00537752 -0.01577975\n",
            "  0.00620438  0.01499261  0.00125724 -0.00700586 -0.00587746]\n",
            "1.1780000009998868\n",
            "Error_max =  3.079462510696128e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16258439  0.00023454 -0.05285518  0.02065233 -0.00538082 -0.01578346\n",
            "  0.00620656  0.01499148  0.00125775 -0.00700501 -0.0058765 ]\n",
            "1.1781000009998868\n",
            "Error_max =  3.078519261725266e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16260241  0.0002167  -0.05284822  0.02065828 -0.00538411 -0.01578717\n",
            "  0.00620875  0.01499034  0.00125826 -0.00700415 -0.00587554]\n",
            "1.1782000009998868\n",
            "Error_max =  3.077575494969516e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16262043  0.00019886 -0.05284126  0.02066423 -0.00538741 -0.01579087\n",
            "  0.00621094  0.0149892   0.00125877 -0.0070033  -0.00587459]\n",
            "1.1783000009998867\n",
            "Error_max =  3.076631210860865e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16263846  0.00018101 -0.0528343   0.02067018 -0.00539071 -0.01579458\n",
            "  0.00621313  0.01498807  0.00125928 -0.00700244 -0.00587363]\n",
            "1.1784000009998867\n",
            "Error_max =  3.075686409824947e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16265648  0.00016316 -0.05282733  0.02067612 -0.00539401 -0.01579828\n",
            "  0.00621531  0.01498693  0.00125979 -0.00700158 -0.00587267]\n",
            "1.1785000009998867\n",
            "Error_max =  3.0747410923032776e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62674512e-01  1.45304606e-04 -5.28203658e-02  2.06820673e-02\n",
            " -5.39730337e-03 -1.58019858e-02  6.21750224e-03  1.49857834e-02\n",
            "  1.26030734e-03 -7.00072823e-03 -5.87171184e-03]\n",
            "1.1786000009998867\n",
            "Error_max =  3.0737952587193737e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62692543e-01  1.27449123e-04 -5.28133947e-02  2.06880095e-02\n",
            " -5.40060091e-03 -1.58056883e-02  6.21969138e-03  1.49846400e-02\n",
            "  1.26082099e-03 -6.99987192e-03 -5.87075228e-03]\n",
            "1.1787000009998867\n",
            "Error_max =  3.0728489095083984e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62710575e-01  1.09591160e-04 -5.28064210e-02  2.06939500e-02\n",
            " -5.40389844e-03 -1.58093901e-02  6.22188100e-03  1.49834950e-02\n",
            "  1.26133514e-03 -6.99901545e-03 -5.86979221e-03]\n",
            "1.1788000009998867\n",
            "Error_max =  3.071902045103397e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62728610e-01  9.17307176e-05 -5.27994446e-02  2.06998887e-02\n",
            " -5.40719596e-03 -1.58130910e-02  6.22407109e-03  1.49823484e-02\n",
            "  1.26184977e-03 -6.99815884e-03 -5.86883162e-03]\n",
            "1.1789000009998867\n",
            "Error_max =  3.070954665940592e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62746647e-01  7.38677964e-05 -5.27924655e-02  2.07058256e-02\n",
            " -5.41049346e-03 -1.58167912e-02  6.22626165e-03  1.49812003e-02\n",
            "  1.26236489e-03 -6.99730207e-03 -5.86787053e-03]\n",
            "1.1790000009998867\n",
            "Error_max =  3.070006772445617e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62764685e-01  5.60023973e-05 -5.27854837e-02  2.07117608e-02\n",
            " -5.41379095e-03 -1.58204905e-02  6.22845268e-03  1.49800506e-02\n",
            "  1.26288050e-03 -6.99644514e-03 -5.86690892e-03]\n",
            "1.1791000009998867\n",
            "Error_max =  3.0690583650642233e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62782725e-01  3.81345211e-05 -5.27784992e-02  2.07176942e-02\n",
            " -5.41708843e-03 -1.58241889e-02  6.23064418e-03  1.49788993e-02\n",
            "  1.26339660e-03 -6.99558807e-03 -5.86594680e-03]\n",
            "1.1792000009998866\n",
            "Error_max =  3.068109444222045e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62800768e-01  2.02641685e-05 -5.27715120e-02  2.07236258e-02\n",
            " -5.42038590e-03 -1.58278866e-02  6.23283615e-03  1.49777464e-02\n",
            "  1.26391319e-03 -6.99473084e-03 -5.86498417e-03]\n",
            "1.1793000009998866\n",
            "Error_max =  3.067160010347892e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62818812e-01  2.39134030e-06 -5.27645222e-02  2.07295557e-02\n",
            " -5.42368336e-03 -1.58315834e-02  6.23502858e-03  1.49765920e-02\n",
            "  1.26443027e-03 -6.99387346e-03 -5.86402104e-03]\n",
            "1.1794000009998866\n",
            "Error_max =  3.0662100638959865e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62836858e-01 -1.54839627e-05 -5.27575296e-02  2.07354839e-02\n",
            " -5.42698081e-03 -1.58352794e-02  6.23722148e-03  1.49754360e-02\n",
            "  1.26494783e-03 -6.99301593e-03 -5.86305739e-03]\n",
            "1.1795000009998866\n",
            "Error_max =  3.065259605272904e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62854906e-01 -3.33617398e-05 -5.27505344e-02  2.07414102e-02\n",
            " -5.43027825e-03 -1.58389746e-02  6.23941484e-03  1.49742784e-02\n",
            "  1.26546589e-03 -6.99215824e-03 -5.86209323e-03]\n",
            "1.1796000009998866\n",
            "Error_max =  3.0643086349339244e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62872956e-01 -5.12419901e-05 -5.27435365e-02  2.07473349e-02\n",
            " -5.43357568e-03 -1.58426690e-02  6.24160867e-03  1.49731193e-02\n",
            "  1.26598443e-03 -6.99130040e-03 -5.86112856e-03]\n",
            "1.1797000009998866\n",
            "Error_max =  3.0633571533025645e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62891008e-01 -6.91247130e-05 -5.27365359e-02  2.07532577e-02\n",
            " -5.43687310e-03 -1.58463625e-02  6.24380296e-03  1.49719586e-02\n",
            "  1.26650345e-03 -6.99044240e-03 -5.86016339e-03]\n",
            "1.1798000009998866\n",
            "Error_max =  3.0624051608182226e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62909061e-01 -8.70099076e-05 -5.27295326e-02  2.07591789e-02\n",
            " -5.44017052e-03 -1.58500552e-02  6.24599772e-03  1.49707963e-02\n",
            "  1.26702297e-03 -6.98958425e-03 -5.85919770e-03]\n",
            "1.1799000009998866\n",
            "Error_max =  3.061452657920297e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62927117e-01 -1.04897573e-04 -5.27225266e-02  2.07650982e-02\n",
            " -5.44346792e-03 -1.58537471e-02  6.24819294e-03  1.49696324e-02\n",
            "  1.26754297e-03 -6.98872595e-03 -5.85823151e-03]\n",
            "1.1800000009998866\n",
            "Error_max =  3.060499645034422e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62945174e-01 -1.22787709e-04 -5.27155179e-02  2.07710158e-02\n",
            " -5.44676532e-03 -1.58574382e-02  6.25038862e-03  1.49684670e-02\n",
            "  1.26806345e-03 -6.98786749e-03 -5.85726480e-03]\n",
            "1.1801000009998865\n",
            "Error_max =  3.0595461225989365e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62963234e-01 -1.40680314e-04 -5.27085066e-02  2.07769317e-02\n",
            " -5.45006271e-03 -1.58611284e-02  6.25258476e-03  1.49673000e-02\n",
            "  1.26858443e-03 -6.98700888e-03 -5.85629759e-03]\n",
            "1.1802000009998865\n",
            "Error_max =  3.058592091064886e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 1.62981295e-01 -1.58575388e-04 -5.27014925e-02  2.07828458e-02\n",
            " -5.45336010e-03 -1.58648178e-02  6.25478135e-03  1.49661315e-02\n",
            "  1.26910589e-03 -6.98615012e-03 -5.85532987e-03]\n",
            "1.1803000009998865\n",
            "Error_max =  3.0576375508483757e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16299936 -0.00017647 -0.05269448  0.02078876 -0.00545666 -0.01586851\n",
            "  0.00625698  0.01496496  0.00126963 -0.00698529 -0.00585436]\n",
            "1.1804000009998865\n",
            "Error_max =  3.05668250239198e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16301742 -0.00019437 -0.05268746  0.02079467 -0.00545995 -0.01587219\n",
            "  0.00625918  0.01496379  0.00127015 -0.00698443 -0.00585339]\n",
            "1.1805000009998865\n",
            "Error_max =  3.055726946129803e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16303549 -0.00021228 -0.05268043  0.02080058 -0.00546325 -0.01587588\n",
            "  0.00626137  0.01496262  0.00127067 -0.00698357 -0.00585242]\n",
            "1.1806000009998865\n",
            "Error_max =  3.0547708825023024e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16305356 -0.00023018 -0.05267341  0.02080648 -0.00546655 -0.01587957\n",
            "  0.00626357  0.01496144  0.0012712  -0.00698271 -0.00585145]\n",
            "1.1807000009998865\n",
            "Error_max =  3.0538143119457e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16307163 -0.00024809 -0.05266638  0.02081239 -0.00546985 -0.01588325\n",
            "  0.00626577  0.01496027  0.00127172 -0.00698185 -0.00585048]\n",
            "1.1808000009998865\n",
            "Error_max =  3.0528572348951585e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1630897  -0.000266   -0.05265935  0.02081829 -0.00547314 -0.01588694\n",
            "  0.00626797  0.01495909  0.00127224 -0.00698099 -0.00584951]\n",
            "1.1809000009998865\n",
            "Error_max =  3.0518996517921944e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16310778 -0.00028391 -0.05265232  0.0208242  -0.00547644 -0.01589062\n",
            "  0.00627017  0.01495791  0.00127277 -0.00698013 -0.00584854]\n",
            "1.1810000009998864\n",
            "Error_max =  3.0509415630687943e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16312585 -0.00030182 -0.05264528  0.0208301  -0.00547974 -0.0158943\n",
            "  0.00627237  0.01495673  0.0012733  -0.00697927 -0.00584757]\n",
            "1.1811000009998864\n",
            "Error_max =  3.0499829691654153e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16314393 -0.00031974 -0.05263825  0.02083599 -0.00548304 -0.01589798\n",
            "  0.00627457  0.01495554  0.00127382 -0.00697841 -0.0058466 ]\n",
            "1.1812000009998864\n",
            "Error_max =  3.0490238705172207e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16316201 -0.00033766 -0.0526312   0.02084189 -0.00548633 -0.01590167\n",
            "  0.00627677  0.01495436  0.00127435 -0.00697755 -0.00584562]\n",
            "1.1813000009998864\n",
            "Error_max =  3.0480642675636087e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16318009 -0.00035558 -0.05262416  0.02084779 -0.00548963 -0.01590535\n",
            "  0.00627897  0.01495317  0.00127487 -0.00697669 -0.00584465]\n",
            "1.1814000009998864\n",
            "Error_max =  3.0471041607439777e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16319818 -0.00037351 -0.05261711  0.02085368 -0.00549293 -0.01590903\n",
            "  0.00628118  0.01495199  0.0012754  -0.00697583 -0.00584368]\n",
            "1.1815000009998864\n",
            "Error_max =  3.046143550496667e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16321626 -0.00039144 -0.05261007  0.02085957 -0.00549623 -0.0159127\n",
            "  0.00628338  0.0149508   0.00127593 -0.00697497 -0.0058427 ]\n",
            "1.1816000009998864\n",
            "Error_max =  3.0451824372515466e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16323435 -0.00040937 -0.05260301  0.02086546 -0.00549952 -0.01591638\n",
            "  0.00628558  0.01494961  0.00127646 -0.00697411 -0.00584173]\n",
            "1.1817000009998864\n",
            "Error_max =  3.044220821462837e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16325244 -0.0004273  -0.05259596  0.02087135 -0.00550282 -0.01592006\n",
            "  0.00628778  0.01494842  0.00127699 -0.00697325 -0.00584075]\n",
            "1.1818000009998864\n",
            "Error_max =  3.0432587035625255e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16327053 -0.00044523 -0.0525889   0.02087723 -0.00550612 -0.01592373\n",
            "  0.00628999  0.01494722  0.00127752 -0.00697239 -0.00583978]\n",
            "1.1819000009998863\n",
            "Error_max =  3.0422960839836576e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16328863 -0.00046317 -0.05258184  0.02088312 -0.00550941 -0.01592741\n",
            "  0.00629219  0.01494603  0.00127804 -0.00697153 -0.0058388 ]\n",
            "1.1820000009998863\n",
            "Error_max =  3.041332963169867e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16330672 -0.00048111 -0.05257478  0.020889   -0.00551271 -0.01593108\n",
            "  0.0062944   0.01494483  0.00127858 -0.00697067 -0.00583782]\n",
            "1.1821000009998863\n",
            "Error_max =  3.0403693415594926e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16332482 -0.00049905 -0.05256772  0.02089488 -0.00551601 -0.01593476\n",
            "  0.0062966   0.01494363  0.00127911 -0.0069698  -0.00583685]\n",
            "1.1822000009998863\n",
            "Error_max =  3.03940521960358e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16334292 -0.00051699 -0.05256065  0.02090076 -0.00551931 -0.01593843\n",
            "  0.00629881  0.01494243  0.00127964 -0.00696894 -0.00583587]\n",
            "1.1823000009998863\n",
            "Error_max =  3.038440597719293e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16336102 -0.00053494 -0.05255358  0.02090664 -0.0055226  -0.0159421\n",
            "  0.00630101  0.01494123  0.00128017 -0.00696808 -0.00583489]\n",
            "1.1824000009998863\n",
            "Error_max =  3.037475476364029e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16337912 -0.00055289 -0.05254651  0.02091251 -0.0055259  -0.01594577\n",
            "  0.00630322  0.01494003  0.0012807  -0.00696722 -0.00583391]\n",
            "1.1825000009998863\n",
            "Error_max =  3.0365098559782455e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16339723 -0.00057084 -0.05253943  0.02091839 -0.0055292  -0.01594944\n",
            "  0.00630543  0.01493882  0.00128123 -0.00696636 -0.00583293]\n",
            "1.1826000009998863\n",
            "Error_max =  3.03554373699287e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16341533 -0.0005888  -0.05253235  0.02092426 -0.0055325  -0.01595311\n",
            "  0.00630764  0.01493762  0.00128177 -0.00696549 -0.00583195]\n",
            "1.1827000009998863\n",
            "Error_max =  3.0345771198589484e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16343344 -0.00060675 -0.05252527  0.02093013 -0.00553579 -0.01595678\n",
            "  0.00630984  0.01493641  0.0012823  -0.00696463 -0.00583097]\n",
            "1.1828000009998862\n",
            "Error_max =  3.033610005006349e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16345155 -0.00062471 -0.05251819  0.020936   -0.00553909 -0.01596045\n",
            "  0.00631205  0.0149352   0.00128283 -0.00696377 -0.00582999]\n",
            "1.1829000009998862\n",
            "Error_max =  3.0326423928808237e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16346966 -0.00064267 -0.0525111   0.02094186 -0.00554239 -0.01596412\n",
            "  0.00631426  0.01493399  0.00128337 -0.0069629  -0.00582901]\n",
            "1.1830000009998862\n",
            "Error_max =  3.0316742839249465e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16348778 -0.00066064 -0.05250401  0.02094773 -0.00554569 -0.01596778\n",
            "  0.00631647  0.01493278  0.0012839  -0.00696204 -0.00582803]\n",
            "1.1831000009998862\n",
            "Error_max =  3.0307056785823514e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16350589 -0.0006786  -0.05249692  0.02095359 -0.00554898 -0.01597145\n",
            "  0.00631868  0.01493156  0.00128444 -0.00696118 -0.00582705]\n",
            "1.1832000009998862\n",
            "Error_max =  3.02973657728926e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16352401 -0.00069657 -0.05248983  0.02095945 -0.00555228 -0.01597511\n",
            "  0.00632089  0.01493035  0.00128497 -0.00696031 -0.00582606]\n",
            "1.1833000009998862\n",
            "Error_max =  3.0287669804924825e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16354213 -0.00071454 -0.05248273  0.02096531 -0.00555558 -0.01597877\n",
            "  0.0063231   0.01492913  0.00128551 -0.00695945 -0.00582508]\n",
            "1.1834000009998862\n",
            "Error_max =  3.0277968886250643e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16356025 -0.00073252 -0.05247563  0.02097117 -0.00555888 -0.01598244\n",
            "  0.00632531  0.01492791  0.00128605 -0.00695859 -0.0058241 ]\n",
            "1.1835000009998862\n",
            "Error_max =  3.026826302142286e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16357838 -0.00075049 -0.05246853  0.02097703 -0.00556217 -0.0159861\n",
            "  0.00632752  0.01492669  0.00128659 -0.00695772 -0.00582311]\n",
            "1.1836000009998862\n",
            "Error_max =  3.0258552214771923e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1635965  -0.00076847 -0.05246142  0.02098288 -0.00556547 -0.01598976\n",
            "  0.00632973  0.01492547  0.00128712 -0.00695686 -0.00582213]\n",
            "1.1837000009998861\n",
            "Error_max =  3.024883647070241e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16361463 -0.00078645 -0.05245431  0.02098874 -0.00556877 -0.01599342\n",
            "  0.00633195  0.01492425  0.00128766 -0.006956   -0.00582114]\n",
            "1.1838000009998861\n",
            "Error_max =  3.02391157937883e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16363276 -0.00080444 -0.0524472   0.02099459 -0.00557206 -0.01599708\n",
            "  0.00633416  0.01492302  0.0012882  -0.00695513 -0.00582015]\n",
            "1.1839000009998861\n",
            "Error_max =  3.022939018830711e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16365089 -0.00082242 -0.05244009  0.02100044 -0.00557536 -0.01600074\n",
            "  0.00633637  0.0149218   0.00128874 -0.00695427 -0.00581917]\n",
            "1.1840000009998861\n",
            "Error_max =  3.0219659658758695e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16366902 -0.00084041 -0.05243297  0.02100628 -0.00557866 -0.01600439\n",
            "  0.00633858  0.01492057  0.00128928 -0.0069534  -0.00581818]\n",
            "1.184100000999886\n",
            "Error_max =  3.0209924209484105e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16368715 -0.0008584  -0.05242586  0.02101213 -0.00558196 -0.01600805\n",
            "  0.0063408   0.01491934  0.00128982 -0.00695254 -0.00581719]\n",
            "1.184200000999886\n",
            "Error_max =  3.0200183845078493e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16370529 -0.00087639 -0.05241874  0.02101797 -0.00558525 -0.0160117\n",
            "  0.00634301  0.01491811  0.00129036 -0.00695167 -0.00581621]\n",
            "1.184300000999886\n",
            "Error_max =  3.019043856985114e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16372343 -0.00089439 -0.05241161  0.02102382 -0.00558855 -0.01601536\n",
            "  0.00634523  0.01491688  0.0012909  -0.00695081 -0.00581522]\n",
            "1.184400000999886\n",
            "Error_max =  3.0180688388248964e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16374157 -0.00091239 -0.05240449  0.02102966 -0.00559185 -0.01601901\n",
            "  0.00634744  0.01491564  0.00129144 -0.00694994 -0.00581423]\n",
            "1.184500000999886\n",
            "Error_max =  3.0170933304761245e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16375971 -0.00093039 -0.05239736  0.0210355  -0.00559515 -0.01602267\n",
            "  0.00634966  0.01491441  0.00129199 -0.00694908 -0.00581324]\n",
            "1.184600000999886\n",
            "Error_max =  3.0161173323877255e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16377785 -0.00094839 -0.05239022  0.02104133 -0.00559844 -0.01602632\n",
            "  0.00635187  0.01491317  0.00129253 -0.00694821 -0.00581225]\n",
            "1.184700000999886\n",
            "Error_max =  3.015140844989569e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.163796   -0.0009664  -0.05238309  0.02104717 -0.00560174 -0.01602997\n",
            "  0.00635409  0.01491193  0.00129307 -0.00694734 -0.00581126]\n",
            "1.184800000999886\n",
            "Error_max =  3.0141638687411696e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16381415 -0.0009844  -0.05237595  0.021053   -0.00560504 -0.01603362\n",
            "  0.00635631  0.01491069  0.00129361 -0.00694648 -0.00581027]\n",
            "1.184900000999886\n",
            "Error_max =  3.0131864040755736e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1638323  -0.00100241 -0.05236881  0.02105883 -0.00560834 -0.01603727\n",
            "  0.00635852  0.01490945  0.00129416 -0.00694561 -0.00580928]\n",
            "1.185000000999886\n",
            "Error_max =  3.0122084514406494e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16385045 -0.00102043 -0.05236167  0.02106466 -0.00561163 -0.01604092\n",
            "  0.00636074  0.01490821  0.0012947  -0.00694475 -0.00580828]\n",
            "1.185100000999886\n",
            "Error_max =  3.0112300112895597e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1638686  -0.00103844 -0.05235453  0.02107049 -0.00561493 -0.01604457\n",
            "  0.00636296  0.01490696  0.00129525 -0.00694388 -0.00580729]\n",
            "1.185200000999886\n",
            "Error_max =  3.010251084056409e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16388676 -0.00105646 -0.05234738  0.02107632 -0.00561823 -0.01604821\n",
            "  0.00636518  0.01490572  0.00129579 -0.00694301 -0.0058063 ]\n",
            "1.185300000999886\n",
            "Error_max =  3.009271670200712e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16390491 -0.00107448 -0.05234023  0.02108214 -0.00562153 -0.01605186\n",
            "  0.0063674   0.01490447  0.00129634 -0.00694215 -0.00580531]\n",
            "1.185400000999886\n",
            "Error_max =  3.008291770145986e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16392307 -0.0010925  -0.05233308  0.02108797 -0.00562482 -0.0160555\n",
            "  0.00636962  0.01490322  0.00129689 -0.00694128 -0.00580431]\n",
            "1.185500000999886\n",
            "Error_max =  3.007311384363393e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16394123 -0.00111053 -0.05232592  0.02109379 -0.00562812 -0.01605915\n",
            "  0.00637184  0.01490197  0.00129743 -0.00694041 -0.00580332]\n",
            "1.185600000999886\n",
            "Error_max =  3.006330513276449e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16395939 -0.00112855 -0.05231876  0.02109961 -0.00563142 -0.01606279\n",
            "  0.00637406  0.01490072  0.00129798 -0.00693954 -0.00580232]\n",
            "1.185700000999886\n",
            "Error_max =  3.005349157348905e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16397756 -0.00114658 -0.0523116   0.02110543 -0.00563472 -0.01606643\n",
            "  0.00637628  0.01489946  0.00129853 -0.00693868 -0.00580133]\n",
            "1.185800000999886\n",
            "Error_max =  3.0043673170191e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16399572 -0.00116462 -0.05230444  0.02111124 -0.00563801 -0.01607008\n",
            "  0.0063785   0.01489821  0.00129908 -0.00693781 -0.00580033]\n",
            "1.185900000999886\n",
            "Error_max =  3.003384992734903e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16401389 -0.00118265 -0.05229727  0.02111706 -0.00564131 -0.01607372\n",
            "  0.00638072  0.01489695  0.00129963 -0.00693694 -0.00579933]\n",
            "1.186000000999886\n",
            "Error_max =  3.0024021849473595e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16403206 -0.00120069 -0.0522901   0.02112287 -0.00564461 -0.01607736\n",
            "  0.00638294  0.01489569  0.00130017 -0.00693607 -0.00579834]\n",
            "1.1861000009998859\n",
            "Error_max =  3.001418894090573e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16405023 -0.00121873 -0.05228293  0.02112868 -0.00564791 -0.016081\n",
            "  0.00638516  0.01489443  0.00130072 -0.00693521 -0.00579734]\n",
            "1.1862000009998859\n",
            "Error_max =  3.0004351206187656e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16406841 -0.00123677 -0.05227576  0.02113449 -0.00565121 -0.01608463\n",
            "  0.00638739  0.01489317  0.00130127 -0.00693434 -0.00579634]\n",
            "1.1863000009998859\n",
            "Error_max =  2.9994508649903936e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16408658 -0.00125481 -0.05226858  0.0211403  -0.0056545  -0.01608827\n",
            "  0.00638961  0.01489191  0.00130183 -0.00693347 -0.00579534]\n",
            "1.1864000009998859\n",
            "Error_max =  2.998466127637444e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16410476 -0.00127286 -0.0522614   0.0211461  -0.0056578  -0.01609191\n",
            "  0.00639183  0.01489064  0.00130238 -0.0069326  -0.00579434]\n",
            "1.1865000009998858\n",
            "Error_max =  2.997480909017314e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16412294 -0.00129091 -0.05225422  0.02115191 -0.0056611  -0.01609554\n",
            "  0.00639406  0.01488938  0.00130293 -0.00693173 -0.00579334]\n",
            "1.1866000009998858\n",
            "Error_max =  2.996495209566226e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16414112 -0.00130896 -0.05224703  0.02115771 -0.0056644  -0.01609918\n",
            "  0.00639628  0.01488811  0.00130348 -0.00693086 -0.00579234]\n",
            "1.1867000009998858\n",
            "Error_max =  2.9955090297458133e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1641593  -0.00132701 -0.05223985  0.02116351 -0.00566769 -0.01610281\n",
            "  0.00639851  0.01488684  0.00130403 -0.00692999 -0.00579134]\n",
            "1.1868000009998858\n",
            "Error_max =  2.994522369999709e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16417749 -0.00134507 -0.05223266  0.02116931 -0.00567099 -0.01610644\n",
            "  0.00640073  0.01488557  0.00130459 -0.00692912 -0.00579034]\n",
            "1.1869000009998858\n",
            "Error_max =  2.9935352307726053e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16419567 -0.00136313 -0.05222546  0.0211751  -0.00567429 -0.01611008\n",
            "  0.00640296  0.0148843   0.00130514 -0.00692825 -0.00578934]\n",
            "1.1870000009998858\n",
            "Error_max =  2.99254761251343e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16421386 -0.00138119 -0.05221827  0.0211809  -0.00567759 -0.01611371\n",
            "  0.00640518  0.01488302  0.00130569 -0.00692739 -0.00578834]\n",
            "1.1871000009998858\n",
            "Error_max =  2.991559515678522e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16423205 -0.00139925 -0.05221107  0.02118669 -0.00568089 -0.01611734\n",
            "  0.00640741  0.01488175  0.00130625 -0.00692652 -0.00578734]\n",
            "1.1872000009998858\n",
            "Error_max =  2.990570940703044e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16425024 -0.00141732 -0.05220387  0.02119249 -0.00568418 -0.01612097\n",
            "  0.00640964  0.01488047  0.0013068  -0.00692565 -0.00578633]\n",
            "1.1873000009998858\n",
            "Error_max =  2.9895818880549823e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16426844 -0.00143539 -0.05219666  0.02119828 -0.00568748 -0.0161246\n",
            "  0.00641186  0.01487919  0.00130736 -0.00692478 -0.00578533]\n",
            "1.1874000009998857\n",
            "Error_max =  2.9885923581620883e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16428663 -0.00145346 -0.05218946  0.02120406 -0.00569078 -0.01612822\n",
            "  0.00641409  0.01487791  0.00130791 -0.00692391 -0.00578433]\n",
            "1.1875000009998857\n",
            "Error_max =  2.9876023515050533e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16430483 -0.00147153 -0.05218225  0.02120985 -0.00569408 -0.01613185\n",
            "  0.00641632  0.01487663  0.00130847 -0.00692303 -0.00578332]\n",
            "1.1876000009998857\n",
            "Error_max =  2.9866118684872766e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16432303 -0.00148961 -0.05217504  0.02121564 -0.00569738 -0.01613548\n",
            "  0.00641855  0.01487535  0.00130903 -0.00692216 -0.00578232]\n",
            "1.1877000009998857\n",
            "Error_max =  2.9856209095947435e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16434123 -0.00150768 -0.05216782  0.02122142 -0.00570067 -0.0161391\n",
            "  0.00642078  0.01487406  0.00130958 -0.00692129 -0.00578131]\n",
            "1.1878000009998857\n",
            "Error_max =  2.984629475267911e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16435943 -0.00152577 -0.05216061  0.0212272  -0.00570397 -0.01614273\n",
            "  0.006423    0.01487278  0.00131014 -0.00692042 -0.00578031]\n",
            "1.1879000009998857\n",
            "Error_max =  2.983637565955707e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16437764 -0.00154385 -0.05215339  0.02123298 -0.00570727 -0.01614635\n",
            "  0.00642523  0.01487149  0.0013107  -0.00691955 -0.0057793 ]\n",
            "1.1880000009998857\n",
            "Error_max =  2.9826451821102344e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16439584 -0.00156193 -0.05214617  0.02123876 -0.00571057 -0.01614997\n",
            "  0.00642746  0.0148702   0.00131126 -0.00691868 -0.00577829]\n",
            "1.1881000009998857\n",
            "Error_max =  2.9816523241804214e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16441405 -0.00158002 -0.05213894  0.02124453 -0.00571387 -0.01615359\n",
            "  0.00642969  0.01486891  0.00131182 -0.00691781 -0.00577729]\n",
            "1.1882000009998857\n",
            "Error_max =  2.9806589926194305e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16443226 -0.00159811 -0.05213172  0.02125031 -0.00571716 -0.01615721\n",
            "  0.00643192  0.01486762  0.00131238 -0.00691694 -0.00577628]\n",
            "1.1883000009998856\n",
            "Error_max =  2.9796651878687776e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16445047 -0.0016162  -0.05212449  0.02125608 -0.00572046 -0.01616083\n",
            "  0.00643416  0.01486632  0.00131294 -0.00691607 -0.00577527]\n",
            "1.1884000009998856\n",
            "Error_max =  2.9786709103953896e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16446869 -0.0016343  -0.05211725  0.02126185 -0.00572376 -0.01616445\n",
            "  0.00643639  0.01486503  0.0013135  -0.00691519 -0.00577426]\n",
            "1.1885000009998856\n",
            "Error_max =  2.977676160636547e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1644869  -0.0016524  -0.05211002  0.02126762 -0.00572706 -0.01616807\n",
            "  0.00643862  0.01486373  0.00131406 -0.00691432 -0.00577325]\n",
            "1.1886000009998856\n",
            "Error_max =  2.9766809390485894e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16450512 -0.0016705  -0.05210278  0.02127339 -0.00573036 -0.01617169\n",
            "  0.00644085  0.01486243  0.00131462 -0.00691345 -0.00577224]\n",
            "1.1887000009998856\n",
            "Error_max =  2.975685246089973e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16452334 -0.0016886  -0.05209554  0.02127915 -0.00573365 -0.0161753\n",
            "  0.00644308  0.01486113  0.00131518 -0.00691258 -0.00577123]\n",
            "1.1888000009998856\n",
            "Error_max =  2.974689082195861e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16454156 -0.0017067  -0.0520883   0.02128492 -0.00573695 -0.01617892\n",
            "  0.00644532  0.01485983  0.00131574 -0.0069117  -0.00577022]\n",
            "1.1889000009998856\n",
            "Error_max =  2.973692447834239e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16455978 -0.00172481 -0.05208105  0.02129068 -0.00574025 -0.01618253\n",
            "  0.00644755  0.01485853  0.00131631 -0.00691083 -0.00576921]\n",
            "1.1890000009998856\n",
            "Error_max =  2.972695343449799e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16457801 -0.00174292 -0.0520738   0.02129644 -0.00574355 -0.01618614\n",
            "  0.00644978  0.01485723  0.00131687 -0.00690996 -0.0057682 ]\n",
            "1.1891000009998856\n",
            "Error_max =  2.971697769494646e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16459623 -0.00176103 -0.05206655  0.0213022  -0.00574685 -0.01618976\n",
            "  0.00645202  0.01485592  0.00131743 -0.00690909 -0.00576719]\n",
            "1.1892000009998855\n",
            "Error_max =  2.970699726428294e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16461446 -0.00177914 -0.0520593   0.02130796 -0.00575015 -0.01619337\n",
            "  0.00645425  0.01485461  0.001318   -0.00690821 -0.00576617]\n",
            "1.1893000009998855\n",
            "Error_max =  2.969701214684848e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16463269 -0.00179726 -0.05205204  0.02131371 -0.00575345 -0.01619698\n",
            "  0.00645649  0.0148533   0.00131856 -0.00690734 -0.00576516]\n",
            "1.1894000009998855\n",
            "Error_max =  2.9687022347397057e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16465092 -0.00181538 -0.05204478  0.02131947 -0.00575674 -0.01620059\n",
            "  0.00645872  0.01485199  0.00131913 -0.00690647 -0.00576415]\n",
            "1.1895000009998855\n",
            "Error_max =  2.9677027870343824e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16466916 -0.0018335  -0.05203752  0.02132522 -0.00576004 -0.0162042\n",
            "  0.00646096  0.01485068  0.00131969 -0.00690559 -0.00576313]\n",
            "1.1896000009998855\n",
            "Error_max =  2.966702872020982e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16468739 -0.00185162 -0.05203026  0.02133097 -0.00576334 -0.01620781\n",
            "  0.0064632   0.01484937  0.00132026 -0.00690472 -0.00576212]\n",
            "1.1897000009998855\n",
            "Error_max =  2.9657024901558437e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16470563 -0.00186975 -0.05202299  0.02133672 -0.00576664 -0.01621141\n",
            "  0.00646543  0.01484805  0.00132083 -0.00690384 -0.0057611 ]\n",
            "1.1898000009998855\n",
            "Error_max =  2.9647016418953063e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16472387 -0.00188788 -0.05201572  0.02134246 -0.00576994 -0.01621502\n",
            "  0.00646767  0.01484674  0.00132139 -0.00690297 -0.00576008]\n",
            "1.1899000009998855\n",
            "Error_max =  2.9637003276872386e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16474211 -0.00190601 -0.05200845  0.02134821 -0.00577324 -0.01621862\n",
            "  0.00646991  0.01484542  0.00132196 -0.0069021  -0.00575907]\n",
            "1.1900000009998855\n",
            "Error_max =  2.9626985479879796e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16476035 -0.00192414 -0.05200117  0.02135395 -0.00577654 -0.01622223\n",
            "  0.00647214  0.0148441   0.00132253 -0.00690122 -0.00575805]\n",
            "1.1901000009998854\n",
            "Error_max =  2.961696303249633e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1647786  -0.00194228 -0.0519939   0.02135969 -0.00577983 -0.01622583\n",
            "  0.00647438  0.01484278  0.0013231  -0.00690035 -0.00575703]\n",
            "1.1902000009998854\n",
            "Error_max =  2.9606935939253617e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16479684 -0.00196042 -0.05198662  0.02136543 -0.00578313 -0.01622943\n",
            "  0.00647662  0.01484146  0.00132367 -0.00689947 -0.00575602]\n",
            "1.1903000009998854\n",
            "Error_max =  2.959690420474681e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16481509 -0.00197856 -0.05197933  0.02137117 -0.00578643 -0.01623304\n",
            "  0.00647886  0.01484013  0.00132424 -0.0068986  -0.005755  ]\n",
            "1.1904000009998854\n",
            "Error_max =  2.9586867833496943e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16483334 -0.0019967  -0.05197205  0.02137691 -0.00578973 -0.01623664\n",
            "  0.0064811   0.01483881  0.00132481 -0.00689772 -0.00575398]\n",
            "1.1905000009998854\n",
            "Error_max =  2.957682683002506e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16485159 -0.00201484 -0.05196476  0.02138264 -0.00579303 -0.01624024\n",
            "  0.00648334  0.01483748  0.00132538 -0.00689685 -0.00575296]\n",
            "1.1906000009998854\n",
            "Error_max =  2.956678119884161e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16486985 -0.00203299 -0.05195747  0.02138837 -0.00579633 -0.01624384\n",
            "  0.00648558  0.01483615  0.00132595 -0.00689597 -0.00575194]\n",
            "1.1907000009998854\n",
            "Error_max =  2.955673094465821e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1648881  -0.00205114 -0.05195018  0.02139411 -0.00579963 -0.01624743\n",
            "  0.00648782  0.01483482  0.00132652 -0.00689509 -0.00575092]\n",
            "1.1908000009998854\n",
            "Error_max =  2.9546676071890025e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16490636 -0.00206929 -0.05194288  0.02139984 -0.00580293 -0.01625103\n",
            "  0.00649006  0.01483349  0.00132709 -0.00689422 -0.0057499 ]\n",
            "1.1909000009998854\n",
            "Error_max =  2.953661658510044e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16492462 -0.00208745 -0.05193558  0.02140556 -0.00580622 -0.01625463\n",
            "  0.0064923   0.01483216  0.00132766 -0.00689334 -0.00574888]\n",
            "1.1910000009998853\n",
            "Error_max =  2.952655248885285e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16494288 -0.00210561 -0.05192828  0.02141129 -0.00580952 -0.01625822\n",
            "  0.00649454  0.01483082  0.00132824 -0.00689247 -0.00574786]\n",
            "1.1911000009998853\n",
            "Error_max =  2.9516483787742404e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16496114 -0.00212376 -0.05192098  0.02141701 -0.00581282 -0.01626182\n",
            "  0.00649678  0.01482949  0.00132881 -0.00689159 -0.00574683]\n",
            "1.1912000009998853\n",
            "Error_max =  2.9506410486279555e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16497941 -0.00214193 -0.05191367  0.02142274 -0.00581612 -0.01626541\n",
            "  0.00649902  0.01482815  0.00132938 -0.00689071 -0.00574581]\n",
            "1.1913000009998853\n",
            "Error_max =  2.9496332588964165e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16499767 -0.00216009 -0.05190636  0.02142846 -0.00581942 -0.016269\n",
            "  0.00650127  0.01482681  0.00132996 -0.00688984 -0.00574479]\n",
            "1.1914000009998853\n",
            "Error_max =  2.948625010058197e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16501594 -0.00217826 -0.05189905  0.02143417 -0.00582272 -0.01627259\n",
            "  0.00650351  0.01482547  0.00133053 -0.00688896 -0.00574377]\n",
            "1.1915000009998853\n",
            "Error_max =  2.9476163025378723e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16503421 -0.00219643 -0.05189174  0.02143989 -0.00582602 -0.01627618\n",
            "  0.00650575  0.01482413  0.0013311  -0.00688808 -0.00574274]\n",
            "1.1916000009998853\n",
            "Error_max =  2.9466071368203687e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16505248 -0.0022146  -0.05188442  0.02144561 -0.00582932 -0.01627977\n",
            "  0.006508    0.01482278  0.00133168 -0.00688721 -0.00574172]\n",
            "1.1917000009998853\n",
            "Error_max =  2.9455975133514373e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16507075 -0.00223277 -0.0518771   0.02145132 -0.00583262 -0.01628336\n",
            "  0.00651024  0.01482144  0.00133226 -0.00688633 -0.00574069]\n",
            "1.1918000009998853\n",
            "Error_max =  2.9445874325800057e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16508903 -0.00225095 -0.05186978  0.02145703 -0.00583592 -0.01628695\n",
            "  0.00651248  0.01482009  0.00133283 -0.00688545 -0.00573967]\n",
            "1.1919000009998852\n",
            "Error_max =  2.943576894971942e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16510731 -0.00226913 -0.05186245  0.02146274 -0.00583922 -0.01629054\n",
            "  0.00651473  0.01481874  0.00133341 -0.00688457 -0.00573864]\n",
            "1.1920000009998852\n",
            "Error_max =  2.9425659009846436e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16512558 -0.00228731 -0.05185513  0.02146845 -0.00584252 -0.01629412\n",
            "  0.00651697  0.01481739  0.00133399 -0.0068837  -0.00573761]\n",
            "1.1921000009998852\n",
            "Error_max =  2.941554451063862e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16514387 -0.00230549 -0.0518478   0.02147416 -0.00584582 -0.01629771\n",
            "  0.00651922  0.01481604  0.00133456 -0.00688282 -0.00573659]\n",
            "1.1922000009998852\n",
            "Error_max =  2.9405425456797004e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16516215 -0.00232368 -0.05184046  0.02147986 -0.00584911 -0.01630129\n",
            "  0.00652146  0.01481469  0.00133514 -0.00688194 -0.00573556]\n",
            "1.1923000009998852\n",
            "Error_max =  2.9395301852906154e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16518043 -0.00234186 -0.05183313  0.02148557 -0.00585241 -0.01630488\n",
            "  0.00652371  0.01481334  0.00133572 -0.00688106 -0.00573453]\n",
            "1.1924000009998852\n",
            "Error_max =  2.938517370343417e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16519872 -0.00236005 -0.05182579  0.02149127 -0.00585571 -0.01630846\n",
            "  0.00652596  0.01481198  0.0013363  -0.00688018 -0.0057335 ]\n",
            "1.1925000009998852\n",
            "Error_max =  2.937504101312443e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.165217   -0.00237825 -0.05181845  0.02149697 -0.00585901 -0.01631204\n",
            "  0.0065282   0.01481062  0.00133688 -0.0068793  -0.00573247]\n",
            "1.1926000009998852\n",
            "Error_max =  2.936490378634975e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16523529 -0.00239644 -0.05181111  0.02150267 -0.00586231 -0.01631562\n",
            "  0.00653045  0.01480926  0.00133746 -0.00687842 -0.00573144]\n",
            "1.1927000009998852\n",
            "Error_max =  2.93547620278641e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16525359 -0.00241464 -0.05180376  0.02150836 -0.00586561 -0.0163192\n",
            "  0.0065327   0.0148079   0.00133804 -0.00687754 -0.00573041]\n",
            "1.1928000009998851\n",
            "Error_max =  2.934461574210381e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16527188 -0.00243284 -0.05179641  0.02151406 -0.00586891 -0.01632278\n",
            "  0.00653495  0.01480654  0.00133862 -0.00687667 -0.00572938]\n",
            "1.1929000009998851\n",
            "Error_max =  2.933446493376992e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16529017 -0.00245104 -0.05178906  0.02151975 -0.00587221 -0.01632636\n",
            "  0.00653719  0.01480518  0.0013392  -0.00687579 -0.00572835]\n",
            "1.1930000009998851\n",
            "Error_max =  2.932430960740464e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16530847 -0.00246925 -0.05178171  0.02152544 -0.00587551 -0.01632993\n",
            "  0.00653944  0.01480382  0.00133978 -0.00687491 -0.00572732]\n",
            "1.1931000009998851\n",
            "Error_max =  2.931414976758195e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16532677 -0.00248745 -0.05177435  0.02153113 -0.00587881 -0.01633351\n",
            "  0.00654169  0.01480245  0.00134037 -0.00687403 -0.00572629]\n",
            "1.193200000999885\n",
            "Error_max =  2.9303985418992293e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16534507 -0.00250566 -0.05176699  0.02153682 -0.00588211 -0.01633708\n",
            "  0.00654394  0.01480108  0.00134095 -0.00687315 -0.00572526]\n",
            "1.193300000999885\n",
            "Error_max =  2.929381656604024e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16536337 -0.00252387 -0.05175963  0.02154251 -0.00588541 -0.01634066\n",
            "  0.00654619  0.01479971  0.00134153 -0.00687227 -0.00572422]\n",
            "1.193400000999885\n",
            "Error_max =  2.928364321345859e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16538167 -0.00254209 -0.05175227  0.02154819 -0.00588871 -0.01634423\n",
            "  0.00654844  0.01479834  0.00134211 -0.00687139 -0.00572319]\n",
            "1.193500000999885\n",
            "Error_max =  2.927346536581073e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16539998 -0.0025603  -0.0517449   0.02155388 -0.00589201 -0.0163478\n",
            "  0.00655069  0.01479697  0.0013427  -0.00687051 -0.00572216]\n",
            "1.193600000999885\n",
            "Error_max =  2.9263283027670644e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16541829 -0.00257852 -0.05173753  0.02155956 -0.00589531 -0.01635138\n",
            "  0.00655294  0.0147956   0.00134328 -0.00686962 -0.00572112]\n",
            "1.193700000999885\n",
            "Error_max =  2.9253096203749945e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16543659 -0.00259674 -0.05173016  0.02156524 -0.00589861 -0.01635495\n",
            "  0.00655519  0.01479422  0.00134387 -0.00686874 -0.00572009]\n",
            "1.193800000999885\n",
            "Error_max =  2.9242904898474385e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16545491 -0.00261497 -0.05172278  0.02157091 -0.00590191 -0.01635851\n",
            "  0.00655744  0.01479285  0.00134445 -0.00686786 -0.00571905]\n",
            "1.193900000999885\n",
            "Error_max =  2.923270911647088e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16547322 -0.00263319 -0.05171541  0.02157659 -0.00590521 -0.01636208\n",
            "  0.00655969  0.01479147  0.00134504 -0.00686698 -0.00571802]\n",
            "1.194000000999885\n",
            "Error_max =  2.922250886239811e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16549153 -0.00265142 -0.05170803  0.02158226 -0.00590851 -0.01636565\n",
            "  0.00656195  0.01479009  0.00134563 -0.0068661  -0.00571698]\n",
            "1.194100000999885\n",
            "Error_max =  2.921230414094652e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16550985 -0.00266965 -0.05170064  0.02158794 -0.00591181 -0.01636922\n",
            "  0.0065642   0.01478871  0.00134621 -0.00686522 -0.00571594]\n",
            "1.194200000999885\n",
            "Error_max =  2.920209495656304e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16552817 -0.00268789 -0.05169326  0.02159361 -0.00591511 -0.01637278\n",
            "  0.00656645  0.01478732  0.0013468  -0.00686434 -0.00571491]\n",
            "1.194300000999885\n",
            "Error_max =  2.9191881313874576e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16554649 -0.00270612 -0.05168587  0.02159928 -0.00591841 -0.01637635\n",
            "  0.0065687   0.01478594  0.00134739 -0.00686346 -0.00571387]\n",
            "1.194400000999885\n",
            "Error_max =  2.9181663217645696e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16556481 -0.00272436 -0.05167848  0.02160494 -0.00592171 -0.01637991\n",
            "  0.00657096  0.01478456  0.00134797 -0.00686257 -0.00571283]\n",
            "1.194500000999885\n",
            "Error_max =  2.917144067227038e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16558313 -0.0027426  -0.05167109  0.02161061 -0.00592501 -0.01638347\n",
            "  0.00657321  0.01478317  0.00134856 -0.00686169 -0.00571179]\n",
            "1.194600000999885\n",
            "Error_max =  2.916121368251319e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16560145 -0.00276084 -0.05166369  0.02161627 -0.00592832 -0.01638704\n",
            "  0.00657547  0.01478178  0.00134915 -0.00686081 -0.00571075]\n",
            "1.194700000999885\n",
            "Error_max =  2.915098225293752e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16561978 -0.00277909 -0.0516563   0.02162193 -0.00593162 -0.0163906\n",
            "  0.00657772  0.01478039  0.00134974 -0.00685993 -0.00570971]\n",
            "1.194800000999885\n",
            "Error_max =  2.914074638815969e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16563811 -0.00279733 -0.05164889  0.02162759 -0.00593492 -0.01639416\n",
            "  0.00657998  0.014779    0.00135033 -0.00685904 -0.00570867]\n",
            "1.194900000999885\n",
            "Error_max =  2.91305060927431e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16565644 -0.00281558 -0.05164149  0.02163325 -0.00593822 -0.01639772\n",
            "  0.00658223  0.01477761  0.00135092 -0.00685816 -0.00570763]\n",
            "1.195000000999885\n",
            "Error_max =  2.9120261371399363e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16567477 -0.00283383 -0.05163409  0.02163891 -0.00594152 -0.01640127\n",
            "  0.00658449  0.01477621  0.00135151 -0.00685728 -0.00570659]\n",
            "1.195100000999885\n",
            "Error_max =  2.9110012228670697e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16569311 -0.00285209 -0.05162668  0.02164457 -0.00594482 -0.01640483\n",
            "  0.00658674  0.01477482  0.0013521  -0.00685639 -0.00570555]\n",
            "1.1952000009998849\n",
            "Error_max =  2.909975866926872e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16571144 -0.00287034 -0.05161927  0.02165022 -0.00594812 -0.01640839\n",
            "  0.006589    0.01477342  0.0013527  -0.00685551 -0.00570451]\n",
            "1.1953000009998849\n",
            "Error_max =  2.9089500697629773e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16572978 -0.0028886  -0.05161185  0.02165587 -0.00595142 -0.01641194\n",
            "  0.00659125  0.01477202  0.00135329 -0.00685463 -0.00570346]\n",
            "1.1954000009998849\n",
            "Error_max =  2.9079238318634877e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16574812 -0.00290686 -0.05160444  0.02166152 -0.00595472 -0.0164155\n",
            "  0.00659351  0.01477062  0.00135388 -0.00685374 -0.00570242]\n",
            "1.1955000009998848\n",
            "Error_max =  2.906897153667802e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16576646 -0.00292513 -0.05159702  0.02166717 -0.00595802 -0.01641905\n",
            "  0.00659577  0.01476922  0.00135447 -0.00685286 -0.00570138]\n",
            "1.1956000009998848\n",
            "Error_max =  2.9058700356576697e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1657848  -0.00294339 -0.0515896   0.02167282 -0.00596132 -0.0164226\n",
            "  0.00659802  0.01476781  0.00135507 -0.00685197 -0.00570033]\n",
            "1.1957000009998848\n",
            "Error_max =  2.9048424782777834e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16580314 -0.00296166 -0.05158217  0.02167846 -0.00596463 -0.01642615\n",
            "  0.00660028  0.01476641  0.00135566 -0.00685109 -0.00569929]\n",
            "1.1958000009998848\n",
            "Error_max =  2.903814482004599e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16582149 -0.00297993 -0.05157474  0.0216841  -0.00596793 -0.0164297\n",
            "  0.00660254  0.014765    0.00135626 -0.00685021 -0.00569824]\n",
            "1.1959000009998848\n",
            "Error_max =  2.9027860472976324e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16583984 -0.0029982  -0.05156731  0.02168975 -0.00597123 -0.01643325\n",
            "  0.0066048   0.0147636   0.00135685 -0.00684932 -0.0056972 ]\n",
            "1.1960000009998848\n",
            "Error_max =  2.901757174612163e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16585819 -0.00301648 -0.05155988  0.02169539 -0.00597453 -0.0164368\n",
            "  0.00660706  0.01476219  0.00135745 -0.00684844 -0.00569615]\n",
            "1.1961000009998848\n",
            "Error_max =  2.900727864421471e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16587654 -0.00303476 -0.05155245  0.02170102 -0.00597783 -0.01644035\n",
            "  0.00660932  0.01476078  0.00135804 -0.00684755 -0.0056951 ]\n",
            "1.1962000009998848\n",
            "Error_max =  2.899698117189307e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16589489 -0.00305304 -0.05154501  0.02170666 -0.00598113 -0.0164439\n",
            "  0.00661158  0.01475936  0.00135864 -0.00684667 -0.00569406]\n",
            "1.1963000009998848\n",
            "Error_max =  2.898667933369892e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16591325 -0.00307132 -0.05153757  0.02171229 -0.00598443 -0.01644744\n",
            "  0.00661384  0.01475795  0.00135923 -0.00684578 -0.00569301]\n",
            "1.1964000009998847\n",
            "Error_max =  2.897637313440741e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1659316  -0.0030896  -0.05153013  0.02171793 -0.00598774 -0.01645099\n",
            "  0.0066161   0.01475654  0.00135983 -0.00684489 -0.00569196]\n",
            "1.1965000009998847\n",
            "Error_max =  2.8966062578507816e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16594996 -0.00310789 -0.05152268  0.02172356 -0.00599104 -0.01645453\n",
            "  0.00661836  0.01475512  0.00136043 -0.00684401 -0.00569091]\n",
            "1.1966000009998847\n",
            "Error_max =  2.895574767073293e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16596832 -0.00312618 -0.05151524  0.02172919 -0.00599434 -0.01645807\n",
            "  0.00662062  0.0147537   0.00136103 -0.00684312 -0.00568987]\n",
            "1.1967000009998847\n",
            "Error_max =  2.894542841575203e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16598668 -0.00314447 -0.05150779  0.02173482 -0.00599764 -0.01646161\n",
            "  0.00662288  0.01475228  0.00136162 -0.00684224 -0.00568882]\n",
            "1.1968000009998847\n",
            "Error_max =  2.8935104818096734e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16600505 -0.00316277 -0.05150033  0.02174044 -0.00600094 -0.01646516\n",
            "  0.00662514  0.01475086  0.00136222 -0.00684135 -0.00568777]\n",
            "1.1969000009998847\n",
            "Error_max =  2.8924776882531606e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16602341 -0.00318106 -0.05149288  0.02174607 -0.00600424 -0.0164687\n",
            "  0.0066274   0.01474944  0.00136282 -0.00684046 -0.00568672]\n",
            "1.1970000009998847\n",
            "Error_max =  2.891444461359886e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16604178 -0.00319936 -0.05148542  0.02175169 -0.00600755 -0.01647223\n",
            "  0.00662966  0.01474802  0.00136342 -0.00683958 -0.00568567]\n",
            "1.1971000009998847\n",
            "Error_max =  2.890410801603129e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16606015 -0.00321766 -0.05147796  0.02175731 -0.00601085 -0.01647577\n",
            "  0.00663192  0.01474659  0.00136402 -0.00683869 -0.00568461]\n",
            "1.1972000009998847\n",
            "Error_max =  2.889376709443464e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16607852 -0.00323596 -0.0514705   0.02176293 -0.00601415 -0.01647931\n",
            "  0.00663419  0.01474516  0.00136462 -0.0068378  -0.00568356]\n",
            "1.1973000009998847\n",
            "Error_max =  2.888342185343583e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16609689 -0.00325427 -0.05146303  0.02176855 -0.00601745 -0.01648285\n",
            "  0.00663645  0.01474373  0.00136522 -0.00683692 -0.00568251]\n",
            "1.1974000009998846\n",
            "Error_max =  2.8873072297778237e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16611526 -0.00327258 -0.05145556  0.02177416 -0.00602076 -0.01648638\n",
            "  0.00663871  0.01474231  0.00136583 -0.00683603 -0.00568146]\n",
            "1.1975000009998846\n",
            "Error_max =  2.8862718432088786e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16613364 -0.00329089 -0.05144809  0.02177978 -0.00602406 -0.01648991\n",
            "  0.00664098  0.01474087  0.00136643 -0.00683514 -0.0056804 ]\n",
            "1.1976000009998846\n",
            "Error_max =  2.88523602608991e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16615202 -0.0033092  -0.05144062  0.02178539 -0.00602736 -0.01649345\n",
            "  0.00664324  0.01473944  0.00136703 -0.00683425 -0.00567935]\n",
            "1.1977000009998846\n",
            "Error_max =  2.884199778901609e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1661704  -0.00332752 -0.05143314  0.021791   -0.00603066 -0.01649698\n",
            "  0.0066455   0.01473801  0.00136763 -0.00683337 -0.0056783 ]\n",
            "1.1978000009998846\n",
            "Error_max =  2.883163102100315e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16618878 -0.00334583 -0.05142566  0.02179661 -0.00603396 -0.01650051\n",
            "  0.00664777  0.01473657  0.00136824 -0.00683248 -0.00567724]\n",
            "1.1979000009998846\n",
            "Error_max =  2.882125996164601e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16620716 -0.00336415 -0.05141818  0.02180221 -0.00603727 -0.01650404\n",
            "  0.00665003  0.01473513  0.00136884 -0.00683159 -0.00567619]\n",
            "1.1980000009998846\n",
            "Error_max =  2.8810884615476303e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16622554 -0.00338247 -0.0514107   0.02180782 -0.00604057 -0.01650757\n",
            "  0.0066523   0.0147337   0.00136944 -0.0068307  -0.00567513]\n",
            "1.1981000009998846\n",
            "Error_max =  2.880050498712094e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16624393 -0.0034008  -0.05140321  0.02181342 -0.00604387 -0.0165111\n",
            "  0.00665456  0.01473226  0.00137005 -0.00682981 -0.00567407]\n",
            "1.1982000009998846\n",
            "Error_max =  2.8790121081418604e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16626232 -0.00341912 -0.05139572  0.02181903 -0.00604718 -0.01651463\n",
            "  0.00665683  0.01473081  0.00137065 -0.00682892 -0.00567302]\n",
            "1.1983000009998845\n",
            "Error_max =  2.8779732902964443e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16628071 -0.00343745 -0.05138823  0.02182463 -0.00605048 -0.01651815\n",
            "  0.00665909  0.01472937  0.00137126 -0.00682803 -0.00567196]\n",
            "1.1984000009998845\n",
            "Error_max =  2.8769340456332436e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1662991  -0.00345578 -0.05138073  0.02183022 -0.00605378 -0.01652168\n",
            "  0.00666136  0.01472793  0.00137187 -0.00682715 -0.0056709 ]\n",
            "1.1985000009998845\n",
            "Error_max =  2.875894374626597e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16631749 -0.00347412 -0.05137324  0.02183582 -0.00605708 -0.0165252\n",
            "  0.00666363  0.01472648  0.00137247 -0.00682626 -0.00566985]\n",
            "1.1986000009998845\n",
            "Error_max =  2.8748542777444897e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16633589 -0.00349245 -0.05136574  0.02184142 -0.00606039 -0.01652873\n",
            "  0.00666589  0.01472503  0.00137308 -0.00682537 -0.00566879]\n",
            "1.1987000009998845\n",
            "Error_max =  2.8738137554527903e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16635428 -0.00351079 -0.05135824  0.02184701 -0.00606369 -0.01653225\n",
            "  0.00666816  0.01472359  0.00137369 -0.00682448 -0.00566773]\n",
            "1.1988000009998845\n",
            "Error_max =  2.872772808217367e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16637268 -0.00352913 -0.05135073  0.0218526  -0.00606699 -0.01653577\n",
            "  0.00667043  0.01472214  0.00137429 -0.00682359 -0.00566667]\n",
            "1.1989000009998845\n",
            "Error_max =  2.871731436498793e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16639108 -0.00354748 -0.05134322  0.02185819 -0.0060703  -0.01653929\n",
            "  0.0066727   0.01472068  0.0013749  -0.0068227  -0.00566561]\n",
            "1.1990000009998845\n",
            "Error_max =  2.8706896407809373e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16640948 -0.00356582 -0.05133571  0.02186378 -0.0060736  -0.01654281\n",
            "  0.00667496  0.01471923  0.00137551 -0.00682181 -0.00566455]\n",
            "1.1991000009998845\n",
            "Error_max =  2.8696474215211967e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16642788 -0.00358417 -0.0513282   0.02186937 -0.0060769  -0.01654633\n",
            "  0.00667723  0.01471778  0.00137612 -0.00682092 -0.00566349]\n",
            "1.1992000009998844\n",
            "Error_max =  2.868604779188616e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16644629 -0.00360252 -0.05132069  0.02187495 -0.00608021 -0.01654985\n",
            "  0.0066795   0.01471632  0.00137673 -0.00682003 -0.00566243]\n",
            "1.1993000009998844\n",
            "Error_max =  2.867561714245887e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1664647  -0.00362087 -0.05131317  0.02188054 -0.00608351 -0.01655336\n",
            "  0.00668177  0.01471486  0.00137734 -0.00681913 -0.00566137]\n",
            "1.1994000009998844\n",
            "Error_max =  2.8665182271694656e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1664831  -0.00363922 -0.05130565  0.02188612 -0.00608681 -0.01655688\n",
            "  0.00668404  0.0147134   0.00137795 -0.00681824 -0.0056603 ]\n",
            "1.1995000009998844\n",
            "Error_max =  2.86547431842522e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16650151 -0.00365758 -0.05129812  0.0218917  -0.00609012 -0.01656039\n",
            "  0.00668631  0.01471194  0.00137856 -0.00681735 -0.00565924]\n",
            "1.1996000009998844\n",
            "Error_max =  2.8644299884779595e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16651993 -0.00367594 -0.0512906   0.02189728 -0.00609342 -0.01656391\n",
            "  0.00668858  0.01471048  0.00137917 -0.00681646 -0.00565818]\n",
            "1.1997000009998844\n",
            "Error_max =  2.8633852378062577e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16653834 -0.0036943  -0.05128307  0.02190285 -0.00609672 -0.01656742\n",
            "  0.00669085  0.01470902  0.00137978 -0.00681557 -0.00565711]\n",
            "1.1998000009998844\n",
            "Error_max =  2.862340066864336e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16655676 -0.00371266 -0.05127554  0.02190843 -0.00610003 -0.01657093\n",
            "  0.00669312  0.01470755  0.00138039 -0.00681468 -0.00565605]\n",
            "1.1999000009998844\n",
            "Error_max =  2.8612944761297094e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16657517 -0.00373103 -0.05126801  0.021914   -0.00610333 -0.01657444\n",
            "  0.00669539  0.01470609  0.00138101 -0.00681379 -0.00565498]\n",
            "1.2000000009998844\n",
            "Error_max =  2.860248466068246e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16659359 -0.0037494  -0.05126047  0.02191957 -0.00610664 -0.01657795\n",
            "  0.00669766  0.01470462  0.00138162 -0.00681289 -0.00565392]\n",
            "1.2001000009998843\n",
            "Error_max =  2.859202037154284e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16661201 -0.00376777 -0.05125293  0.02192514 -0.00610994 -0.01658146\n",
            "  0.00669993  0.01470315  0.00138223 -0.006812   -0.00565285]\n",
            "1.2002000009998843\n",
            "Error_max =  2.8581551898526327e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16663043 -0.00378614 -0.05124539  0.02193071 -0.00611324 -0.01658497\n",
            "  0.0067022   0.01470168  0.00138285 -0.00681111 -0.00565179]\n",
            "1.2003000009998843\n",
            "Error_max =  2.8571079246281017e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16664886 -0.00380452 -0.05123785  0.02193627 -0.00611655 -0.01658848\n",
            "  0.00670448  0.01470021  0.00138346 -0.00681022 -0.00565072]\n",
            "1.2004000009998843\n",
            "Error_max =  2.856060241956088e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16666728 -0.00382289 -0.0512303   0.02194184 -0.00611985 -0.01659198\n",
            "  0.00670675  0.01469873  0.00138408 -0.00680932 -0.00564965]\n",
            "1.2005000009998843\n",
            "Error_max =  2.8550121423056366e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16668571 -0.00384127 -0.05122275  0.0219474  -0.00612316 -0.01659549\n",
            "  0.00670902  0.01469726  0.00138469 -0.00680843 -0.00564859]\n",
            "1.2006000009998843\n",
            "Error_max =  2.853963626143674e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16670414 -0.00385966 -0.0512152   0.02195296 -0.00612646 -0.01659899\n",
            "  0.00671129  0.01469578  0.00138531 -0.00680754 -0.00564752]\n",
            "1.2007000009998843\n",
            "Error_max =  2.8529146939445384e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16672257 -0.00387804 -0.05120765  0.02195852 -0.00612977 -0.01660249\n",
            "  0.00671357  0.01469431  0.00138592 -0.00680664 -0.00564645]\n",
            "1.2008000009998843\n",
            "Error_max =  2.85186534618151e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.166741   -0.00389643 -0.05120009  0.02196408 -0.00613307 -0.016606\n",
            "  0.00671584  0.01469283  0.00138654 -0.00680575 -0.00564538]\n",
            "1.2009000009998843\n",
            "Error_max =  2.850815583313045e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16675944 -0.00391482 -0.05119253  0.02196964 -0.00613638 -0.0166095\n",
            "  0.00671811  0.01469135  0.00138716 -0.00680486 -0.00564431]\n",
            "1.2010000009998842\n",
            "Error_max =  2.8497654058103056e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16677787 -0.00393321 -0.05118497  0.02197519 -0.00613968 -0.016613\n",
            "  0.00672039  0.01468986  0.00138777 -0.00680396 -0.00564324]\n",
            "1.2011000009998842\n",
            "Error_max =  2.8487148141508067e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16679631 -0.0039516  -0.05117741  0.02198074 -0.00614299 -0.01661649\n",
            "  0.00672266  0.01468838  0.00138839 -0.00680307 -0.00564217]\n",
            "1.2012000009998842\n",
            "Error_max =  2.8476638088057103e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16681475 -0.00397    -0.05116984  0.02198629 -0.00614629 -0.01661999\n",
            "  0.00672494  0.01468689  0.00138901 -0.00680217 -0.0056411 ]\n",
            "1.2013000009998842\n",
            "Error_max =  2.8466123902451197e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16683319 -0.00398839 -0.05116227  0.02199184 -0.0061496  -0.01662349\n",
            "  0.00672721  0.01468541  0.00138963 -0.00680128 -0.00564003]\n",
            "1.2014000009998842\n",
            "Error_max =  2.845560558930668e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16685163 -0.00400679 -0.0511547   0.02199739 -0.0061529  -0.01662699\n",
            "  0.00672948  0.01468392  0.00139025 -0.00680039 -0.00563896]\n",
            "1.2015000009998842\n",
            "Error_max =  2.844508315338811e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16687008 -0.0040252  -0.05114712  0.02200294 -0.00615621 -0.01663048\n",
            "  0.00673176  0.01468243  0.00139087 -0.00679949 -0.00563789]\n",
            "1.2016000009998842\n",
            "Error_max =  2.8434556599428283e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16688852 -0.0040436  -0.05113955  0.02200848 -0.00615951 -0.01663397\n",
            "  0.00673404  0.01468094  0.00139149 -0.0067986  -0.00563681]\n",
            "1.2017000009998842\n",
            "Error_max =  2.842402593213882e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16690697 -0.00406201 -0.05113197  0.02201402 -0.00616282 -0.01663747\n",
            "  0.00673631  0.01467945  0.00139211 -0.0067977  -0.00563574]\n",
            "1.2018000009998842\n",
            "Error_max =  2.841349115623135e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16692542 -0.00408042 -0.05112439  0.02201956 -0.00616612 -0.01664096\n",
            "  0.00673859  0.01467795  0.00139273 -0.0067968  -0.00563467]\n",
            "1.2019000009998841\n",
            "Error_max =  2.840295227636454e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16694387 -0.00409883 -0.0511168   0.0220251  -0.00616943 -0.01664445\n",
            "  0.00674086  0.01467646  0.00139335 -0.00679591 -0.00563359]\n",
            "1.2020000009998841\n",
            "Error_max =  2.8392409297324137e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16696232 -0.00411725 -0.05110921  0.02203064 -0.00617273 -0.01664794\n",
            "  0.00674314  0.01467496  0.00139397 -0.00679501 -0.00563252]\n",
            "1.2021000009998841\n",
            "Error_max =  2.8381862223832345e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16698078 -0.00413566 -0.05110162  0.02203617 -0.00617604 -0.01665143\n",
            "  0.00674542  0.01467346  0.00139459 -0.00679412 -0.00563144]\n",
            "1.202200000999884\n",
            "Error_max =  2.837131106048432e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16699924 -0.00415408 -0.05109403  0.02204171 -0.00617934 -0.01665492\n",
            "  0.00674769  0.01467197  0.00139521 -0.00679322 -0.00563037]\n",
            "1.202300000999884\n",
            "Error_max =  2.8360755812065796e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16701769 -0.0041725  -0.05108644  0.02204724 -0.00618265 -0.0166584\n",
            "  0.00674997  0.01467046  0.00139584 -0.00679233 -0.00562929]\n",
            "1.202400000999884\n",
            "Error_max =  2.835019648336251e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16703615 -0.00419093 -0.05107884  0.02205277 -0.00618596 -0.01666189\n",
            "  0.00675225  0.01466896  0.00139646 -0.00679143 -0.00562822]\n",
            "1.202500000999884\n",
            "Error_max =  2.833963307910726e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16705461 -0.00420935 -0.05107124  0.0220583  -0.00618926 -0.01666537\n",
            "  0.00675453  0.01466746  0.00139708 -0.00679053 -0.00562714]\n",
            "1.202600000999884\n",
            "Error_max =  2.832906560388461e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16707308 -0.00422778 -0.05106364  0.02206383 -0.00619257 -0.01666886\n",
            "  0.00675681  0.01466595  0.00139771 -0.00678963 -0.00562606]\n",
            "1.202700000999884\n",
            "Error_max =  2.831849406255441e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16709154 -0.00424621 -0.05105603  0.02206935 -0.00619587 -0.01667234\n",
            "  0.00675908  0.01466445  0.00139833 -0.00678874 -0.00562498]\n",
            "1.202800000999884\n",
            "Error_max =  2.8307918459732993e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16711001 -0.00426464 -0.05104842  0.02207488 -0.00619918 -0.01667582\n",
            "  0.00676136  0.01466294  0.00139896 -0.00678784 -0.00562391]\n",
            "1.202900000999884\n",
            "Error_max =  2.829733880022727e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16712848 -0.00428308 -0.05104081  0.0220804  -0.00620249 -0.0166793\n",
            "  0.00676364  0.01466143  0.00139958 -0.00678694 -0.00562283]\n",
            "1.203000000999884\n",
            "Error_max =  2.8286755088770037e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16714695 -0.00430151 -0.0510332   0.02208592 -0.00620579 -0.01668278\n",
            "  0.00676592  0.01465992  0.00140021 -0.00678605 -0.00562175]\n",
            "1.203100000999884\n",
            "Error_max =  2.8276167330030564e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16716542 -0.00431995 -0.05102558  0.02209144 -0.0062091  -0.01668626\n",
            "  0.0067682   0.01465841  0.00140083 -0.00678515 -0.00562067]\n",
            "1.203200000999884\n",
            "Error_max =  2.826557552867812e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16718389 -0.00433839 -0.05101796  0.02209695 -0.00621241 -0.01668974\n",
            "  0.00677048  0.01465689  0.00140146 -0.00678425 -0.00561959]\n",
            "1.203300000999884\n",
            "Error_max =  2.8254979689657257e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16720237 -0.00435684 -0.05101034  0.02210247 -0.00621571 -0.01669322\n",
            "  0.00677276  0.01465538  0.00140209 -0.00678335 -0.00561851]\n",
            "1.203400000999884\n",
            "Error_max =  2.8244379817552544e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16722084 -0.00437528 -0.05100272  0.02210798 -0.00621902 -0.01669669\n",
            "  0.00677504  0.01465386  0.00140272 -0.00678245 -0.00561743]\n",
            "1.203500000999884\n",
            "Error_max =  2.8233775917065014e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16723932 -0.00439373 -0.05099509  0.02211349 -0.00622233 -0.01670017\n",
            "  0.00677732  0.01465234  0.00140334 -0.00678155 -0.00561634]\n",
            "1.203600000999884\n",
            "Error_max =  2.8223167993001577e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1672578  -0.00441218 -0.05098747  0.022119   -0.00622563 -0.01670364\n",
            "  0.0067796   0.01465082  0.00140397 -0.00678066 -0.00561526]\n",
            "1.203700000999884\n",
            "Error_max =  2.8212556050020915e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16727628 -0.00443064 -0.05097984  0.02212451 -0.00622894 -0.01670711\n",
            "  0.00678188  0.0146493   0.0014046  -0.00677976 -0.00561418]\n",
            "1.203800000999884\n",
            "Error_max =  2.820194009303582e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16729476 -0.00444909 -0.0509722   0.02213002 -0.00623225 -0.01671059\n",
            "  0.00678416  0.01464778  0.00140523 -0.00677886 -0.0056131 ]\n",
            "1.203900000999884\n",
            "Error_max =  2.819132012660968e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16731325 -0.00446755 -0.05096457  0.02213552 -0.00623556 -0.01671406\n",
            "  0.00678645  0.01464626  0.00140586 -0.00677796 -0.00561201]\n",
            "1.204000000999884\n",
            "Error_max =  2.8180696155570586e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16733174 -0.00448601 -0.05095693  0.02214103 -0.00623886 -0.01671753\n",
            "  0.00678873  0.01464473  0.00140649 -0.00677706 -0.00561093]\n",
            "1.204100000999884\n",
            "Error_max =  2.817006818466192e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16735022 -0.00450447 -0.05094929  0.02214653 -0.00624217 -0.01672099\n",
            "  0.00679101  0.0146432   0.00140712 -0.00677616 -0.00560984]\n",
            "1.204200000999884\n",
            "Error_max =  2.815943621850001e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16736871 -0.00452294 -0.05094164  0.02215203 -0.00624548 -0.01672446\n",
            "  0.00679329  0.01464168  0.00140775 -0.00677526 -0.00560876]\n",
            "1.2043000009998839\n",
            "Error_max =  2.8148800261987064e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16738721 -0.0045414  -0.05093399  0.02215753 -0.00624879 -0.01672793\n",
            "  0.00679557  0.01464015  0.00140838 -0.00677436 -0.00560767]\n",
            "1.2044000009998839\n",
            "Error_max =  2.8138160319802936e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1674057  -0.00455987 -0.05092635  0.02216302 -0.00625209 -0.01673139\n",
            "  0.00679786  0.01463861  0.00140902 -0.00677346 -0.00560659]\n",
            "1.2045000009998839\n",
            "Error_max =  2.81275163967016e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16742419 -0.00457834 -0.05091869  0.02216852 -0.0062554  -0.01673486\n",
            "  0.00680014  0.01463708  0.00140965 -0.00677256 -0.0056055 ]\n",
            "1.2046000009998838\n",
            "Error_max =  2.811686849735232e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16744269 -0.00459682 -0.05091104  0.02217401 -0.00625871 -0.01673832\n",
            "  0.00680242  0.01463555  0.00141028 -0.00677166 -0.00560442]\n",
            "1.2047000009998838\n",
            "Error_max =  2.810621662662554e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16746119 -0.00461529 -0.05090338  0.0221795  -0.00626202 -0.01674179\n",
            "  0.00680471  0.01463401  0.00141091 -0.00677076 -0.00560333]\n",
            "1.2048000009998838\n",
            "Error_max =  2.8095560789307e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16747969 -0.00463377 -0.05089572  0.02218499 -0.00626533 -0.01674525\n",
            "  0.00680699  0.01463248  0.00141155 -0.00676985 -0.00560224]\n",
            "1.2049000009998838\n",
            "Error_max =  2.808490098994949e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16749819 -0.00465225 -0.05088806  0.02219048 -0.00626863 -0.01674871\n",
            "  0.00680928  0.01463094  0.00141218 -0.00676895 -0.00560115]\n",
            "1.2050000009998838\n",
            "Error_max =  2.8074237233465815e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16751669 -0.00467073 -0.0508804   0.02219597 -0.00627194 -0.01675217\n",
            "  0.00681156  0.0146294   0.00141282 -0.00676805 -0.00560006]\n",
            "1.2051000009998838\n",
            "Error_max =  2.806356952454641e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1675352  -0.00468922 -0.05087273  0.02220145 -0.00627525 -0.01675563\n",
            "  0.00681384  0.01462786  0.00141345 -0.00676715 -0.00559898]\n",
            "1.2052000009998838\n",
            "Error_max =  2.805289786792408e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1675537  -0.0047077  -0.05086506  0.02220693 -0.00627856 -0.01675908\n",
            "  0.00681613  0.01462632  0.00141408 -0.00676625 -0.00559789]\n",
            "1.2053000009998838\n",
            "Error_max =  2.804222226838455e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16757221 -0.00472619 -0.05085739  0.02221242 -0.00628187 -0.01676254\n",
            "  0.00681841  0.01462477  0.00141472 -0.00676535 -0.0055968 ]\n",
            "1.2054000009998838\n",
            "Error_max =  2.803154273075592e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16759072 -0.00474469 -0.05084972  0.02221789 -0.00628518 -0.01676599\n",
            "  0.0068207   0.01462323  0.00141536 -0.00676444 -0.00559571]\n",
            "1.2055000009998837\n",
            "Error_max =  2.802085925971804e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16760923 -0.00476318 -0.05084204  0.02222337 -0.00628849 -0.01676945\n",
            "  0.00682299  0.01462168  0.00141599 -0.00676354 -0.00559461]\n",
            "1.2056000009998837\n",
            "Error_max =  2.8010171860003704e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16762775 -0.00478168 -0.05083436  0.02222885 -0.00629179 -0.0167729\n",
            "  0.00682527  0.01462013  0.00141663 -0.00676264 -0.00559352]\n",
            "1.2057000009998837\n",
            "Error_max =  2.799948053646218e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16764626 -0.00480017 -0.05082668  0.02223432 -0.0062951  -0.01677635\n",
            "  0.00682756  0.01461858  0.00141727 -0.00676174 -0.00559243]\n",
            "1.2058000009998837\n",
            "Error_max =  2.798878529382627e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16766478 -0.00481867 -0.05081899  0.0222398  -0.00629841 -0.01677981\n",
            "  0.00682984  0.01461703  0.0014179  -0.00676083 -0.00559134]\n",
            "1.2059000009998837\n",
            "Error_max =  2.7978086136744054e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1676833  -0.00483718 -0.0508113   0.02224527 -0.00630172 -0.01678326\n",
            "  0.00683213  0.01461548  0.00141854 -0.00675993 -0.00559025]\n",
            "1.2060000009998837\n",
            "Error_max =  2.796738307010716e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16770182 -0.00485568 -0.05080361  0.02225074 -0.00630503 -0.01678671\n",
            "  0.00683442  0.01461393  0.00141918 -0.00675903 -0.00558915]\n",
            "1.2061000009998837\n",
            "Error_max =  2.7956676098637787e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16772034 -0.00487419 -0.05079592  0.0222562  -0.00630834 -0.01679015\n",
            "  0.0068367   0.01461237  0.00141982 -0.00675812 -0.00558806]\n",
            "1.2062000009998837\n",
            "Error_max =  2.794596522715344e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16773886 -0.0048927  -0.05078823  0.02226167 -0.00631165 -0.0167936\n",
            "  0.00683899  0.01461082  0.00142046 -0.00675722 -0.00558697]\n",
            "1.2063000009998837\n",
            "Error_max =  2.7935250460291625e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16775739 -0.00491121 -0.05078053  0.02226714 -0.00631496 -0.01679705\n",
            "  0.00684128  0.01460926  0.0014211  -0.00675632 -0.00558587]\n",
            "1.2064000009998836\n",
            "Error_max =  2.7924531802996895e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16777591 -0.00492973 -0.05077283  0.0222726  -0.00631827 -0.01680049\n",
            "  0.00684357  0.0146077   0.00142174 -0.00675541 -0.00558478]\n",
            "1.2065000009998836\n",
            "Error_max =  2.791380925993852e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16779444 -0.00494824 -0.05076513  0.02227806 -0.00632158 -0.01680394\n",
            "  0.00684585  0.01460614  0.00142238 -0.00675451 -0.00558368]\n",
            "1.2066000009998836\n",
            "Error_max =  2.790308283582812e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16781297 -0.00496676 -0.05075742  0.02228352 -0.00632489 -0.01680738\n",
            "  0.00684814  0.01460458  0.00142302 -0.0067536  -0.00558258]\n",
            "1.2067000009998836\n",
            "Error_max =  2.7892352535536133e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1678315  -0.00498528 -0.05074971  0.02228898 -0.0063282  -0.01681082\n",
            "  0.00685043  0.01460301  0.00142366 -0.0067527  -0.00558149]\n",
            "1.2068000009998836\n",
            "Error_max =  2.7881618363805947e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16785003 -0.0050038  -0.050742    0.02229443 -0.00633151 -0.01681426\n",
            "  0.00685272  0.01460145  0.00142431 -0.00675179 -0.00558039]\n",
            "1.2069000009998836\n",
            "Error_max =  2.787088032540212e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16786857 -0.00502233 -0.05073429  0.02229989 -0.00633482 -0.0168177\n",
            "  0.00685501  0.01459988  0.00142495 -0.00675089 -0.00557929]\n",
            "1.2070000009998836\n",
            "Error_max =  2.786013842516333e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16788711 -0.00504086 -0.05072658  0.02230534 -0.00633813 -0.01682114\n",
            "  0.0068573   0.01459831  0.00142559 -0.00674998 -0.0055782 ]\n",
            "1.2071000009998836\n",
            "Error_max =  2.7849392667737664e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16790564 -0.00505939 -0.05071886  0.02231079 -0.00634144 -0.01682458\n",
            "  0.00685959  0.01459674  0.00142623 -0.00674908 -0.0055771 ]\n",
            "1.2072000009998836\n",
            "Error_max =  2.7838643058016745e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16792418 -0.00507792 -0.05071114  0.02231624 -0.00634475 -0.01682801\n",
            "  0.00686188  0.01459517  0.00142688 -0.00674817 -0.005576  ]\n",
            "1.2073000009998835\n",
            "Error_max =  2.7827889600733366e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16794272 -0.00509645 -0.05070341  0.02232169 -0.00634806 -0.01683145\n",
            "  0.00686417  0.0145936   0.00142752 -0.00674727 -0.0055749 ]\n",
            "1.2074000009998835\n",
            "Error_max =  2.7817132300673263e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16796127 -0.00511499 -0.05069569  0.02232713 -0.00635137 -0.01683488\n",
            "  0.00686646  0.01459203  0.00142817 -0.00674636 -0.0055738 ]\n",
            "1.2075000009998835\n",
            "Error_max =  2.7806371162601e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16797981 -0.00513353 -0.05068796  0.02233258 -0.00635468 -0.01683832\n",
            "  0.00686875  0.01459045  0.00142881 -0.00674545 -0.0055727 ]\n",
            "1.2076000009998835\n",
            "Error_max =  2.7795606191302305e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16799836 -0.00515207 -0.05068023  0.02233802 -0.00635799 -0.01684175\n",
            "  0.00687104  0.01458888  0.00142946 -0.00674455 -0.0055716 ]\n",
            "1.2077000009998835\n",
            "Error_max =  2.7784837391552333e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16801691 -0.00517061 -0.0506725   0.02234346 -0.0063613  -0.01684518\n",
            "  0.00687333  0.0145873   0.0014301  -0.00674364 -0.0055705 ]\n",
            "1.2078000009998835\n",
            "Error_max =  2.7774064768157995e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16803546 -0.00518916 -0.05066476  0.0223489  -0.00636462 -0.01684861\n",
            "  0.00687562  0.01458572  0.00143075 -0.00674273 -0.0055694 ]\n",
            "1.2079000009998835\n",
            "Error_max =  2.776328832594738e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16805401 -0.00520771 -0.05065702  0.02235434 -0.00636793 -0.01685204\n",
            "  0.00687791  0.01458414  0.00143139 -0.00674183 -0.0055683 ]\n",
            "1.2080000009998835\n",
            "Error_max =  2.775250806960034e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16807256 -0.00522626 -0.05064928  0.02235977 -0.00637124 -0.01685547\n",
            "  0.0068802   0.01458256  0.00143204 -0.00674092 -0.00556719]\n",
            "1.2081000009998835\n",
            "Error_max =  2.7741724004040257e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16809111 -0.00524481 -0.05064154  0.02236521 -0.00637455 -0.0168589\n",
            "  0.00688249  0.01458098  0.00143269 -0.00674001 -0.00556609]\n",
            "1.2082000009998834\n",
            "Error_max =  2.773093613389405e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16810967 -0.00526337 -0.05063379  0.02237064 -0.00637786 -0.01686232\n",
            "  0.00688478  0.01457939  0.00143334 -0.0067391  -0.00556499]\n",
            "1.2083000009998834\n",
            "Error_max =  2.7720144464095684e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16812823 -0.00528192 -0.05062604  0.02237607 -0.00638117 -0.01686575\n",
            "  0.00688708  0.01457781  0.00143398 -0.0067382  -0.00556388]\n",
            "1.2084000009998834\n",
            "Error_max =  2.7709348999325016e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16814679 -0.00530048 -0.05061829  0.0223815  -0.00638449 -0.01686917\n",
            "  0.00688937  0.01457622  0.00143463 -0.00673729 -0.00556278]\n",
            "1.2085000009998834\n",
            "Error_max =  2.769854974443131e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16816535 -0.00531904 -0.05061054  0.02238692 -0.0063878  -0.0168726\n",
            "  0.00689166  0.01457463  0.00143528 -0.00673638 -0.00556167]\n",
            "1.2086000009998834\n",
            "Error_max =  2.768774670422148e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16818391 -0.00533761 -0.05060278  0.02239235 -0.00639111 -0.01687602\n",
            "  0.00689395  0.01457304  0.00143593 -0.00673547 -0.00556057]\n",
            "1.2087000009998834\n",
            "Error_max =  2.7676939883407143e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16820247 -0.00535617 -0.05059503  0.02239777 -0.00639442 -0.01687944\n",
            "  0.00689625  0.01457145  0.00143658 -0.00673456 -0.00555946]\n",
            "1.2088000009998834\n",
            "Error_max =  2.7666129286890505e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16822104 -0.00537474 -0.05058726  0.0224032  -0.00639773 -0.01688286\n",
            "  0.00689854  0.01456985  0.00143723 -0.00673365 -0.00555836]\n",
            "1.2089000009998834\n",
            "Error_max =  2.7655314919383186e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16823961 -0.00539331 -0.0505795   0.02240862 -0.00640105 -0.01688628\n",
            "  0.00690083  0.01456826  0.00143788 -0.00673274 -0.00555725]\n",
            "1.2090000009998834\n",
            "Error_max =  2.764449678576621e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16825818 -0.00541188 -0.05057173  0.02241404 -0.00640436 -0.0168897\n",
            "  0.00690313  0.01456666  0.00143853 -0.00673183 -0.00555614]\n",
            "1.2091000009998834\n",
            "Error_max =  2.763367489073003e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16827675 -0.00543046 -0.05056397  0.02241945 -0.00640767 -0.01689311\n",
            "  0.00690542  0.01456507  0.00143918 -0.00673092 -0.00555504]\n",
            "1.2092000009998833\n",
            "Error_max =  2.762284923917684e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16829532 -0.00544903 -0.05055619  0.02242487 -0.00641098 -0.01689653\n",
            "  0.00690771  0.01456347  0.00143983 -0.00673002 -0.00555393]\n",
            "1.2093000009998833\n",
            "Error_max =  2.7612019835892385e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16831389 -0.00546761 -0.05054842  0.02243028 -0.0064143  -0.01689994\n",
            "  0.00691001  0.01456187  0.00144049 -0.00672911 -0.00555282]\n",
            "1.2094000009998833\n",
            "Error_max =  2.760118668557769e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16833247 -0.00548619 -0.05054064  0.02243569 -0.00641761 -0.01690336\n",
            "  0.0069123   0.01456027  0.00144114 -0.0067282  -0.00555171]\n",
            "1.2095000009998833\n",
            "Error_max =  2.759034979311379e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16835105 -0.00550478 -0.05053287  0.02244111 -0.00642092 -0.01690677\n",
            "  0.0069146   0.01455866  0.00144179 -0.00672728 -0.0055506 ]\n",
            "1.2096000009998833\n",
            "Error_max =  2.757950916332876e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16836962 -0.00552336 -0.05052508  0.02244651 -0.00642424 -0.01691018\n",
            "  0.00691689  0.01455706  0.00144245 -0.00672637 -0.00554949]\n",
            "1.2097000009998833\n",
            "Error_max =  2.7568664800902473e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16838821 -0.00554195 -0.0505173   0.02245192 -0.00642755 -0.01691359\n",
            "  0.00691919  0.01455546  0.0014431  -0.00672546 -0.00554838]\n",
            "1.2098000009998833\n",
            "Error_max =  2.7557816710864177e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16840679 -0.00556054 -0.05050951  0.02245733 -0.00643086 -0.016917\n",
            "  0.00692148  0.01455385  0.00144375 -0.00672455 -0.00554727]\n",
            "1.2099000009998833\n",
            "Error_max =  2.7546964897819617e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16842537 -0.00557913 -0.05050173  0.02246273 -0.00643418 -0.01692041\n",
            "  0.00692378  0.01455224  0.00144441 -0.00672364 -0.00554616]\n",
            "1.2100000009998833\n",
            "Error_max =  2.753610936664982e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16844396 -0.00559773 -0.05049393  0.02246813 -0.00643749 -0.01692382\n",
            "  0.00692607  0.01455063  0.00144506 -0.00672273 -0.00554505]\n",
            "1.2101000009998832\n",
            "Error_max =  2.752525012208758e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16846254 -0.00561633 -0.05048614  0.02247353 -0.0064408  -0.01692722\n",
            "  0.00692837  0.01454902  0.00144572 -0.00672182 -0.00554394]\n",
            "1.2102000009998832\n",
            "Error_max =  2.751438716905628e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16848113 -0.00563493 -0.05047834  0.02247893 -0.00644412 -0.01693063\n",
            "  0.00693066  0.01454741  0.00144638 -0.00672091 -0.00554282]\n",
            "1.2103000009998832\n",
            "Error_max =  2.750352051236283e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16849972 -0.00565353 -0.05047054  0.02248433 -0.00644743 -0.01693403\n",
            "  0.00693296  0.01454579  0.00144703 -0.00672    -0.00554171]\n",
            "1.2104000009998832\n",
            "Error_max =  2.749265015671885e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16851831 -0.00567213 -0.05046274  0.02248972 -0.00645075 -0.01693743\n",
            "  0.00693525  0.01454418  0.00144769 -0.00671908 -0.0055406 ]\n",
            "1.2105000009998832\n",
            "Error_max =  2.748177610701596e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16853691 -0.00569074 -0.05045494  0.02249512 -0.00645406 -0.01694084\n",
            "  0.00693755  0.01454256  0.00144835 -0.00671817 -0.00553948]\n",
            "1.2106000009998832\n",
            "Error_max =  2.747089836807165e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1685555  -0.00570934 -0.05044713  0.02250051 -0.00645737 -0.01694424\n",
            "  0.00693985  0.01454094  0.001449   -0.00671726 -0.00553837]\n",
            "1.2107000009998832\n",
            "Error_max =  2.746001694465049e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1685741  -0.00572795 -0.05043932  0.0225059  -0.00646069 -0.01694764\n",
            "  0.00694214  0.01453932  0.00144966 -0.00671635 -0.00553726]\n",
            "1.2108000009998832\n",
            "Error_max =  2.744913184160174e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1685927  -0.00574657 -0.05043151  0.02251129 -0.006464   -0.01695103\n",
            "  0.00694444  0.0145377   0.00145032 -0.00671543 -0.00553614]\n",
            "1.2109000009998832\n",
            "Error_max =  2.743824306368996e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1686113  -0.00576518 -0.0504237   0.02251668 -0.00646732 -0.01695443\n",
            "  0.00694674  0.01453608  0.00145098 -0.00671452 -0.00553502]\n",
            "1.2110000009998831\n",
            "Error_max =  2.7427350615827943e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1686299  -0.0057838  -0.05041588  0.02252206 -0.00647063 -0.01695783\n",
            "  0.00694904  0.01453446  0.00145164 -0.00671361 -0.00553391]\n",
            "1.2111000009998831\n",
            "Error_max =  2.7416454502737895e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1686485  -0.00580242 -0.05040806  0.02252744 -0.00647395 -0.01696122\n",
            "  0.00695133  0.01453283  0.0014523  -0.00671269 -0.00553279]\n",
            "1.2112000009998831\n",
            "Error_max =  2.740555472933261e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16866711 -0.00582104 -0.05040024  0.02253283 -0.00647726 -0.01696462\n",
            "  0.00695363  0.01453121  0.00145296 -0.00671178 -0.00553167]\n",
            "1.211300000999883\n",
            "Error_max =  2.7394651300260176e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16868571 -0.00583966 -0.05039241  0.02253821 -0.00648058 -0.01696801\n",
            "  0.00695593  0.01452958  0.00145362 -0.00671087 -0.00553056]\n",
            "1.211400000999883\n",
            "Error_max =  2.7383744220560444e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16870432 -0.00585829 -0.05038459  0.02254359 -0.00648389 -0.0169714\n",
            "  0.00695823  0.01452795  0.00145428 -0.00670995 -0.00552944]\n",
            "1.211500000999883\n",
            "Error_max =  2.737283349492386e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16872293 -0.00587692 -0.05037676  0.02254896 -0.00648721 -0.01697479\n",
            "  0.00696053  0.01452632  0.00145494 -0.00670904 -0.00552832]\n",
            "1.211600000999883\n",
            "Error_max =  2.7361919128284385e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16874154 -0.00589555 -0.05036893  0.02255434 -0.00649053 -0.01697818\n",
            "  0.00696283  0.01452469  0.0014556  -0.00670812 -0.0055272 ]\n",
            "1.211700000999883\n",
            "Error_max =  2.7351001125300705e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16876015 -0.00591418 -0.05036109  0.02255971 -0.00649384 -0.01698157\n",
            "  0.00696512  0.01452306  0.00145626 -0.00670721 -0.00552608]\n",
            "1.211800000999883\n",
            "Error_max =  2.734007949093855e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16877877 -0.00593281 -0.05035326  0.02256508 -0.00649716 -0.01698496\n",
            "  0.00696742  0.01452142  0.00145692 -0.00670629 -0.00552496]\n",
            "1.211900000999883\n",
            "Error_max =  2.732915422995189e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16879738 -0.00595145 -0.05034542  0.02257045 -0.00650047 -0.01698835\n",
            "  0.00696972  0.01451978  0.00145759 -0.00670538 -0.00552384]\n",
            "1.212000000999883\n",
            "Error_max =  2.7318225347168817e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.168816   -0.00597009 -0.05033757  0.02257582 -0.00650379 -0.01699173\n",
            "  0.00697202  0.01451815  0.00145825 -0.00670446 -0.00552272]\n",
            "1.212100000999883\n",
            "Error_max =  2.730729284738565e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16883462 -0.00598873 -0.05032973  0.02258119 -0.00650711 -0.01699512\n",
            "  0.00697432  0.01451651  0.00145891 -0.00670355 -0.0055216 ]\n",
            "1.212200000999883\n",
            "Error_max =  2.7296356735621065e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16885324 -0.00600737 -0.05032188  0.02258655 -0.00651042 -0.0169985\n",
            "  0.00697662  0.01451487  0.00145958 -0.00670263 -0.00552048]\n",
            "1.212300000999883\n",
            "Error_max =  2.72854170164808e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16887186 -0.00602602 -0.05031403  0.02259192 -0.00651374 -0.01700188\n",
            "  0.00697892  0.01451323  0.00146024 -0.00670172 -0.00551936]\n",
            "1.212400000999883\n",
            "Error_max =  2.727447369490941e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16889049 -0.00604467 -0.05030618  0.02259728 -0.00651705 -0.01700527\n",
            "  0.00698122  0.01451158  0.00146091 -0.0067008  -0.00551824]\n",
            "1.212500000999883\n",
            "Error_max =  2.7263526775703217e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16890911 -0.00606332 -0.05029833  0.02260264 -0.00652037 -0.01700865\n",
            "  0.00698352  0.01450994  0.00146157 -0.00669988 -0.00551711]\n",
            "1.212600000999883\n",
            "Error_max =  2.725257626374325e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16892774 -0.00608197 -0.05029047  0.022608   -0.00652369 -0.01701203\n",
            "  0.00698582  0.0145083   0.00146224 -0.00669897 -0.00551599]\n",
            "1.212700000999883\n",
            "Error_max =  2.7241622163698784e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16894637 -0.00610062 -0.05028261  0.02261336 -0.00652701 -0.0170154\n",
            "  0.00698812  0.01450665  0.0014629  -0.00669805 -0.00551487]\n",
            "1.212800000999883\n",
            "Error_max =  2.723066448064142e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.168965   -0.00611928 -0.05027475  0.02261871 -0.00653032 -0.01701878\n",
            "  0.00699042  0.014505    0.00146357 -0.00669713 -0.00551374]\n",
            "1.212900000999883\n",
            "Error_max =  2.721970321926161e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16898363 -0.00613794 -0.05026688  0.02262406 -0.00653364 -0.01702216\n",
            "  0.00699272  0.01450335  0.00146424 -0.00669622 -0.00551262]\n",
            "1.213000000999883\n",
            "Error_max =  2.7208738384440374e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16900226 -0.0061566  -0.05025902  0.02262942 -0.00653696 -0.01702553\n",
            "  0.00699502  0.0145017   0.0014649  -0.0066953  -0.00551149]\n",
            "1.213100000999883\n",
            "Error_max =  2.719776998097404e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1690209  -0.00617526 -0.05025115  0.02263477 -0.00654027 -0.0170289\n",
            "  0.00699733  0.01450005  0.00146557 -0.00669438 -0.00551037]\n",
            "1.213200000999883\n",
            "Error_max =  2.71867980137754e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16903953 -0.00619393 -0.05024327  0.02264012 -0.00654359 -0.01703228\n",
            "  0.00699963  0.01449839  0.00146624 -0.00669346 -0.00550924]\n",
            "1.2133000009998829\n",
            "Error_max =  2.717582248758784e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16905817 -0.0062126  -0.0502354   0.02264546 -0.00654691 -0.01703565\n",
            "  0.00700193  0.01449674  0.00146691 -0.00669254 -0.00550811]\n",
            "1.2134000009998829\n",
            "Error_max =  2.716484340731356e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16907681 -0.00623127 -0.05022752  0.02265081 -0.00655023 -0.01703902\n",
            "  0.00700423  0.01449508  0.00146758 -0.00669163 -0.00550699]\n",
            "1.2135000009998829\n",
            "Error_max =  2.7153860777791234e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16909545 -0.00624994 -0.05021964  0.02265615 -0.00655355 -0.01704239\n",
            "  0.00700653  0.01449342  0.00146824 -0.00669071 -0.00550586]\n",
            "1.2136000009998829\n",
            "Error_max =  2.714287460382778e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16911409 -0.00626861 -0.05021176  0.02266149 -0.00655686 -0.01704576\n",
            "  0.00700883  0.01449177  0.00146891 -0.00668979 -0.00550473]\n",
            "1.2137000009998828\n",
            "Error_max =  2.7131884890367746e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16913274 -0.00628729 -0.05020388  0.02266683 -0.00656018 -0.01704912\n",
            "  0.00701114  0.0144901   0.00146958 -0.00668887 -0.0055036 ]\n",
            "1.2138000009998828\n",
            "Error_max =  2.7120891642122757e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16915138 -0.00630597 -0.05019599  0.02267217 -0.0065635  -0.01705249\n",
            "  0.00701344  0.01448844  0.00147025 -0.00668795 -0.00550247]\n",
            "1.2139000009998828\n",
            "Error_max =  2.710989486402678e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16917003 -0.00632465 -0.0501881   0.02267751 -0.00656682 -0.01705586\n",
            "  0.00701574  0.01448678  0.00147092 -0.00668703 -0.00550135]\n",
            "1.2140000009998828\n",
            "Error_max =  2.7098894560886725e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16918868 -0.00634333 -0.05018021  0.02268284 -0.00657014 -0.01705922\n",
            "  0.00701804  0.01448512  0.0014716  -0.00668611 -0.00550022]\n",
            "1.2141000009998828\n",
            "Error_max =  2.7087890737509505e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16920733 -0.00636202 -0.05017231  0.02268818 -0.00657346 -0.01706258\n",
            "  0.00702035  0.01448345  0.00147227 -0.00668519 -0.00549909]\n",
            "1.2142000009998828\n",
            "Error_max =  2.7076883398882026e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16922598 -0.0063807  -0.05016442  0.02269351 -0.00657678 -0.01706594\n",
            "  0.00702265  0.01448178  0.00147294 -0.00668427 -0.00549796]\n",
            "1.2143000009998828\n",
            "Error_max =  2.706587254967356e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16924464 -0.00639939 -0.05015652  0.02269884 -0.0065801  -0.0170693\n",
            "  0.00702495  0.01448011  0.00147361 -0.00668335 -0.00549682]\n",
            "1.2144000009998828\n",
            "Error_max =  2.705485819487101e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16926329 -0.00641809 -0.05014861  0.02270417 -0.00658342 -0.01707266\n",
            "  0.00702726  0.01447844  0.00147428 -0.00668243 -0.00549569]\n",
            "1.2145000009998828\n",
            "Error_max =  2.7043840339281286e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16928195 -0.00643678 -0.05014071  0.0227095  -0.00658673 -0.01707602\n",
            "  0.00702956  0.01447677  0.00147496 -0.00668151 -0.00549456]\n",
            "1.2146000009998827\n",
            "Error_max =  2.703281898769013e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16930061 -0.00645547 -0.0501328   0.02271482 -0.00659005 -0.01707938\n",
            "  0.00703186  0.0144751   0.00147563 -0.00668059 -0.00549343]\n",
            "1.2147000009998827\n",
            "Error_max =  2.7021794145020917e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16931927 -0.00647417 -0.05012489  0.02272014 -0.00659337 -0.01708274\n",
            "  0.00703417  0.01447343  0.0014763  -0.00667967 -0.0054923 ]\n",
            "1.2148000009998827\n",
            "Error_max =  2.70107658161335e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16933793 -0.00649287 -0.05011698  0.02272547 -0.00659669 -0.01708609\n",
            "  0.00703647  0.01447175  0.00147698 -0.00667875 -0.00549116]\n",
            "1.2149000009998827\n",
            "Error_max =  2.699973400589832e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16935659 -0.00651158 -0.05010907  0.02273079 -0.00660001 -0.01708944\n",
            "  0.00703878  0.01447007  0.00147765 -0.00667783 -0.00549003]\n",
            "1.2150000009998827\n",
            "Error_max =  2.698869871909052e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16937526 -0.00653028 -0.05010115  0.0227361  -0.00660333 -0.0170928\n",
            "  0.00704108  0.01446839  0.00147833 -0.00667691 -0.0054889 ]\n",
            "1.2151000009998827\n",
            "Error_max =  2.6977659960622897e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16939393 -0.00654899 -0.05009323  0.02274142 -0.00660665 -0.01709615\n",
            "  0.00704338  0.01446672  0.001479   -0.00667599 -0.00548776]\n",
            "1.2152000009998827\n",
            "Error_max =  2.6966617735334123e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16941259 -0.0065677  -0.05008531  0.02274674 -0.00660997 -0.0170995\n",
            "  0.00704569  0.01446503  0.00147968 -0.00667506 -0.00548663]\n",
            "1.2153000009998827\n",
            "Error_max =  2.695557204808405e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16943126 -0.00658641 -0.05007738  0.02275205 -0.0066133  -0.01710285\n",
            "  0.00704799  0.01446335  0.00148036 -0.00667414 -0.00548549]\n",
            "1.2154000009998827\n",
            "Error_max =  2.6944522903721945e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16944993 -0.00660512 -0.05006945  0.02275736 -0.00661662 -0.0171062\n",
            "  0.0070503   0.01446167  0.00148103 -0.00667322 -0.00548436]\n",
            "1.2155000009998826\n",
            "Error_max =  2.693347030718177e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16946861 -0.00662384 -0.05006152  0.02276267 -0.00661994 -0.01710954\n",
            "  0.0070526   0.01445998  0.00148171 -0.0066723  -0.00548322]\n",
            "1.2156000009998826\n",
            "Error_max =  2.6922414263153973e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16948728 -0.00664256 -0.05005359  0.02276798 -0.00662326 -0.01711289\n",
            "  0.00705491  0.0144583   0.00148239 -0.00667137 -0.00548208]\n",
            "1.2157000009998826\n",
            "Error_max =  2.691135477668899e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16950596 -0.00666128 -0.05004566  0.02277329 -0.00662658 -0.01711624\n",
            "  0.00705721  0.01445661  0.00148306 -0.00667045 -0.00548095]\n",
            "1.2158000009998826\n",
            "Error_max =  2.6900291852530197e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16952463 -0.00668    -0.05003772  0.02277859 -0.0066299  -0.01711958\n",
            "  0.00705952  0.01445492  0.00148374 -0.00666953 -0.00547981]\n",
            "1.2159000009998826\n",
            "Error_max =  2.688922549555863e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16954331 -0.00669872 -0.05002978  0.0227839  -0.00663322 -0.01712292\n",
            "  0.00706183  0.01445323  0.00148442 -0.0066686  -0.00547867]\n",
            "1.2160000009998826\n",
            "Error_max =  2.687815571067649e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16956199 -0.00671745 -0.05002184  0.0227892  -0.00663654 -0.01712626\n",
            "  0.00706413  0.01445154  0.0014851  -0.00666768 -0.00547753]\n",
            "1.2161000009998826\n",
            "Error_max =  2.6867082502701274e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16958068 -0.00673618 -0.05001389  0.0227945  -0.00663986 -0.0171296\n",
            "  0.00706644  0.01444985  0.00148578 -0.00666676 -0.00547639]\n",
            "1.2162000009998826\n",
            "Error_max =  2.685600587653519e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16959936 -0.00675491 -0.05000595  0.0227998  -0.00664319 -0.01713294\n",
            "  0.00706874  0.01444815  0.00148646 -0.00666583 -0.00547525]\n",
            "1.2163000009998826\n",
            "Error_max =  2.684492583700632e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16961804 -0.00677364 -0.049998    0.0228051  -0.00664651 -0.01713628\n",
            "  0.00707105  0.01444646  0.00148714 -0.00666491 -0.00547411]\n",
            "1.2164000009998825\n",
            "Error_max =  2.6833842388995695e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16963673 -0.00679238 -0.04999005  0.02281039 -0.00664983 -0.01713962\n",
            "  0.00707336  0.01444476  0.00148782 -0.00666398 -0.00547297]\n",
            "1.2165000009998825\n",
            "Error_max =  2.6822755537426695e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16965542 -0.00681111 -0.04998209  0.02281568 -0.00665315 -0.01714296\n",
            "  0.00707566  0.01444306  0.0014885  -0.00666306 -0.00547183]\n",
            "1.2166000009998825\n",
            "Error_max =  2.681166528709564e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16967411 -0.00682985 -0.04997413  0.02282098 -0.00665648 -0.01714629\n",
            "  0.00707797  0.01444136  0.00148918 -0.00666213 -0.00547069]\n",
            "1.2167000009998825\n",
            "Error_max =  2.6800571642883563e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1696928  -0.00684859 -0.04996617  0.02282627 -0.0066598  -0.01714963\n",
            "  0.00708028  0.01443966  0.00148986 -0.00666121 -0.00546955]\n",
            "1.2168000009998825\n",
            "Error_max =  2.6789474609724426e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16971149 -0.00686734 -0.04995821  0.02283156 -0.00666312 -0.01715296\n",
            "  0.00708258  0.01443796  0.00149054 -0.00666028 -0.00546841]\n",
            "1.2169000009998825\n",
            "Error_max =  2.677837419232985e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16973019 -0.00688608 -0.04995025  0.02283684 -0.00666644 -0.01715629\n",
            "  0.00708489  0.01443625  0.00149123 -0.00665936 -0.00546727]\n",
            "1.2170000009998825\n",
            "Error_max =  2.676727039577145e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16974888 -0.00690483 -0.04994228  0.02284213 -0.00666977 -0.01715962\n",
            "  0.0070872   0.01443455  0.00149191 -0.00665843 -0.00546612]\n",
            "1.2171000009998825\n",
            "Error_max =  2.675616322477143e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16976758 -0.00692358 -0.04993431  0.02284741 -0.00667309 -0.01716295\n",
            "  0.00708951  0.01443284  0.00149259 -0.00665751 -0.00546498]\n",
            "1.2172000009998825\n",
            "Error_max =  2.6745052684327284e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16978628 -0.00694233 -0.04992634  0.02285269 -0.00667641 -0.01716628\n",
            "  0.00709181  0.01443113  0.00149328 -0.00665658 -0.00546384]\n",
            "1.2173000009998824\n",
            "Error_max =  2.673393877917181e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16980498 -0.00696109 -0.04991836  0.02285797 -0.00667974 -0.0171696\n",
            "  0.00709412  0.01442942  0.00149396 -0.00665565 -0.00546269]\n",
            "1.2174000009998824\n",
            "Error_max =  2.6722821514291916e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16982368 -0.00697985 -0.04991039  0.02286325 -0.00668306 -0.01717293\n",
            "  0.00709643  0.01442771  0.00149464 -0.00665473 -0.00546155]\n",
            "1.2175000009998824\n",
            "Error_max =  2.671170089449451e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16984239 -0.0069986  -0.04990241  0.02286853 -0.00668638 -0.01717626\n",
            "  0.00709874  0.014426    0.00149533 -0.0066538  -0.0054604 ]\n",
            "1.2176000009998824\n",
            "Error_max =  2.670057692473474e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16986109 -0.00701737 -0.04989443  0.02287381 -0.00668971 -0.01717958\n",
            "  0.00710104  0.01442429  0.00149601 -0.00665287 -0.00545926]\n",
            "1.2177000009998824\n",
            "Error_max =  2.668944960973481e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1698798  -0.00703613 -0.04988644  0.02287908 -0.00669303 -0.0171829\n",
            "  0.00710335  0.01442257  0.0014967  -0.00665195 -0.00545811]\n",
            "1.2178000009998824\n",
            "Error_max =  2.667831895456633e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16989851 -0.00705489 -0.04987845  0.02288435 -0.00669636 -0.01718622\n",
            "  0.00710566  0.01442086  0.00149738 -0.00665102 -0.00545696]\n",
            "1.2179000009998824\n",
            "Error_max =  2.6667184964057394e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16991722 -0.00707366 -0.04987046  0.02288962 -0.00669968 -0.01718954\n",
            "  0.00710797  0.01441914  0.00149807 -0.00665009 -0.00545582]\n",
            "1.2180000009998824\n",
            "Error_max =  2.6656047642919615e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16993593 -0.00709243 -0.04986247  0.02289489 -0.00670301 -0.01719286\n",
            "  0.00711028  0.01441742  0.00149876 -0.00664916 -0.00545467]\n",
            "1.2181000009998824\n",
            "Error_max =  2.664490699626696e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16995464 -0.0071112  -0.04985448  0.02290016 -0.00670633 -0.01719618\n",
            "  0.00711259  0.0144157   0.00149944 -0.00664823 -0.00545352]\n",
            "1.2182000009998823\n",
            "Error_max =  2.6633763028853396e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16997336 -0.00712998 -0.04984648  0.02290542 -0.00670966 -0.0171995\n",
            "  0.00711489  0.01441398  0.00150013 -0.00664731 -0.00545237]\n",
            "1.2183000009998823\n",
            "Error_max =  2.662261574557054e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.16999207 -0.00714875 -0.04983848  0.02291069 -0.00671298 -0.01720281\n",
            "  0.0071172   0.01441226  0.00150082 -0.00664638 -0.00545122]\n",
            "1.2184000009998823\n",
            "Error_max =  2.661146515128884e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17001079 -0.00716753 -0.04983048  0.02291595 -0.00671631 -0.01720613\n",
            "  0.00711951  0.01441054  0.00150151 -0.00664545 -0.00545008]\n",
            "1.2185000009998823\n",
            "Error_max =  2.660031125094225e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17002951 -0.00718631 -0.04982248  0.02292121 -0.00671963 -0.01720944\n",
            "  0.00712182  0.01440881  0.0015022  -0.00664452 -0.00544893]\n",
            "1.2186000009998823\n",
            "Error_max =  2.658915404938004e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17004823 -0.00720509 -0.04981447  0.02292647 -0.00672296 -0.01721276\n",
            "  0.00712413  0.01440708  0.00150288 -0.00664359 -0.00544778]\n",
            "1.2187000009998823\n",
            "Error_max =  2.6577993551536176e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17006695 -0.00722388 -0.04980646  0.02293173 -0.00672628 -0.01721607\n",
            "  0.00712644  0.01440536  0.00150357 -0.00664266 -0.00544663]\n",
            "1.2188000009998823\n",
            "Error_max =  2.656682976222816e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17008568 -0.00724267 -0.04979845  0.02293698 -0.00672961 -0.01721938\n",
            "  0.00712875  0.01440363  0.00150426 -0.00664173 -0.00544548]\n",
            "1.2189000009998823\n",
            "Error_max =  2.6555662686389954e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1701044  -0.00726146 -0.04979043  0.02294224 -0.00673293 -0.01722269\n",
            "  0.00713106  0.0144019   0.00150495 -0.0066408  -0.00544432]\n",
            "1.2190000009998823\n",
            "Error_max =  2.654449232879671e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17012313 -0.00728025 -0.04978242  0.02294749 -0.00673626 -0.01722599\n",
            "  0.00713337  0.01440017  0.00150564 -0.00663987 -0.00544317]\n",
            "1.2191000009998822\n",
            "Error_max =  2.653331869449886e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17014186 -0.00729904 -0.0497744   0.02295274 -0.00673959 -0.0172293\n",
            "  0.00713568  0.01439843  0.00150633 -0.00663894 -0.00544202]\n",
            "1.2192000009998822\n",
            "Error_max =  2.6522141788292734e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17016059 -0.00731784 -0.04976638  0.02295799 -0.00674291 -0.01723261\n",
            "  0.00713799  0.0143967   0.00150703 -0.00663801 -0.00544087]\n",
            "1.2193000009998822\n",
            "Error_max =  2.6510961615154643e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17017932 -0.00733663 -0.04975835  0.02296324 -0.00674624 -0.01723591\n",
            "  0.0071403   0.01439496  0.00150772 -0.00663708 -0.00543972]\n",
            "1.2194000009998822\n",
            "Error_max =  2.6499778179870326e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17019805 -0.00735543 -0.04975033  0.02296848 -0.00674957 -0.01723921\n",
            "  0.00714261  0.01439323  0.00150841 -0.00663615 -0.00543856]\n",
            "1.2195000009998822\n",
            "Error_max =  2.648859148731022e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17021678 -0.00737423 -0.0497423   0.02297373 -0.00675289 -0.01724252\n",
            "  0.00714492  0.01439149  0.0015091  -0.00663522 -0.00543741]\n",
            "1.2196000009998822\n",
            "Error_max =  2.647740154250359e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17023552 -0.00739304 -0.04973426  0.02297897 -0.00675622 -0.01724582\n",
            "  0.00714723  0.01438975  0.00150979 -0.00663429 -0.00543625]\n",
            "1.2197000009998822\n",
            "Error_max =  2.646620835017264e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17025426 -0.00741184 -0.04972623  0.02298421 -0.00675955 -0.01724912\n",
            "  0.00714954  0.01438801  0.00151049 -0.00663336 -0.0054351 ]\n",
            "1.2198000009998822\n",
            "Error_max =  2.6455011915388977e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.170273   -0.00743065 -0.04971819  0.02298945 -0.00676287 -0.01725242\n",
            "  0.00715185  0.01438626  0.00151118 -0.00663242 -0.00543394]\n",
            "1.2199000009998822\n",
            "Error_max =  2.6443812242917166e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17029174 -0.00744946 -0.04971016  0.02299469 -0.0067662  -0.01725571\n",
            "  0.00715416  0.01438452  0.00151187 -0.00663149 -0.00543279]\n",
            "1.2200000009998822\n",
            "Error_max =  2.6432609337733523e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17031048 -0.00746828 -0.04970211  0.02299992 -0.00676953 -0.01725901\n",
            "  0.00715647  0.01438277  0.00151257 -0.00663056 -0.00543163]\n",
            "1.2201000009998821\n",
            "Error_max =  2.642140320453908e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17032922 -0.00748709 -0.04969407  0.02300516 -0.00677286 -0.0172623\n",
            "  0.00715878  0.01438103  0.00151326 -0.00662963 -0.00543048]\n",
            "1.2202000009998821\n",
            "Error_max =  2.6410193848606624e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17034797 -0.00750591 -0.04968602  0.02301039 -0.00677619 -0.0172656\n",
            "  0.0071611   0.01437928  0.00151396 -0.00662869 -0.00542932]\n",
            "1.2203000009998821\n",
            "Error_max =  2.6398981274510124e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17036671 -0.00752473 -0.04967797  0.02301562 -0.00677951 -0.01726889\n",
            "  0.00716341  0.01437753  0.00151465 -0.00662776 -0.00542816]\n",
            "1.220400000999882\n",
            "Error_max =  2.6387765487172964e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17038546 -0.00754355 -0.04966992  0.02302085 -0.00678284 -0.01727218\n",
            "  0.00716572  0.01437578  0.00151535 -0.00662683 -0.005427  ]\n",
            "1.220500000999882\n",
            "Error_max =  2.637654649161381e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17040421 -0.00756237 -0.04966187  0.02302608 -0.00678617 -0.01727547\n",
            "  0.00716803  0.01437403  0.00151604 -0.0066259  -0.00542585]\n",
            "1.220600000999882\n",
            "Error_max =  2.636532429269252e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17042296 -0.0075812  -0.04965381  0.0230313  -0.0067895  -0.01727876\n",
            "  0.00717034  0.01437228  0.00151674 -0.00662496 -0.00542469]\n",
            "1.220700000999882\n",
            "Error_max =  2.635409889527953e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17044171 -0.00760002 -0.04964575  0.02303653 -0.00679283 -0.01728205\n",
            "  0.00717265  0.01437052  0.00151744 -0.00662403 -0.00542353]\n",
            "1.220800000999882\n",
            "Error_max =  2.634287030432998e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17046047 -0.00761885 -0.04963769  0.02304175 -0.00679616 -0.01728534\n",
            "  0.00717496  0.01436877  0.00151813 -0.00662309 -0.00542237]\n",
            "1.220900000999882\n",
            "Error_max =  2.633163852474608e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17047922 -0.00763768 -0.04962963  0.02304697 -0.00679949 -0.01728863\n",
            "  0.00717728  0.01436701  0.00151883 -0.00662216 -0.00542121]\n",
            "1.221000000999882\n",
            "Error_max =  2.6320403561345324e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17049798 -0.00765652 -0.04962156  0.02305219 -0.00680282 -0.01729191\n",
            "  0.00717959  0.01436525  0.00151953 -0.00662123 -0.00542005]\n",
            "1.221100000999882\n",
            "Error_max =  2.630916541900874e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17051674 -0.00767535 -0.04961349  0.02305741 -0.00680615 -0.01729519\n",
            "  0.0071819   0.01436349  0.00152023 -0.00662029 -0.00541889]\n",
            "1.221200000999882\n",
            "Error_max =  2.629792410274441e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1705355  -0.00769419 -0.04960542  0.02306262 -0.00680948 -0.01729848\n",
            "  0.00718421  0.01436173  0.00152093 -0.00661936 -0.00541773]\n",
            "1.221300000999882\n",
            "Error_max =  2.628667961742278e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17055426 -0.00771303 -0.04959735  0.02306784 -0.00681281 -0.01730176\n",
            "  0.00718652  0.01435997  0.00152163 -0.00661842 -0.00541656]\n",
            "1.221400000999882\n",
            "Error_max =  2.627543196795663e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17057302 -0.00773187 -0.04958927  0.02307305 -0.00681614 -0.01730504\n",
            "  0.00718884  0.01435821  0.00152232 -0.00661749 -0.0054154 ]\n",
            "1.221500000999882\n",
            "Error_max =  2.6264181159248174e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17059179 -0.00775072 -0.0495812   0.02307826 -0.00681947 -0.01730832\n",
            "  0.00719115  0.01435644  0.00152302 -0.00661655 -0.00541424]\n",
            "1.221600000999882\n",
            "Error_max =  2.625292719614667e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17061055 -0.00776957 -0.04957311  0.02308347 -0.0068228  -0.0173116\n",
            "  0.00719346  0.01435468  0.00152372 -0.00661561 -0.00541308]\n",
            "1.221700000999882\n",
            "Error_max =  2.624167008360726e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17062932 -0.00778841 -0.04956503  0.02308868 -0.00682613 -0.01731487\n",
            "  0.00719577  0.01435291  0.00152442 -0.00661468 -0.00541191]\n",
            "1.221800000999882\n",
            "Error_max =  2.623040982662744e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17064809 -0.00780726 -0.04955695  0.02309389 -0.00682946 -0.01731815\n",
            "  0.00719809  0.01435114  0.00152513 -0.00661374 -0.00541075]\n",
            "1.221900000999882\n",
            "Error_max =  2.621914642990824e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17066686 -0.00782612 -0.04954886  0.02309909 -0.00683279 -0.01732142\n",
            "  0.0072004   0.01434937  0.00152583 -0.00661281 -0.00540959]\n",
            "1.222000000999882\n",
            "Error_max =  2.6207879898531866e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17068563 -0.00784497 -0.04954077  0.02310429 -0.00683612 -0.0173247\n",
            "  0.00720271  0.0143476   0.00152653 -0.00661187 -0.00540842]\n",
            "1.222100000999882\n",
            "Error_max =  2.6196610237241694e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17070441 -0.00786383 -0.04953267  0.02310949 -0.00683945 -0.01732797\n",
            "  0.00720502  0.01434583  0.00152723 -0.00661093 -0.00540726]\n",
            "1.222200000999882\n",
            "Error_max =  2.6185337451162277e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17072318 -0.00788269 -0.04952458  0.02311469 -0.00684278 -0.01733124\n",
            "  0.00720734  0.01434405  0.00152793 -0.00660999 -0.00540609]\n",
            "1.222300000999882\n",
            "Error_max =  2.617406154502641e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17074196 -0.00790155 -0.04951648  0.02311989 -0.00684611 -0.01733451\n",
            "  0.00720965  0.01434228  0.00152864 -0.00660906 -0.00540492]\n",
            "1.2224000009998819\n",
            "Error_max =  2.6162782523842177e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17076074 -0.00792041 -0.04950838  0.02312509 -0.00684945 -0.01733778\n",
            "  0.00721196  0.0143405   0.00152934 -0.00660812 -0.00540376]\n",
            "1.2225000009998819\n",
            "Error_max =  2.615150039251178e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17077952 -0.00793928 -0.04950028  0.02313028 -0.00685278 -0.01734105\n",
            "  0.00721428  0.01433872  0.00153004 -0.00660718 -0.00540259]\n",
            "1.2226000009998819\n",
            "Error_max =  2.6140215155884483e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1707983  -0.00795815 -0.04949217  0.02313548 -0.00685611 -0.01734431\n",
            "  0.00721659  0.01433694  0.00153075 -0.00660624 -0.00540142]\n",
            "1.2227000009998819\n",
            "Error_max =  2.612892681886249e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17081708 -0.00797702 -0.04948406  0.02314067 -0.00685944 -0.01734758\n",
            "  0.0072189   0.01433516  0.00153145 -0.00660531 -0.00540026]\n",
            "1.2228000009998818\n",
            "Error_max =  2.6117635386422117e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17083586 -0.00799589 -0.04947595  0.02314586 -0.00686277 -0.01735084\n",
            "  0.00722122  0.01433338  0.00153215 -0.00660437 -0.00539909]\n",
            "1.2229000009998818\n",
            "Error_max =  2.6106340863550273e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17085465 -0.00801476 -0.04946784  0.02315105 -0.00686611 -0.0173541\n",
            "  0.00722353  0.0143316   0.00153286 -0.00660343 -0.00539792]\n",
            "1.2230000009998818\n",
            "Error_max =  2.609504325500093e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17087344 -0.00803364 -0.04945972  0.02315623 -0.00686944 -0.01735737\n",
            "  0.00722584  0.01432981  0.00153356 -0.00660249 -0.00539675]\n",
            "1.2231000009998818\n",
            "Error_max =  2.6083742565760994e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17089223 -0.00805252 -0.04945161  0.02316142 -0.00687277 -0.01736063\n",
            "  0.00722816  0.01432803  0.00153427 -0.00660155 -0.00539558]\n",
            "1.2232000009998818\n",
            "Error_max =  2.607243880078561e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17091102 -0.0080714  -0.04944349  0.0231666  -0.00687611 -0.01736389\n",
            "  0.00723047  0.01432624  0.00153498 -0.00660061 -0.00539441]\n",
            "1.2233000009998818\n",
            "Error_max =  2.6061131964924035e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17092981 -0.00809028 -0.04943536  0.02317178 -0.00687944 -0.01736714\n",
            "  0.00723279  0.01432445  0.00153568 -0.00659967 -0.00539324]\n",
            "1.2234000009998818\n",
            "Error_max =  2.6049822063099654e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1709486  -0.00810916 -0.04942724  0.02317696 -0.00688277 -0.0173704\n",
            "  0.0072351   0.01432266  0.00153639 -0.00659873 -0.00539207]\n",
            "1.2235000009998818\n",
            "Error_max =  2.6038509100341725e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17096739 -0.00812805 -0.04941911  0.02318214 -0.00688611 -0.01737366\n",
            "  0.00723741  0.01432087  0.0015371  -0.00659779 -0.0053909 ]\n",
            "1.2236000009998818\n",
            "Error_max =  2.602719308134069e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17098619 -0.00814694 -0.04941098  0.02318732 -0.00688944 -0.01737691\n",
            "  0.00723973  0.01431908  0.0015378  -0.00659685 -0.00538973]\n",
            "1.2237000009998817\n",
            "Error_max =  2.601587401132698e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17100499 -0.00816583 -0.04940285  0.02319249 -0.00689277 -0.01738016\n",
            "  0.00724204  0.01431729  0.00153851 -0.00659591 -0.00538856]\n",
            "1.2238000009998817\n",
            "Error_max =  2.600455189489575e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17102379 -0.00818472 -0.04939471  0.02319767 -0.00689611 -0.01738342\n",
            "  0.00724436  0.01431549  0.00153922 -0.00659497 -0.00538738]\n",
            "1.2239000009998817\n",
            "Error_max =  2.599322673719272e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17104259 -0.00820362 -0.04938658  0.02320284 -0.00689944 -0.01738667\n",
            "  0.00724667  0.0143137   0.00153993 -0.00659403 -0.00538621]\n",
            "1.2240000009998817\n",
            "Error_max =  2.5981898543024803e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17106139 -0.00822252 -0.04937844  0.02320801 -0.00690278 -0.01738992\n",
            "  0.00724899  0.0143119   0.00154064 -0.00659309 -0.00538504]\n",
            "1.2241000009998817\n",
            "Error_max =  2.597056731733656e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17108019 -0.00824142 -0.04937029  0.02321318 -0.00690611 -0.01739317\n",
            "  0.0072513   0.0143101   0.00154134 -0.00659215 -0.00538386]\n",
            "1.2242000009998817\n",
            "Error_max =  2.59592330651043e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.171099   -0.00826032 -0.04936215  0.02321834 -0.00690945 -0.01739641\n",
            "  0.00725361  0.0143083   0.00154205 -0.00659121 -0.00538269]\n",
            "1.2243000009998817\n",
            "Error_max =  2.5947895791240824e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1711178  -0.00827922 -0.049354    0.02322351 -0.00691278 -0.01739966\n",
            "  0.00725593  0.0143065   0.00154276 -0.00659026 -0.00538152]\n",
            "1.2244000009998817\n",
            "Error_max =  2.593655550059539e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17113661 -0.00829813 -0.04934585  0.02322867 -0.00691612 -0.0174029\n",
            "  0.00725824  0.0143047   0.00154347 -0.00658932 -0.00538034]\n",
            "1.2245000009998817\n",
            "Error_max =  2.592521219808079e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17115542 -0.00831703 -0.0493377   0.02323383 -0.00691945 -0.01740615\n",
            "  0.00726056  0.0143029   0.00154419 -0.00658838 -0.00537917]\n",
            "1.2246000009998816\n",
            "Error_max =  2.5913865888747457e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17117423 -0.00833594 -0.04932955  0.023239   -0.00692279 -0.01740939\n",
            "  0.00726287  0.01430109  0.0015449  -0.00658744 -0.00537799]\n",
            "1.2247000009998816\n",
            "Error_max =  2.5902516577402304e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17119304 -0.00835485 -0.04932139  0.02324415 -0.00692613 -0.01741263\n",
            "  0.00726519  0.01429928  0.00154561 -0.00658649 -0.00537681]\n",
            "1.2248000009998816\n",
            "Error_max =  2.5891164269053414e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17121186 -0.00837377 -0.04931323  0.02324931 -0.00692946 -0.01741587\n",
            "  0.0072675   0.01429748  0.00154632 -0.00658555 -0.00537564]\n",
            "1.2249000009998816\n",
            "Error_max =  2.5879808968634753e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17123067 -0.00839268 -0.04930507  0.02325447 -0.0069328  -0.01741911\n",
            "  0.00726982  0.01429567  0.00154703 -0.00658461 -0.00537446]\n",
            "1.2250000009998816\n",
            "Error_max =  2.586845068097441e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17124949 -0.0084116  -0.0492969   0.02325962 -0.00693613 -0.01742235\n",
            "  0.00727213  0.01429386  0.00154774 -0.00658366 -0.00537328]\n",
            "1.2251000009998816\n",
            "Error_max =  2.585708941105929e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17126831 -0.00843052 -0.04928874  0.02326477 -0.00693947 -0.01742559\n",
            "  0.00727445  0.01429205  0.00154846 -0.00658272 -0.0053721 ]\n",
            "1.2252000009998816\n",
            "Error_max =  2.5845725163791595e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17128712 -0.00844944 -0.04928057  0.02326992 -0.00694281 -0.01742882\n",
            "  0.00727676  0.01429023  0.00154917 -0.00658178 -0.00537093]\n",
            "1.2253000009998816\n",
            "Error_max =  2.5834357944147647e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17130595 -0.00846837 -0.0492724   0.02327507 -0.00694614 -0.01743206\n",
            "  0.00727908  0.01428842  0.00154988 -0.00658083 -0.00536975]\n",
            "1.2254000009998816\n",
            "Error_max =  2.582298775695553e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17132477 -0.0084873  -0.04926422  0.02328022 -0.00694948 -0.01743529\n",
            "  0.00728139  0.0142866   0.0015506  -0.00657989 -0.00536857]\n",
            "1.2255000009998815\n",
            "Error_max =  2.581161460731862e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17134359 -0.00850622 -0.04925605  0.02328537 -0.00695282 -0.01743852\n",
            "  0.00728371  0.01428479  0.00155131 -0.00657894 -0.00536739]\n",
            "1.2256000009998815\n",
            "Error_max =  2.5800238499980304e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17136242 -0.00852515 -0.04924787  0.02329051 -0.00695616 -0.01744175\n",
            "  0.00728602  0.01428297  0.00155203 -0.006578   -0.00536621]\n",
            "1.2257000009998815\n",
            "Error_max =  2.578885943994866e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17138124 -0.00854409 -0.04923969  0.02329565 -0.00695949 -0.01744498\n",
            "  0.00728834  0.01428115  0.00155274 -0.00657705 -0.00536503]\n",
            "1.2258000009998815\n",
            "Error_max =  2.5777477432221183e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17140007 -0.00856302 -0.0492315   0.02330079 -0.00696283 -0.01744821\n",
            "  0.00729066  0.01427933  0.00155346 -0.00657611 -0.00536385]\n",
            "1.2259000009998815\n",
            "Error_max =  2.57660924816789e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1714189  -0.00858196 -0.04922332  0.02330593 -0.00696617 -0.01745144\n",
            "  0.00729297  0.01427751  0.00155417 -0.00657516 -0.00536267]\n",
            "1.2260000009998815\n",
            "Error_max =  2.575470459316049e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17143773 -0.0086009  -0.04921513  0.02331107 -0.00696951 -0.01745467\n",
            "  0.00729529  0.01427569  0.00155489 -0.00657422 -0.00536148]\n",
            "1.2261000009998815\n",
            "Error_max =  2.574331377174815e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17145657 -0.00861984 -0.04920694  0.02331621 -0.00697285 -0.01745789\n",
            "  0.0072976   0.01427386  0.0015556  -0.00657327 -0.0053603 ]\n",
            "1.2262000009998815\n",
            "Error_max =  2.5731920022259373e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1714754  -0.00863878 -0.04919874  0.02332134 -0.00697619 -0.01746111\n",
            "  0.00729992  0.01427204  0.00155632 -0.00657232 -0.00535912]\n",
            "1.2263000009998815\n",
            "Error_max =  2.572052334969166e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17149424 -0.00865773 -0.04919055  0.02332647 -0.00697952 -0.01746434\n",
            "  0.00730223  0.01427021  0.00155704 -0.00657138 -0.00535794]\n",
            "1.2264000009998814\n",
            "Error_max =  2.570912375898957e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17151307 -0.00867667 -0.04918235  0.0233316  -0.00698286 -0.01746756\n",
            "  0.00730455  0.01426838  0.00155775 -0.00657043 -0.00535675]\n",
            "1.2265000009998814\n",
            "Error_max =  2.5697721255044707e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17153191 -0.00869562 -0.04917415  0.02333673 -0.0069862  -0.01747078\n",
            "  0.00730687  0.01426655  0.00155847 -0.00656948 -0.00535557]\n",
            "1.2266000009998814\n",
            "Error_max =  2.56863158428334e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17155075 -0.00871457 -0.04916595  0.02334186 -0.00698954 -0.017474\n",
            "  0.00730918  0.01426472  0.00155919 -0.00656854 -0.00535439]\n",
            "1.2267000009998814\n",
            "Error_max =  2.5674907527204904e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17156959 -0.00873353 -0.04915774  0.02334699 -0.00699288 -0.01747721\n",
            "  0.0073115   0.01426289  0.00155991 -0.00656759 -0.0053532 ]\n",
            "1.2268000009998814\n",
            "Error_max =  2.5663496313220246e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17158843 -0.00875248 -0.04914953  0.02335211 -0.00699622 -0.01748043\n",
            "  0.00731381  0.01426106  0.00156063 -0.00656664 -0.00535202]\n",
            "1.2269000009998814\n",
            "Error_max =  2.5652082205696925e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17160728 -0.00877144 -0.04914132  0.02335724 -0.00699956 -0.01748365\n",
            "  0.00731613  0.01425922  0.00156135 -0.0065657  -0.00535083]\n",
            "1.2270000009998814\n",
            "Error_max =  2.5640665209685375e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17162612 -0.0087904  -0.04913311  0.02336236 -0.0070029  -0.01748686\n",
            "  0.00731845  0.01425739  0.00156207 -0.00656475 -0.00534964]\n",
            "1.2271000009998814\n",
            "Error_max =  2.562924532999251e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17164497 -0.00880936 -0.04912489  0.02336748 -0.00700624 -0.01749007\n",
            "  0.00732076  0.01425555  0.00156279 -0.0065638  -0.00534846]\n",
            "1.2272000009998814\n",
            "Error_max =  2.561782257165817e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17166382 -0.00882833 -0.04911668  0.02337259 -0.00700958 -0.01749328\n",
            "  0.00732308  0.01425371  0.00156351 -0.00656285 -0.00534727]\n",
            "1.2273000009998813\n",
            "Error_max =  2.560639693964809e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17168267 -0.00884729 -0.04910845  0.02337771 -0.00701292 -0.01749649\n",
            "  0.00732539  0.01425187  0.00156423 -0.0065619  -0.00534608]\n",
            "1.2274000009998813\n",
            "Error_max =  2.5594968438800947e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17170152 -0.00886626 -0.04910023  0.02338283 -0.00701627 -0.0174997\n",
            "  0.00732771  0.01425003  0.00156495 -0.00656095 -0.0053449 ]\n",
            "1.2275000009998813\n",
            "Error_max =  2.558353707408247e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17172037 -0.00888523 -0.04909201  0.02338794 -0.00701961 -0.01750291\n",
            "  0.00733003  0.01424819  0.00156567 -0.00656    -0.00534371]\n",
            "1.2276000009998813\n",
            "Error_max =  2.557210285050074e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17173923 -0.0089042  -0.04908378  0.02339305 -0.00702295 -0.01750612\n",
            "  0.00733234  0.01424635  0.00156639 -0.00655905 -0.00534252]\n",
            "1.2277000009998813\n",
            "Error_max =  2.5560665772883844e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17175808 -0.00892318 -0.04907555  0.02339816 -0.00702629 -0.01750932\n",
            "  0.00733466  0.0142445   0.00156711 -0.0065581  -0.00534133]\n",
            "1.2278000009998813\n",
            "Error_max =  2.5549225846261044e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17177694 -0.00894215 -0.04906732  0.02340327 -0.00702963 -0.01751253\n",
            "  0.00733698  0.01424266  0.00156783 -0.00655715 -0.00534014]\n",
            "1.2279000009998813\n",
            "Error_max =  2.5537783075566304e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1717958  -0.00896113 -0.04905908  0.02340838 -0.00703297 -0.01751573\n",
            "  0.00733929  0.01424081  0.00156856 -0.0065562  -0.00533895]\n",
            "1.2280000009998813\n",
            "Error_max =  2.5526337465733593e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17181466 -0.00898011 -0.04905085  0.02341348 -0.00703632 -0.01751893\n",
            "  0.00734161  0.01423896  0.00156928 -0.00655525 -0.00533776]\n",
            "1.2281000009998813\n",
            "Error_max =  2.5514889021654525e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17183352 -0.00899909 -0.04904261  0.02341858 -0.00703966 -0.01752213\n",
            "  0.00734392  0.01423711  0.00157    -0.0065543  -0.00533657]\n",
            "1.2282000009998812\n",
            "Error_max =  2.5503437748316006e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17185238 -0.00901808 -0.04903436  0.02342369 -0.007043   -0.01752533\n",
            "  0.00734624  0.01423526  0.00157073 -0.00655335 -0.00533538]\n",
            "1.2283000009998812\n",
            "Error_max =  2.5491983650704943e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17187125 -0.00903706 -0.04902612  0.02342879 -0.00704634 -0.01752853\n",
            "  0.00734856  0.01423341  0.00157145 -0.0065524  -0.00533419]\n",
            "1.2284000009998812\n",
            "Error_max =  2.548052673372354e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17189011 -0.00905605 -0.04901787  0.02343389 -0.00704969 -0.01753173\n",
            "  0.00735087  0.01423155  0.00157218 -0.00655145 -0.005333  ]\n",
            "1.2285000009998812\n",
            "Error_max =  2.546906700225282e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17190898 -0.00907504 -0.04900962  0.02343898 -0.00705303 -0.01753493\n",
            "  0.00735319  0.0142297   0.0015729  -0.0065505  -0.00533181]\n",
            "1.2286000009998812\n",
            "Error_max =  2.545760446133264e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17192785 -0.00909403 -0.04900137  0.02344408 -0.00705637 -0.01753812\n",
            "  0.00735551  0.01422784  0.00157363 -0.00654955 -0.00533061]\n",
            "1.2287000009998812\n",
            "Error_max =  2.544613911580166e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17194672 -0.00911303 -0.04899312  0.02344917 -0.00705972 -0.01754131\n",
            "  0.00735782  0.01422599  0.00157435 -0.00654859 -0.00532942]\n",
            "1.2288000009998812\n",
            "Error_max =  2.543467097075268e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17196559 -0.00913203 -0.04898486  0.02345426 -0.00706306 -0.01754451\n",
            "  0.00736014  0.01422413  0.00157508 -0.00654764 -0.00532823]\n",
            "1.2289000009998812\n",
            "Error_max =  2.5423200031045544e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17198446 -0.00915102 -0.0489766   0.02345935 -0.0070664  -0.0175477\n",
            "  0.00736246  0.01422227  0.0015758  -0.00654669 -0.00532703]\n",
            "1.2290000009998812\n",
            "Error_max =  2.541172630165657e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17200334 -0.00917003 -0.04896834  0.02346444 -0.00706975 -0.01755089\n",
            "  0.00736477  0.01422041  0.00157653 -0.00654574 -0.00532584]\n",
            "1.2291000009998811\n",
            "Error_max =  2.540024978750914e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17202221 -0.00918903 -0.04896008  0.02346953 -0.00707309 -0.01755408\n",
            "  0.00736709  0.01421855  0.00157726 -0.00654478 -0.00532464]\n",
            "1.2292000009998811\n",
            "Error_max =  2.5388770493516047e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17204109 -0.00920803 -0.04895181  0.02347462 -0.00707644 -0.01755726\n",
            "  0.00736941  0.01421668  0.00157798 -0.00654383 -0.00532345]\n",
            "1.2293000009998811\n",
            "Error_max =  2.537728842477007e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17205997 -0.00922704 -0.04894354  0.0234797  -0.00707978 -0.01756045\n",
            "  0.00737172  0.01421482  0.00157871 -0.00654288 -0.00532225]\n",
            "1.2294000009998811\n",
            "Error_max =  2.5365803585993424e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17207885 -0.00924605 -0.04893527  0.02348478 -0.00708313 -0.01756363\n",
            "  0.00737404  0.01421295  0.00157944 -0.00654192 -0.00532106]\n",
            "1.229500000999881\n",
            "Error_max =  2.535431598223654e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17209773 -0.00926506 -0.048927    0.02348986 -0.00708647 -0.01756682\n",
            "  0.00737636  0.01421108  0.00158017 -0.00654097 -0.00531986]\n",
            "1.229600000999881\n",
            "Error_max =  2.534282561854985e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17211661 -0.00928407 -0.04891872  0.02349494 -0.00708982 -0.01757\n",
            "  0.00737867  0.01420922  0.0015809  -0.00654002 -0.00531866]\n",
            "1.229700000999881\n",
            "Error_max =  2.53313324998038e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1721355  -0.00930309 -0.04891044  0.02350002 -0.00709316 -0.01757318\n",
            "  0.00738099  0.01420735  0.00158162 -0.00653906 -0.00531747]\n",
            "1.229800000999881\n",
            "Error_max =  2.53198366309747e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17215438 -0.00932211 -0.04890216  0.0235051  -0.00709651 -0.01757636\n",
            "  0.00738331  0.01420548  0.00158235 -0.00653811 -0.00531627]\n",
            "1.229900000999881\n",
            "Error_max =  2.530833801695417e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17217327 -0.00934112 -0.04889388  0.02351017 -0.00709986 -0.01757954\n",
            "  0.00738562  0.0142036   0.00158308 -0.00653715 -0.00531507]\n",
            "1.230000000999881\n",
            "Error_max =  2.5296836662655003e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17219216 -0.00936015 -0.04888559  0.02351524 -0.0071032  -0.01758272\n",
            "  0.00738794  0.01420173  0.00158381 -0.0065362  -0.00531387]\n",
            "1.230100000999881\n",
            "Error_max =  2.5285332573095866e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17221105 -0.00937917 -0.04887731  0.02352031 -0.00710655 -0.01758589\n",
            "  0.00739026  0.01419986  0.00158454 -0.00653524 -0.00531267]\n",
            "1.230200000999881\n",
            "Error_max =  2.527382575330602e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17222994 -0.00939819 -0.04886902  0.02352538 -0.0071099  -0.01758907\n",
            "  0.00739258  0.01419798  0.00158527 -0.00653429 -0.00531148]\n",
            "1.230300000999881\n",
            "Error_max =  2.526231620819825e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17224883 -0.00941722 -0.04886072  0.02353045 -0.00711324 -0.01759224\n",
            "  0.00739489  0.0141961   0.001586   -0.00653333 -0.00531028]\n",
            "1.230400000999881\n",
            "Error_max =  2.525080394260065e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17226773 -0.00943625 -0.04885243  0.02353552 -0.00711659 -0.01759541\n",
            "  0.00739721  0.01419422  0.00158674 -0.00653237 -0.00530908]\n",
            "1.230500000999881\n",
            "Error_max =  2.5239288961595415e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17228662 -0.00945528 -0.04884413  0.02354058 -0.00711994 -0.01759859\n",
            "  0.00739953  0.01419234  0.00158747 -0.00653142 -0.00530788]\n",
            "1.230600000999881\n",
            "Error_max =  2.5227771270052986e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17230552 -0.00947432 -0.04883583  0.02354565 -0.00712328 -0.01760176\n",
            "  0.00740184  0.01419046  0.0015882  -0.00653046 -0.00530667]\n",
            "1.230700000999881\n",
            "Error_max =  2.521625087300262e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17232442 -0.00949335 -0.04882753  0.02355071 -0.00712663 -0.01760493\n",
            "  0.00740416  0.01418858  0.00158893 -0.0065295  -0.00530547]\n",
            "1.230800000999881\n",
            "Error_max =  2.520472777539946e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17234332 -0.00951239 -0.04881922  0.02355577 -0.00712998 -0.01760809\n",
            "  0.00740648  0.0141867   0.00158966 -0.00652855 -0.00530427]\n",
            "1.230900000999881\n",
            "Error_max =  2.5193201982061004e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17236222 -0.00953143 -0.04881092  0.02356083 -0.00713333 -0.01761126\n",
            "  0.00740879  0.01418481  0.0015904  -0.00652759 -0.00530307]\n",
            "1.231000000999881\n",
            "Error_max =  2.518167349822827e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17238112 -0.00955047 -0.04880261  0.02356588 -0.00713668 -0.01761442\n",
            "  0.00741111  0.01418293  0.00159113 -0.00652663 -0.00530187]\n",
            "1.231100000999881\n",
            "Error_max =  2.5170142328559943e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17240003 -0.00956951 -0.0487943   0.02357094 -0.00714003 -0.01761759\n",
            "  0.00741343  0.01418104  0.00159186 -0.00652567 -0.00530066]\n",
            "1.231200000999881\n",
            "Error_max =  2.515860847810645e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17241893 -0.00958856 -0.04878598  0.02357599 -0.00714337 -0.01762075\n",
            "  0.00741574  0.01417915  0.0015926  -0.00652472 -0.00529946]\n",
            "1.231300000999881\n",
            "Error_max =  2.514707195186529e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17243784 -0.00960761 -0.04877766  0.02358104 -0.00714672 -0.01762391\n",
            "  0.00741806  0.01417726  0.00159333 -0.00652376 -0.00529826]\n",
            "1.231400000999881\n",
            "Error_max =  2.513553275483396e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17245675 -0.00962666 -0.04876935  0.02358609 -0.00715007 -0.01762707\n",
            "  0.00742038  0.01417537  0.00159407 -0.0065228  -0.00529705]\n",
            "1.2315000009998809\n",
            "Error_max =  2.512399089177701e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17247566 -0.00964571 -0.04876102  0.02359114 -0.00715342 -0.01763023\n",
            "  0.0074227   0.01417348  0.0015948  -0.00652184 -0.00529585]\n",
            "1.2316000009998809\n",
            "Error_max =  2.5112446367829586e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17249457 -0.00966476 -0.0487527   0.02359619 -0.00715677 -0.01763339\n",
            "  0.00742501  0.01417159  0.00159554 -0.00652088 -0.00529464]\n",
            "1.2317000009998809\n",
            "Error_max =  2.5100899187957417e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17251348 -0.00968382 -0.04874437  0.02360123 -0.00716012 -0.01763655\n",
            "  0.00742733  0.01416969  0.00159627 -0.00651992 -0.00529344]\n",
            "1.2318000009998809\n",
            "Error_max =  2.508934935703094e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17253239 -0.00970288 -0.04873605  0.02360628 -0.00716347 -0.0176397\n",
            "  0.00742965  0.0141678   0.00159701 -0.00651896 -0.00529223]\n",
            "1.2319000009998808\n",
            "Error_max =  2.5077796880079417e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17255131 -0.00972194 -0.04872771  0.02361132 -0.00716682 -0.01764286\n",
            "  0.00743196  0.0141659   0.00159774 -0.006518   -0.00529103]\n",
            "1.2320000009998808\n",
            "Error_max =  2.506624176199446e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17257023 -0.009741   -0.04871938  0.02361636 -0.00717017 -0.01764601\n",
            "  0.00743428  0.014164    0.00159848 -0.00651704 -0.00528982]\n",
            "1.2321000009998808\n",
            "Error_max =  2.5054684007731214e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17258914 -0.00976006 -0.04871104  0.0236214  -0.00717352 -0.01764916\n",
            "  0.0074366   0.0141621   0.00159922 -0.00651608 -0.00528861]\n",
            "1.2322000009998808\n",
            "Error_max =  2.504312362230835e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17260806 -0.00977913 -0.04870271  0.02362644 -0.00717687 -0.01765231\n",
            "  0.00743891  0.0141602   0.00159995 -0.00651512 -0.0052874 ]\n",
            "1.2323000009998808\n",
            "Error_max =  2.503156061065983e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17262698 -0.0097982  -0.04869437  0.02363147 -0.00718023 -0.01765546\n",
            "  0.00744123  0.0141583   0.00160069 -0.00651416 -0.0052862 ]\n",
            "1.2324000009998808\n",
            "Error_max =  2.5019994977761974e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17264591 -0.00981727 -0.04868602  0.02363651 -0.00718358 -0.01765861\n",
            "  0.00744355  0.01415639  0.00160143 -0.0065132  -0.00528499]\n",
            "1.2325000009998808\n",
            "Error_max =  2.5008426728527577e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17266483 -0.00983634 -0.04867768  0.02364154 -0.00718693 -0.01766175\n",
            "  0.00744587  0.01415449  0.00160217 -0.00651224 -0.00528378]\n",
            "1.2326000009998808\n",
            "Error_max =  2.499685586799648e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17268376 -0.00985541 -0.04866933  0.02364657 -0.00719028 -0.0176649\n",
            "  0.00744818  0.01415258  0.00160291 -0.00651128 -0.00528257]\n",
            "1.2327000009998808\n",
            "Error_max =  2.498528240109207e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17270268 -0.00987449 -0.04866098  0.0236516  -0.00719363 -0.01766804\n",
            "  0.0074505   0.01415068  0.00160365 -0.00651032 -0.00528136]\n",
            "1.2328000009998807\n",
            "Error_max =  2.497370633272713e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17272161 -0.00989357 -0.04865263  0.02365663 -0.00719698 -0.01767118\n",
            "  0.00745282  0.01414877  0.00160439 -0.00650936 -0.00528015]\n",
            "1.2329000009998807\n",
            "Error_max =  2.4962127667909745e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17274054 -0.00991265 -0.04864427  0.02366165 -0.00720034 -0.01767433\n",
            "  0.00745513  0.01414686  0.00160512 -0.00650839 -0.00527894]\n",
            "1.2330000009998807\n",
            "Error_max =  2.495054641157388e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17275947 -0.00993173 -0.04863591  0.02366668 -0.00720369 -0.01767747\n",
            "  0.00745745  0.01414495  0.00160586 -0.00650743 -0.00527773]\n",
            "1.2331000009998807\n",
            "Error_max =  2.4938962568759387e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1727784  -0.00995081 -0.04862755  0.0236717  -0.00720704 -0.01768061\n",
            "  0.00745977  0.01414304  0.0016066  -0.00650647 -0.00527652]\n",
            "1.2332000009998807\n",
            "Error_max =  2.492737614438964e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17279733 -0.0099699  -0.04861919  0.02367672 -0.0072104  -0.01768374\n",
            "  0.00746208  0.01414112  0.00160735 -0.00650551 -0.00527531]\n",
            "1.2333000009998807\n",
            "Error_max =  2.491578714332449e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17281627 -0.00998899 -0.04861083  0.02368174 -0.00721375 -0.01768688\n",
            "  0.0074644   0.01413921  0.00160809 -0.00650454 -0.0052741 ]\n",
            "1.2334000009998807\n",
            "Error_max =  2.490419557068849e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1728352  -0.01000808 -0.04860246  0.02368676 -0.0072171  -0.01769001\n",
            "  0.00746672  0.0141373   0.00160883 -0.00650358 -0.00527288]\n",
            "1.2335000009998807\n",
            "Error_max =  2.48926014313309e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17285414 -0.01002717 -0.04859409  0.02369178 -0.00722046 -0.01769315\n",
            "  0.00746903  0.01413538  0.00160957 -0.00650262 -0.00527167]\n",
            "1.2336000009998807\n",
            "Error_max =  2.488100473029157e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17287308 -0.01004626 -0.04858572  0.02369679 -0.00722381 -0.01769628\n",
            "  0.00747135  0.01413346  0.00161031 -0.00650165 -0.00527046]\n",
            "1.2337000009998806\n",
            "Error_max =  2.486940547251505e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17289202 -0.01006536 -0.04857734  0.0237018  -0.00722717 -0.01769941\n",
            "  0.00747367  0.01413154  0.00161105 -0.00650069 -0.00526924]\n",
            "1.2338000009998806\n",
            "Error_max =  2.4857803662903545e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17291096 -0.01008446 -0.04856897  0.02370682 -0.00723052 -0.01770254\n",
            "  0.00747598  0.01412962  0.0016118  -0.00649972 -0.00526803]\n",
            "1.2339000009998806\n",
            "Error_max =  2.484619930647573e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17292991 -0.01010356 -0.04856059  0.02371183 -0.00723387 -0.01770567\n",
            "  0.0074783   0.0141277   0.00161254 -0.00649876 -0.00526682]\n",
            "1.2340000009998806\n",
            "Error_max =  2.4834592408303205e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17294885 -0.01012266 -0.04855221  0.02371683 -0.00723723 -0.0177088\n",
            "  0.00748062  0.01412578  0.00161328 -0.00649779 -0.0052656 ]\n",
            "1.2341000009998806\n",
            "Error_max =  2.482298297319289e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1729678  -0.01014176 -0.04854382  0.02372184 -0.00724059 -0.01771193\n",
            "  0.00748293  0.01412385  0.00161403 -0.00649683 -0.00526439]\n",
            "1.2342000009998806\n",
            "Error_max =  2.4811371006068163e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17298674 -0.01016087 -0.04853544  0.02372685 -0.00724394 -0.01771505\n",
            "  0.00748525  0.01412193  0.00161477 -0.00649586 -0.00526317]\n",
            "1.2343000009998806\n",
            "Error_max =  2.4799756512042983e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17300569 -0.01017998 -0.04852705  0.02373185 -0.0072473  -0.01771817\n",
            "  0.00748757  0.01412     0.00161551 -0.0064949  -0.00526195]\n",
            "1.2344000009998806\n",
            "Error_max =  2.4788139496072493e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17302464 -0.01019909 -0.04851866  0.02373685 -0.00725065 -0.0177213\n",
            "  0.00748988  0.01411807  0.00161626 -0.00649393 -0.00526074]\n",
            "1.2345000009998806\n",
            "Error_max =  2.4776519963027134e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17304359 -0.0102182  -0.04851026  0.02374185 -0.00725401 -0.01772442\n",
            "  0.0074922   0.01411614  0.001617   -0.00649297 -0.00525952]\n",
            "1.2346000009998805\n",
            "Error_max =  2.476489791795734e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17306254 -0.01023732 -0.04850187  0.02374685 -0.00725736 -0.01772754\n",
            "  0.00749452  0.01411421  0.00161775 -0.006492   -0.0052583 ]\n",
            "1.2347000009998805\n",
            "Error_max =  2.475327336578649e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1730815  -0.01025643 -0.04849347  0.02375185 -0.00726072 -0.01773066\n",
            "  0.00749683  0.01411228  0.00161849 -0.00649103 -0.00525709]\n",
            "1.2348000009998805\n",
            "Error_max =  2.4741646311554425e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17310045 -0.01027555 -0.04848507  0.02375684 -0.00726408 -0.01773378\n",
            "  0.00749915  0.01411035  0.00161924 -0.00649007 -0.00525587]\n",
            "1.2349000009998805\n",
            "Error_max =  2.473001676008924e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17311941 -0.01029467 -0.04847667  0.02376184 -0.00726744 -0.01773689\n",
            "  0.00750146  0.01410842  0.00161998 -0.0064891  -0.00525465]\n",
            "1.2350000009998805\n",
            "Error_max =  2.4718384716536656e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17313837 -0.01031379 -0.04846826  0.02376683 -0.00727079 -0.01774001\n",
            "  0.00750378  0.01410648  0.00162073 -0.00648813 -0.00525343]\n",
            "1.2351000009998805\n",
            "Error_max =  2.470675018562947e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17315733 -0.01033292 -0.04845986  0.02377182 -0.00727415 -0.01774312\n",
            "  0.0075061   0.01410455  0.00162148 -0.00648716 -0.00525221]\n",
            "1.2352000009998805\n",
            "Error_max =  2.4695113172587526e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17317629 -0.01035204 -0.04845145  0.02377681 -0.00727751 -0.01774623\n",
            "  0.00750841  0.01410261  0.00162223 -0.0064862  -0.00525099]\n",
            "1.2353000009998805\n",
            "Error_max =  2.4683473682249495e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17319525 -0.01037117 -0.04844303  0.0237818  -0.00728087 -0.01774934\n",
            "  0.00751073  0.01410067  0.00162297 -0.00648523 -0.00524977]\n",
            "1.2354000009998805\n",
            "Error_max =  2.4671831719612874e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17321421 -0.0103903  -0.04843462  0.02378679 -0.00728422 -0.01775245\n",
            "  0.00751305  0.01409873  0.00162372 -0.00648426 -0.00524855]\n",
            "1.2355000009998804\n",
            "Error_max =  2.466018728961163e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17323318 -0.01040943 -0.0484262   0.02379177 -0.00728758 -0.01775556\n",
            "  0.00751536  0.01409679  0.00162447 -0.00648329 -0.00524733]\n",
            "1.2356000009998804\n",
            "Error_max =  2.4648540397243255e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17325214 -0.01042857 -0.04841778  0.02379675 -0.00729094 -0.01775867\n",
            "  0.00751768  0.01409485  0.00162522 -0.00648232 -0.00524611]\n",
            "1.2357000009998804\n",
            "Error_max =  2.4636891047568774e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17327111 -0.0104477  -0.04840936  0.02380173 -0.0072943  -0.01776178\n",
            "  0.00751999  0.0140929   0.00162597 -0.00648135 -0.00524489]\n",
            "1.2358000009998804\n",
            "Error_max =  2.4625239245342157e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17329008 -0.01046684 -0.04840094  0.02380671 -0.00729766 -0.01776488\n",
            "  0.00752231  0.01409096  0.00162671 -0.00648038 -0.00524367]\n",
            "1.2359000009998804\n",
            "Error_max =  2.4613584995793834e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17330905 -0.01048598 -0.04839251  0.02381169 -0.00730102 -0.01776798\n",
            "  0.00752463  0.01408901  0.00162746 -0.00647941 -0.00524244]\n",
            "1.2360000009998804\n",
            "Error_max =  2.4601928303741304e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17332802 -0.01050512 -0.04838408  0.02381667 -0.00730438 -0.01777109\n",
            "  0.00752694  0.01408707  0.00162821 -0.00647844 -0.00524122]\n",
            "1.2361000009998804\n",
            "Error_max =  2.4590269174065595e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17334699 -0.01052427 -0.04837565  0.02382164 -0.00730774 -0.01777419\n",
            "  0.00752926  0.01408512  0.00162896 -0.00647747 -0.00524   ]\n",
            "1.2362000009998804\n",
            "Error_max =  2.457860761196537e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17336597 -0.01054341 -0.04836722  0.02382662 -0.0073111  -0.01777729\n",
            "  0.00753157  0.01408317  0.00162971 -0.0064765  -0.00523878]\n",
            "1.2363000009998804\n",
            "Error_max =  2.4566943622258133e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17338494 -0.01056256 -0.04835878  0.02383159 -0.00731446 -0.01778038\n",
            "  0.00753389  0.01408122  0.00163046 -0.00647553 -0.00523755]\n",
            "1.2364000009998803\n",
            "Error_max =  2.4555277209930786e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17340392 -0.01058171 -0.04835034  0.02383656 -0.00731782 -0.01778348\n",
            "  0.0075362   0.01407927  0.00163121 -0.00647456 -0.00523633]\n",
            "1.2365000009998803\n",
            "Error_max =  2.4543608380033765e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1734229  -0.01060086 -0.0483419   0.02384153 -0.00732118 -0.01778658\n",
            "  0.00753852  0.01407731  0.00163197 -0.00647359 -0.0052351 ]\n",
            "1.2366000009998803\n",
            "Error_max =  2.453193713749045e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17344188 -0.01062002 -0.04833346  0.02384649 -0.00732454 -0.01778967\n",
            "  0.00754084  0.01407536  0.00163272 -0.00647262 -0.00523388]\n",
            "1.2367000009998803\n",
            "Error_max =  2.452026348721363e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17346086 -0.01063917 -0.04832501  0.02385146 -0.0073279  -0.01779277\n",
            "  0.00754315  0.0140734   0.00163347 -0.00647165 -0.00523265]\n",
            "1.2368000009998803\n",
            "Error_max =  2.45085874342855e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17347984 -0.01065833 -0.04831656  0.02385642 -0.00733126 -0.01779586\n",
            "  0.00754547  0.01407145  0.00163422 -0.00647068 -0.00523143]\n",
            "1.2369000009998803\n",
            "Error_max =  2.449690898365062e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17349883 -0.01067749 -0.04830811  0.02386139 -0.00733463 -0.01779895\n",
            "  0.00754778  0.01406949  0.00163497 -0.00646971 -0.0052302 ]\n",
            "1.2370000009998803\n",
            "Error_max =  2.4485228140200606e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17351781 -0.01069665 -0.04829966  0.02386635 -0.00733799 -0.01780204\n",
            "  0.0075501   0.01406753  0.00163573 -0.00646873 -0.00522897]\n",
            "1.2371000009998803\n",
            "Error_max =  2.447354490898589e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1735368  -0.01071582 -0.04829121  0.0238713  -0.00734135 -0.01780513\n",
            "  0.00755241  0.01406557  0.00163648 -0.00646776 -0.00522775]\n",
            "1.2372000009998803\n",
            "Error_max =  2.446185929500396e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17355579 -0.01073498 -0.04828275  0.02387626 -0.00734471 -0.01780821\n",
            "  0.00755473  0.01406361  0.00163723 -0.00646679 -0.00522652]\n",
            "1.2373000009998802\n",
            "Error_max =  2.445017130311468e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17357477 -0.01075415 -0.04827429  0.02388122 -0.00734807 -0.0178113\n",
            "  0.00755704  0.01406164  0.00163799 -0.00646581 -0.00522529]\n",
            "1.2374000009998802\n",
            "Error_max =  2.4438480938410826e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17359376 -0.01077332 -0.04826583  0.02388617 -0.00735144 -0.01781438\n",
            "  0.00755936  0.01405968  0.00163874 -0.00646484 -0.00522406]\n",
            "1.2375000009998802\n",
            "Error_max =  2.442678820585813e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17361276 -0.01079249 -0.04825736  0.02389112 -0.0073548  -0.01781746\n",
            "  0.00756167  0.01405772  0.0016395  -0.00646387 -0.00522283]\n",
            "1.2376000009998802\n",
            "Error_max =  2.4415093110379977e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17363175 -0.01081167 -0.0482489   0.02389608 -0.00735816 -0.01782055\n",
            "  0.00756399  0.01405575  0.00164025 -0.00646289 -0.0052216 ]\n",
            "1.2377000009998802\n",
            "Error_max =  2.440339565688915e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17365074 -0.01083084 -0.04824043  0.02390103 -0.00736153 -0.01782363\n",
            "  0.0075663   0.01405378  0.00164101 -0.00646192 -0.00522037]\n",
            "1.2378000009998802\n",
            "Error_max =  2.439169585048903e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17366974 -0.01085002 -0.04823196  0.02390597 -0.00736489 -0.01782671\n",
            "  0.00756862  0.01405181  0.00164176 -0.00646094 -0.00521914]\n",
            "1.2379000009998802\n",
            "Error_max =  2.4379993696124166e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17368874 -0.0108692  -0.04822348  0.02391092 -0.00736826 -0.01782978\n",
            "  0.00757093  0.01404984  0.00164252 -0.00645997 -0.00521791]\n",
            "1.2380000009998802\n",
            "Error_max =  2.436828919877088e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17370773 -0.01088838 -0.04821501  0.02391586 -0.00737162 -0.01783286\n",
            "  0.00757325  0.01404787  0.00164327 -0.006459   -0.00521668]\n",
            "1.2381000009998802\n",
            "Error_max =  2.4356582363310196e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17372673 -0.01090756 -0.04820653  0.02392081 -0.00737498 -0.01783593\n",
            "  0.00757556  0.0140459   0.00164403 -0.00645802 -0.00521545]\n",
            "1.2382000009998801\n",
            "Error_max =  2.4344873194824314e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17374574 -0.01092675 -0.04819805  0.02392575 -0.00737835 -0.01783901\n",
            "  0.00757788  0.01404393  0.00164478 -0.00645704 -0.00521422]\n",
            "1.2383000009998801\n",
            "Error_max =  2.433316169825779e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17376474 -0.01094594 -0.04818956  0.02393069 -0.00738172 -0.01784208\n",
            "  0.00758019  0.01404195  0.00164554 -0.00645607 -0.00521299]\n",
            "1.2384000009998801\n",
            "Error_max =  2.432144787863988e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17378374 -0.01096513 -0.04818108  0.02393563 -0.00738508 -0.01784515\n",
            "  0.00758251  0.01403998  0.0016463  -0.00645509 -0.00521176]\n",
            "1.2385000009998801\n",
            "Error_max =  2.430973174076691e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17380275 -0.01098432 -0.04817259  0.02394056 -0.00738845 -0.01784822\n",
            "  0.00758482  0.014038    0.00164706 -0.00645412 -0.00521052]\n",
            "1.23860000099988\n",
            "Error_max =  2.4298013289911655e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17382175 -0.01100351 -0.0481641   0.0239455  -0.00739181 -0.01785129\n",
            "  0.00758714  0.01403602  0.00164781 -0.00645314 -0.00520929]\n",
            "1.23870000099988\n",
            "Error_max =  2.4286292530732803e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17384076 -0.01102271 -0.04815561  0.02395043 -0.00739518 -0.01785436\n",
            "  0.00758945  0.01403404  0.00164857 -0.00645216 -0.00520806]\n",
            "1.23880000099988\n",
            "Error_max =  2.427456946846078e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17385977 -0.0110419  -0.04814711  0.02395536 -0.00739854 -0.01785742\n",
            "  0.00759177  0.01403206  0.00164933 -0.00645119 -0.00520682]\n",
            "1.23890000099988\n",
            "Error_max =  2.4262844107997786e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17387878 -0.0110611  -0.04813861  0.0239603  -0.00740191 -0.01786049\n",
            "  0.00759408  0.01403008  0.00165009 -0.00645021 -0.00520559]\n",
            "1.23900000099988\n",
            "Error_max =  2.425111645415074e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17389779 -0.0110803  -0.04813011  0.02396522 -0.00740528 -0.01786355\n",
            "  0.00759639  0.0140281   0.00165085 -0.00644923 -0.00520435]\n",
            "1.23910000099988\n",
            "Error_max =  2.423938651209712e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1739168  -0.01109951 -0.04812161  0.02397015 -0.00740865 -0.01786661\n",
            "  0.00759871  0.01402611  0.00165161 -0.00644825 -0.00520312]\n",
            "1.23920000099988\n",
            "Error_max =  2.422765428680267e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17393582 -0.01111871 -0.04811311  0.02397508 -0.00741201 -0.01786968\n",
            "  0.00760102  0.01402413  0.00165237 -0.00644728 -0.00520188]\n",
            "1.23930000099988\n",
            "Error_max =  2.4215919783158994e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17395483 -0.01113792 -0.0481046   0.02398    -0.00741538 -0.01787273\n",
            "  0.00760334  0.01402214  0.00165313 -0.0064463  -0.00520065]\n",
            "1.23940000099988\n",
            "Error_max =  2.4204183006248296e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17397385 -0.01115713 -0.04809609  0.02398492 -0.00741875 -0.01787579\n",
            "  0.00760565  0.01402015  0.00165389 -0.00644532 -0.00519941]\n",
            "1.23950000099988\n",
            "Error_max =  2.419244396089866e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17399287 -0.01117634 -0.04808758  0.02398984 -0.00742212 -0.01787885\n",
            "  0.00760796  0.01401817  0.00165465 -0.00644434 -0.00519817]\n",
            "1.23960000099988\n",
            "Error_max =  2.418070265227699e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17401189 -0.01119555 -0.04807907  0.02399476 -0.00742548 -0.01788191\n",
            "  0.00761028  0.01401618  0.00165541 -0.00644336 -0.00519694]\n",
            "1.23970000099988\n",
            "Error_max =  2.4168959085105496e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17403091 -0.01121477 -0.04807055  0.02399968 -0.00742885 -0.01788496\n",
            "  0.00761259  0.01401418  0.00165617 -0.00644238 -0.0051957 ]\n",
            "1.23980000099988\n",
            "Error_max =  2.4157213264656954e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17404993 -0.01123398 -0.04806203  0.0240046  -0.00743222 -0.01788801\n",
            "  0.0076149   0.01401219  0.00165693 -0.0064414  -0.00519446]\n",
            "1.23990000099988\n",
            "Error_max =  2.4145465195706514e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17406896 -0.0112532  -0.04805351  0.02400951 -0.00743559 -0.01789106\n",
            "  0.00761722  0.0140102   0.00165769 -0.00644042 -0.00519322]\n",
            "1.24000000099988\n",
            "Error_max =  2.413371488329402e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17408798 -0.01127242 -0.04804499  0.02401443 -0.00743896 -0.01789411\n",
            "  0.00761953  0.0140082   0.00165846 -0.00643944 -0.00519199]\n",
            "1.24010000099988\n",
            "Error_max =  2.4121962332501675e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17410701 -0.01129165 -0.04803646  0.02401934 -0.00744233 -0.01789716\n",
            "  0.00762184  0.01400621  0.00165922 -0.00643846 -0.00519075]\n",
            "1.24020000099988\n",
            "Error_max =  2.4110207548041095e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17412603 -0.01131087 -0.04802793  0.02402425 -0.0074457  -0.01790021\n",
            "  0.00762416  0.01400421  0.00165998 -0.00643748 -0.00518951]\n",
            "1.24030000099988\n",
            "Error_max =  2.4098450535216826e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17414506 -0.0113301  -0.0480194   0.02402916 -0.00744907 -0.01790326\n",
            "  0.00762647  0.01400221  0.00166074 -0.0064365  -0.00518827]\n",
            "1.24040000099988\n",
            "Error_max =  2.408669129877225e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17416409 -0.01134933 -0.04801087  0.02403406 -0.00745244 -0.0179063\n",
            "  0.00762878  0.01400021  0.00166151 -0.00643552 -0.00518703]\n",
            "1.24050000099988\n",
            "Error_max =  2.407492984372604e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17418312 -0.01136856 -0.04800233  0.02403897 -0.00745581 -0.01790935\n",
            "  0.0076311   0.01399821  0.00166227 -0.00643454 -0.00518579]\n",
            "1.2406000009998799\n",
            "Error_max =  2.4063166175202745e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17420216 -0.01138779 -0.0479938   0.02404387 -0.00745918 -0.01791239\n",
            "  0.00763341  0.01399621  0.00166303 -0.00643356 -0.00518455]\n",
            "1.2407000009998799\n",
            "Error_max =  2.405140029799869e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17422119 -0.01140702 -0.04798526  0.02404877 -0.00746255 -0.01791543\n",
            "  0.00763572  0.01399421  0.0016638  -0.00643258 -0.0051833 ]\n",
            "1.2408000009998799\n",
            "Error_max =  2.403963221721724e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17424022 -0.01142626 -0.04797672  0.02405367 -0.00746593 -0.01791847\n",
            "  0.00763803  0.01399221  0.00166456 -0.00643159 -0.00518206]\n",
            "1.2409000009998798\n",
            "Error_max =  2.40278619377712e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17425926 -0.0114455  -0.04796817  0.02405857 -0.0074693  -0.01792151\n",
            "  0.00764035  0.0139902   0.00166533 -0.00643061 -0.00518082]\n",
            "1.2410000009998798\n",
            "Error_max =  2.4016089464668643e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1742783  -0.01146474 -0.04795962  0.02406347 -0.00747267 -0.01792455\n",
            "  0.00764266  0.01398819  0.00166609 -0.00642963 -0.00517958]\n",
            "1.2411000009998798\n",
            "Error_max =  2.4004314802864714e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17429734 -0.01148398 -0.04795108  0.02406836 -0.00747604 -0.01792758\n",
            "  0.00764497  0.01398619  0.00166686 -0.00642865 -0.00517834]\n",
            "1.2412000009998798\n",
            "Error_max =  2.3992537957356907e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17431638 -0.01150322 -0.04794252  0.02407326 -0.00747941 -0.01793062\n",
            "  0.00764728  0.01398418  0.00166762 -0.00642766 -0.00517709]\n",
            "1.2413000009998798\n",
            "Error_max =  2.398075893314272e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17433542 -0.01152247 -0.04793397  0.02407815 -0.00748279 -0.01793365\n",
            "  0.0076496   0.01398217  0.00166839 -0.00642668 -0.00517585]\n",
            "1.2414000009998798\n",
            "Error_max =  2.3968977735240815e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17435446 -0.01154172 -0.04792541  0.02408304 -0.00748616 -0.01793668\n",
            "  0.00765191  0.01398016  0.00166916 -0.0064257  -0.0051746 ]\n",
            "1.2415000009998798\n",
            "Error_max =  2.395719436857458e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17437351 -0.01156097 -0.04791686  0.02408793 -0.00748953 -0.01793971\n",
            "  0.00765422  0.01397814  0.00166992 -0.00642471 -0.00517336]\n",
            "1.2416000009998798\n",
            "Error_max =  2.394540883803562e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17439255 -0.01158022 -0.04790829  0.02409282 -0.00749291 -0.01794274\n",
            "  0.00765653  0.01397613  0.00167069 -0.00642373 -0.00517211]\n",
            "1.2417000009998798\n",
            "Error_max =  2.3933621148769673e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1744116  -0.01159947 -0.04789973  0.02409771 -0.00749628 -0.01794577\n",
            "  0.00765884  0.01397412  0.00167146 -0.00642274 -0.00517087]\n",
            "1.2418000009998797\n",
            "Error_max =  2.392183130568952e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17443065 -0.01161873 -0.04789117  0.02410259 -0.00749965 -0.01794879\n",
            "  0.00766115  0.0139721   0.00167222 -0.00642176 -0.00516962]\n",
            "1.2419000009998797\n",
            "Error_max =  2.39100393137609e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1744497  -0.01163799 -0.0478826   0.02410747 -0.00750303 -0.01795182\n",
            "  0.00766347  0.01397008  0.00167299 -0.00642077 -0.00516838]\n",
            "1.2420000009998797\n",
            "Error_max =  2.3898245178044825e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17446875 -0.01165725 -0.04787403  0.02411235 -0.0075064  -0.01795484\n",
            "  0.00766578  0.01396807  0.00167376 -0.00641979 -0.00516713]\n",
            "1.2421000009998797\n",
            "Error_max =  2.388644890330586e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1744878  -0.01167651 -0.04786546  0.02411723 -0.00750978 -0.01795787\n",
            "  0.00766809  0.01396605  0.00167453 -0.0064188  -0.00516588]\n",
            "1.2422000009998797\n",
            "Error_max =  2.3874650494795614e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17450685 -0.01169577 -0.04785688  0.02412211 -0.00751315 -0.01796089\n",
            "  0.0076704   0.01396403  0.0016753  -0.00641782 -0.00516464]\n",
            "1.2423000009998797\n",
            "Error_max =  2.3862849957268053e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17452591 -0.01171504 -0.0478483   0.02412699 -0.00751653 -0.01796391\n",
            "  0.00767271  0.01396201  0.00167607 -0.00641683 -0.00516339]\n",
            "1.2424000009998797\n",
            "Error_max =  2.385104729593243e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17454496 -0.0117343  -0.04783973  0.02413187 -0.0075199  -0.01796693\n",
            "  0.00767502  0.01395998  0.00167684 -0.00641585 -0.00516214]\n",
            "1.2425000009998797\n",
            "Error_max =  2.383924251560625e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17456402 -0.01175357 -0.04783114  0.02413674 -0.00752328 -0.01796994\n",
            "  0.00767733  0.01395796  0.0016776  -0.00641486 -0.00516089]\n",
            "1.2426000009998797\n",
            "Error_max =  2.3827435621318766e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17458308 -0.01177284 -0.04782256  0.02414161 -0.00752666 -0.01797296\n",
            "  0.00767964  0.01395593  0.00167837 -0.00641387 -0.00515965]\n",
            "1.2427000009998797\n",
            "Error_max =  2.381562661807806e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17460214 -0.01179212 -0.04781397  0.02414648 -0.00753003 -0.01797597\n",
            "  0.00768195  0.01395391  0.00167914 -0.00641288 -0.0051584 ]\n",
            "1.2428000009998796\n",
            "Error_max =  2.3803815510754577e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.1746212  -0.01181139 -0.04780538  0.02415135 -0.00753341 -0.01797899\n",
            "  0.00768427  0.01395188  0.00167992 -0.0064119  -0.00515715]\n",
            "1.2429000009998796\n",
            "Error_max =  2.379200230447286e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17464026 -0.01183067 -0.04779679  0.02415622 -0.00753679 -0.017982\n",
            "  0.00768658  0.01394985  0.00168069 -0.00641091 -0.0051559 ]\n",
            "1.2430000009998796\n",
            "Error_max =  2.3780187004092766e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17465933 -0.01184995 -0.0477882   0.02416108 -0.00754016 -0.01798501\n",
            "  0.00768889  0.01394782  0.00168146 -0.00640992 -0.00515465]\n",
            "1.2431000009998796\n",
            "Error_max =  2.376836961474943e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17467839 -0.01186923 -0.0477796   0.02416595 -0.00754354 -0.01798802\n",
            "  0.0076912   0.01394579  0.00168223 -0.00640893 -0.0051534 ]\n",
            "1.2432000009998796\n",
            "Error_max =  2.3756550141270935e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17469746 -0.01188851 -0.04777101  0.02417081 -0.00754692 -0.01799103\n",
            "  0.00769351  0.01394376  0.001683   -0.00640795 -0.00515215]\n",
            "1.2433000009998796\n",
            "Error_max =  2.374472858877125e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17471653 -0.0119078  -0.04776241  0.02417567 -0.0075503  -0.01799403\n",
            "  0.00769582  0.01394173  0.00168377 -0.00640696 -0.00515089]\n",
            "1.2434000009998796\n",
            "Error_max =  2.373290496211022e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17473559 -0.01192708 -0.0477538   0.02418053 -0.00755367 -0.01799704\n",
            "  0.00769813  0.01393969  0.00168454 -0.00640597 -0.00514964]\n",
            "1.2435000009998796\n",
            "Error_max =  2.3721079266306523e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17475466 -0.01194637 -0.0477452   0.02418539 -0.00755705 -0.01800004\n",
            "  0.00770044  0.01393766  0.00168532 -0.00640498 -0.00514839]\n",
            "1.2436000009998796\n",
            "Error_max =  2.3709251506368235e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17477374 -0.01196566 -0.04773659  0.02419025 -0.00756043 -0.01800305\n",
            "  0.00770275  0.01393562  0.00168609 -0.00640399 -0.00514714]\n",
            "1.2437000009998795\n",
            "Error_max =  2.369742168734579e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17479281 -0.01198495 -0.04772798  0.0241951  -0.00756381 -0.01800605\n",
            "  0.00770506  0.01393358  0.00168686 -0.006403   -0.00514588]\n",
            "1.2438000009998795\n",
            "Error_max =  2.3685589814035517e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17481188 -0.01200425 -0.04771937  0.02419995 -0.00756719 -0.01800905\n",
            "  0.00770737  0.01393155  0.00168764 -0.00640201 -0.00514463]\n",
            "1.2439000009998795\n",
            "Error_max =  2.367375589156196e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17483096 -0.01202354 -0.04771075  0.0242048  -0.00757057 -0.01801204\n",
            "  0.00770967  0.01392951  0.00168841 -0.00640102 -0.00514338]\n",
            "1.2440000009998795\n",
            "Error_max =  2.3661919924922617e-10\n",
            "h =  0.0001\n",
            "Steps: 5000000000\n",
            "a = [ 0.17485003 -0.01204284 -0.04770214  0.02420965 -0.00757395 -0.01801504\n",
            "  0.00771198  0.01392746  0.00168918 -0.00640003 -0.00514212]\n"
          ]
        }
      ],
      "source": [
        "# Runge Kutta Fehlberg : adaptative step\n",
        "\n",
        "tf = 5\n",
        "\n",
        "h_max = 0.001\n",
        "h_min = 0.00001\n",
        "tol = 1e-9        # Tolerance\n",
        "h = h_max\n",
        "\n",
        "It = int(tf/h)\n",
        "\n",
        "\n",
        "\n",
        "t = 0\n",
        "\n",
        "\n",
        "#phi_set = np.zeros([It,M])   \n",
        "#chi_set = np.zeros([It,M])\n",
        "#pi_set = np.zeros([It,M])\n",
        "#A = np.zeros([It])  \n",
        "#Alpha_origin = np.zeros([It])\n",
        "#phi_origin = np.zeros([It]) \n",
        "\n",
        "V = 0\n",
        "\n",
        "#print 'Time step:', h\n",
        "#print 'Steps:', It\n",
        "\n",
        "for i in range(It): \n",
        "#while h > h_min:\n",
        "\n",
        "  # First step\n",
        "  Phi = np.dot(a0, psi)      \n",
        "  rPhi = np.dot(a0, rpsi)\n",
        "  rrPhi = np.dot(a0, rrpsi)      \n",
        "  Pi = np.dot(b0, psi) \n",
        "  rPi= np.dot(b0, rpsi)\n",
        "  Chi = np.dot(c0, psi) \n",
        "  rChi = np.dot(c0, rpsi)\n",
        "  rrChi = np.dot(c0, rrpsi)   \n",
        "  Matrix_Krr = 2*rChi*SB1 + rSB1 + 3/r*SB1 \n",
        "  inv_matrix_krr = np.linalg.inv(Matrix_Krr)\n",
        "  rhsk = - Pi*rPhi*np.exp(4*Chi)\n",
        "  ck0 = np.dot(rhsk, inv_matrix_krr)\n",
        "  Krr = np.dot(ck0, SB1) \n",
        "  rKrr = np.dot(ck0, rSB1)\n",
        "  Matrix_Alpha = rrpsi + 2*(1/r + rChi)*rpsi - 3/2*np.exp(-4*Chi)*Krr**2*psi - np.exp(4*Chi)*(Pi**2 - V)*psi \n",
        "  inv_matrix_alpha = np.linalg.inv(Matrix_Alpha)\n",
        "  rhsal = 3/2*np.exp(-4*Chi)*Krr**2 + np.exp(4*Chi)*(Pi**2-V)\n",
        "  al0 = np.dot(rhsal, inv_matrix_alpha)\n",
        "  Alpha = 1 + np.dot(al0, psi)\n",
        "  rAlpha = np.dot(al0, rpsi)\n",
        "  rrAlpha = np.dot(al0, rrpsi)\n",
        "  Matrix_Beta = rSB2/r - SB2/r**2\n",
        "  inv_matrix_beta = np.linalg.inv(Matrix_Beta)\n",
        "  rhsbe = 3/2*Alpha*np.exp(-4*Chi)*Krr/r\n",
        "  be0 = np.dot(rhsbe , inv_matrix_beta)\n",
        "  Beta = np.dot(be0, SB2)\n",
        "  rBeta = np.dot(be0, rSB2)\n",
        "  db = np.dot(Beta*rPi + np.exp(-4*Chi)*(2*Alpha/r + rAlpha + 2*rChi*Alpha)*rPhi + np.exp(-4*Chi)*Alpha*rrPhi - Alpha* V, inv_psi)\n",
        "  dc = np.dot(Beta*rChi + Beta/2/r + Alpha/4*np.exp(-4*Chi)*Krr, inv_psi)   \n",
        "  da = np.dot(Alpha*Pi + Beta*rPhi, inv_psi)   \n",
        "  K1 = h*(dc)\n",
        "  L1 = h*(da)\n",
        "  N1 = h*(db)\n",
        "  \n",
        "  # L2-error associated to the Hamiltonian constraint\n",
        "  qPhi = np.dot(a0, qpsi)      \n",
        "  rqPhi= np.dot(a0, rqpsi)\n",
        "  qPi = np.dot(b0, qpsi) \n",
        "  qChi = np.dot(c0, qpsi)\n",
        "  rqChi = np.dot(c0, rqpsi)\n",
        "  rrqChi = np.dot(c0, rrqpsi) \n",
        "  qKrr = np.dot(ck0, qSB1)\n",
        "  H = 4*rqChi**2 + 4*rrqChi + 8*rqChi/rq + 3/4*np.exp(-4*qChi)*qKrr**2 + np.exp(4*qChi)*(1/2*qPi**2 + np.exp(-4*qChi)/2*rqPhi**2)   # Hamiltonian constraint (HC)\n",
        "  L2HC = (1/2*np.dot(H**2,wq_col))**(1/2)     # L2 error of HC \n",
        "  out_h = open('L2HC_30_L02.txt', 'a')\n",
        "  out_h.write(str(L2HC)+\"\\n\")\n",
        "\n",
        "\n",
        "  # Alpha in r=0\n",
        "#  Alpha_origin[i] = 1 + np.dot(al0, psi_0)\n",
        "\n",
        "  #Phi origin:\n",
        "#  phi_origin[i] = np.dot(a0, psi_0)\n",
        "\n",
        "  # Second step\n",
        "  Phi = np.dot(a0 + L1/4, psi)     \n",
        "  rPhi= np.dot(a0 + L1/4 , rpsi)\n",
        "  rrPhi = np.dot(a0 + L1/4, rrpsi) \n",
        "  Pi = np.dot(b0 + N1/4, psi)\n",
        "  rPi= np.dot(b0 + N1/4, rpsi)\n",
        "  Chi = np.dot(c0 + K1/4, psi)\n",
        "  rChi = np.dot(c0 + K1/4, rpsi)\n",
        "  rrChi = np.dot(c0 + K1/4, rrpsi)\n",
        "  Matrix_Krr = 2*rChi*SB1 + rSB1 + 3/r*SB1 \n",
        "  inv_matrix_krr = np.linalg.inv(Matrix_Krr)\n",
        "  rhsk = - Pi*rPhi*np.exp(4*Chi)\n",
        "  ck0 = np.dot(rhsk, inv_matrix_krr)\n",
        "  Krr = np.dot(ck0, SB1) \n",
        "  rKrr = np.dot(ck0, rSB1)\n",
        "  Matrix_Alpha = rrpsi + 2*(1/r + rChi)*rpsi - 3/2*np.exp(-4*Chi)*Krr**2*psi - np.exp(4*Chi)*(Pi**2 - V)*psi \n",
        "  inv_matrix_alpha = np.linalg.inv(Matrix_Alpha)\n",
        "  rhsal = 3/2*np.exp(-4*Chi)*Krr**2 + np.exp(4*Chi)*(Pi**2-V)\n",
        "  al0 = np.dot(rhsal, inv_matrix_alpha)\n",
        "  Alpha = 1 + np.dot(al0, psi)\n",
        "  rAlpha = np.dot(al0, rpsi)\n",
        "  rrAlpha = np.dot(al0, rrpsi)\n",
        "  Matrix_Beta = rSB2/r - SB2/r**2\n",
        "  inv_matrix_beta = np.linalg.inv(Matrix_Beta)\n",
        "  rhsbe = 3/2*Alpha*np.exp(-4*Chi)*Krr/r\n",
        "  be0 = np.dot(rhsbe , inv_matrix_beta)\n",
        "  Beta = np.dot(be0, SB2)\n",
        "  rBeta = np.dot(be0, rSB2)\n",
        "  db = np.dot(Beta*rPi + np.exp(-4*Chi)*(2*Alpha/r + rAlpha + 2*rChi*Alpha)*rPhi + np.exp(-4*Chi)*Alpha*rrPhi - Alpha* V, inv_psi)   \n",
        "  dc = np.dot(Beta*rChi + Beta/2/r + Alpha/4*np.exp(-4*Chi)*Krr, inv_psi)    \n",
        "  da = np.dot(Alpha*Pi + Beta*rPhi, inv_psi)   \n",
        "  K2 = h*(dc)\n",
        "  L2 = h*(da)\n",
        "  N2 = h*(db)\n",
        "\n",
        "  # Third step\n",
        "  Phi = np.dot(a0 + 3/(32)*L1 + 9/(32)*L2, psi)     \n",
        "  rPhi = np.dot(a0 + 3/(32)*L1 + 9/(32)*L2 , rpsi)\n",
        "  rrPhi = np.dot(a0 + 3/(32)*L1 + 9/(32)*L2, rrpsi) \n",
        "  Pi = np.dot(b0 + 3/(32)*N1 + 9/(32)*N2, psi)\n",
        "  rPi= np.dot(b0 + 3/(32)*N1 + 9/(32)*N2, rpsi)\n",
        "  Chi = np.dot(c0 + 3/(32)*K1 + 9/(32)*K2, psi)\n",
        "  rChi = np.dot(c0 + 3/(32)*K1 + 9/(32)*K2, rpsi)\n",
        "  rrChi = np.dot(c0 +3/(32)*K1 + 9/(32)*K2, rrpsi)\n",
        "  Matrix_Krr = 2*rChi*SB1 + rSB1 + 3/r*SB1\n",
        "  inv_matrix_krr = np.linalg.inv(Matrix_Krr)\n",
        "  rhsk = - Pi*rPhi*np.exp(4*Chi)\n",
        "  ck0 = np.dot(rhsk, inv_matrix_krr)\n",
        "  Krr = np.dot(ck0, SB1) \n",
        "  rKrr = np.dot(ck0, rSB1)\n",
        "  Matrix_Alpha = rrpsi + 2*(1/r + rChi)*rpsi - 3/2*np.exp(-4*Chi)*Krr**2*psi - np.exp(4*Chi)*(Pi**2 - V)*psi \n",
        "  inv_matrix_alpha = np.linalg.inv(Matrix_Alpha)\n",
        "  rhsal = 3/2*np.exp(-4*Chi)*Krr**2 + np.exp(4*Chi)*(Pi**2-V)\n",
        "  al0 = np.dot(rhsal, inv_matrix_alpha)\n",
        "  Alpha = 1 + np.dot(al0, psi)\n",
        "  rAlpha = np.dot(al0, rpsi)\n",
        "  rrAlpha = np.dot(al0, rrpsi)\n",
        "  Matrix_Beta = rSB2/r - SB2/r**2\n",
        "  inv_matrix_beta = np.linalg.inv(Matrix_Beta)\n",
        "  rhsbe = 3/2*Alpha*np.exp(-4*Chi)*Krr/r\n",
        "  be0 = np.dot(rhsbe , inv_matrix_beta)\n",
        "  Beta = np.dot(be0, SB2)\n",
        "  rBeta = np.dot(be0, rSB2)\n",
        "  db = np.dot(Beta*rPi + np.exp(-4*Chi)*(2*Alpha/r + rAlpha + 2*rChi*Alpha)*rPhi + np.exp(-4*Chi)*Alpha*rrPhi - Alpha* V, inv_psi)   \n",
        "  dc = np.dot(Beta*rChi + Beta/2/r + Alpha/4*np.exp(-4*Chi)*Krr, inv_psi)    \n",
        "  da = np.dot(Alpha*Pi + Beta*rPhi, inv_psi)   \n",
        "  K3 = h*(dc)\n",
        "  L3 = h*(da)\n",
        "  N3 = h*(db) \n",
        "\n",
        "  # Forth step\n",
        "  Phi = np.dot(a0 + (1932)/(2197)*L3 - (7200)/(2197)*L2 + (7296)/(2197)*L3, psi)     \n",
        "  rPhi= np.dot(a0 + (1932)/(2197)*L3 - (7200)/(2197)*L2 + (7296)/(2197)*L3 , rpsi)\n",
        "  rrPhi = np.dot(a0 + (1932)/(2197)*L3 - (7200)/(2197)*L2 + (7296)/(2197)*L3, rrpsi) \n",
        "  Pi = np.dot(b0 + (1932)/(2197)*N3 - (7200)/(2197)*N2 + (7296)/(2197)*N3, psi)\n",
        "  rPi= np.dot(b0 + (1932)/(2197)*N3 - (7200)/(2197)*N2 + (7296)/(2197)*N3, rpsi)\n",
        "  Chi = np.dot(c0 + (1932)/(2197)*K3 - (7200)/(2197)*K2 + (7296)/(2197)*K3, psi)\n",
        "  rChi = np.dot(c0 + (1932)/(2197)*K3 - (7200)/(2197)*K2 + (7296)/(2197)*K3, rpsi)\n",
        "  rrChi = np.dot(c0 + (1932)/(2197)*K3 - (7200)/(2197)*K2 + (7296)/(2197)*K3, rrpsi)\n",
        "  Matrix_Krr = 2*rChi*SB1 + rSB1 + 3/r*SB1 \n",
        "  inv_matrix_krr = np.linalg.inv(Matrix_Krr)\n",
        "  rhsk = - Pi*rPhi*np.exp(4*Chi)\n",
        "  ck0 = np.dot(rhsk, inv_matrix_krr)\n",
        "  Krr = np.dot(ck0, SB1) \n",
        "  rKrr = np.dot(ck0, rSB1)\n",
        "  Matrix_Alpha = rrpsi + 2*(1/r + rChi)*rpsi - 3/2*np.exp(-4*Chi)*Krr**2*psi - np.exp(4*Chi)*(Pi**2 - V)*psi \n",
        "  inv_matrix_alpha = np.linalg.inv(Matrix_Alpha)\n",
        "  rhsal = 3/2*np.exp(-4*Chi)*Krr**2 + np.exp(4*Chi)*(Pi**2-V)\n",
        "  al0 = np.dot(rhsal, inv_matrix_alpha)\n",
        "  Alpha = 1 + np.dot(al0, psi)\n",
        "  rAlpha = np.dot(al0, rpsi)\n",
        "  rrAlpha = np.dot(al0, rrpsi)\n",
        "  Matrix_Beta = rSB2/r - SB2/r**2\n",
        "  inv_matrix_beta = np.linalg.inv(Matrix_Beta)\n",
        "  rhsbe = 3/2*Alpha*np.exp(-4*Chi)*Krr/r\n",
        "  be0 = np.dot(rhsbe , inv_matrix_beta)\n",
        "  Beta = np.dot(be0, SB2)\n",
        "  rBeta = np.dot(be0, rSB2)\n",
        "  db = np.dot(Beta*rPi + np.exp(-4*Chi)*(2*Alpha/r + rAlpha + 2*rChi*Alpha)*rPhi + np.exp(-4*Chi)*Alpha*rrPhi - Alpha* V, inv_psi)   \n",
        "  dc = np.dot(Beta*rChi + Beta/2/r + Alpha/4*np.exp(-4*Chi)*Krr, inv_psi)    \n",
        "  da = np.dot(Alpha*Pi + Beta*rPhi, inv_psi)   \n",
        "  K4 = h*(dc)\n",
        "  L4 = h*(da)\n",
        "  N4 = h*(db)  \n",
        "  \n",
        "  # Fifth step\n",
        "  Phi = np.dot(a0 + (439)/(216)*L1 - 8*L2 + (3680)/(513)*L3 - (845)/(4104)*L4, psi)     \n",
        "  rPhi= np.dot(a0 + (439)/(216)*L1 - 8*L2 + (3680)/(513)*L3 - (845)/(4104)*L4 , rpsi)\n",
        "  rrPhi = np.dot(a0 + (439)/(216)*L1 - 8*L2 + (3680)/(513)*L3 - (845)/(4104)*L4, rrpsi) \n",
        "  Pi = np.dot(b0 + (439)/(216)*N1 - 8*N2 + (3680)/(513)*N3 - (845)/(4104)*N4, psi)\n",
        "  rPi= np.dot(b0 + (439)/(216)*N1 - 8*N2 + (3680)/(513)*N3 - (845)/(4104)*N4, rpsi)\n",
        "  Chi = np.dot(c0 + (439)/(216)*K1 - 8*K2 + (3680)/(513)*K3 - (845)/(4104)*K4, psi)\n",
        "  rChi = np.dot(c0 + (439)/(216)*K1 - 8*K2 + (3680)/(513)*K3 - (845)/(4104)*K4, rpsi)\n",
        "  rrChi = np.dot(c0 + (439)/(216)*K1 - 8*K2 + (3680)/(513)*K3 - (845)/(4104)*K4, rrpsi)\n",
        "  Matrix_Krr = 2*rChi*SB1 + rSB1 + 3/r*SB1 \n",
        "  inv_matrix_krr = np.linalg.inv(Matrix_Krr)\n",
        "  rhsk = - Pi*rPhi*np.exp(4*Chi)\n",
        "  ck0 = np.dot(rhsk, inv_matrix_krr)\n",
        "  Krr = np.dot(ck0, SB1) \n",
        "  rKrr = np.dot(ck0, rSB1)\n",
        "  Matrix_Alpha = rrpsi + 2*(1/r + rChi)*rpsi - 3/2*np.exp(-4*Chi)*Krr**2*psi - np.exp(4*Chi)*(Pi**2 - V)*psi \n",
        "  inv_matrix_alpha = np.linalg.inv(Matrix_Alpha)\n",
        "  rhsal = 3/2*np.exp(-4*Chi)*Krr**2 + np.exp(4*Chi)*(Pi**2-V)\n",
        "  al0 = np.dot(rhsal, inv_matrix_alpha)\n",
        "  Alpha = 1 + np.dot(al0, psi)\n",
        "  rAlpha = np.dot(al0, rpsi)\n",
        "  rrAlpha = np.dot(al0, rrpsi)\n",
        "  Matrix_Beta = rSB2/r - SB2/r**2\n",
        "  inv_matrix_beta = np.linalg.inv(Matrix_Beta)\n",
        "  rhsbe = 3/2*Alpha*np.exp(-4*Chi)*Krr/r\n",
        "  be0 = np.dot(rhsbe , inv_matrix_beta)\n",
        "  Beta = np.dot(be0, SB2)\n",
        "  rBeta = np.dot(be0, rSB2)\n",
        "  db = np.dot(Beta*rPi + np.exp(-4*Chi)*(2*Alpha/r + rAlpha + 2*rChi*Alpha)*rPhi + np.exp(-4*Chi)*Alpha*rrPhi - Alpha* V, inv_psi)   \n",
        "  dc = np.dot(Beta*rChi + Beta/2/r + Alpha/4*np.exp(-4*Chi)*Krr, inv_psi)    \n",
        "  da = np.dot(Alpha*Pi + Beta*rPhi, inv_psi)   \n",
        "  K5 = h*(dc)\n",
        "  L5 = h*(da)\n",
        "  N5 = h*(db)  \n",
        "\n",
        "  # Sixth step\n",
        "  Phi = np.dot(a0 - (8)/(27)*L1 - 2*L2 - (3544)/(2565)*L3 + (1859)/(4104)*L4 - (11)/(40)*L5, psi)     \n",
        "  rPhi= np.dot(a0 + (8)/(27)*L1 - 2*L2 - (3544)/(2565)*L3 + (1859)/(4104)*L4 - (11)/(40)*L5 , rpsi)\n",
        "  rrPhi = np.dot(a0 + (8)/(27)*L1 - 2*L2 - (3544)/(2565)*L3 + (1859)/(4104)*L4 - (11)/(40)*L5, rrpsi) \n",
        "  Pi = np.dot(b0 + (8)/(27)*N1 - 2*N2 - (3544)/(2565)*N3 + (1859)/(4104)*N4 - (11)/(40)*N5, psi)\n",
        "  rPi= np.dot(b0 + (8)/(27)*N1 - 2*N2 - (3544)/(2565)*N3 + (1859)/(4104)*N4 - (11)/(40)*N5, rpsi)\n",
        "  Chi = np.dot(c0 + (8)/(27)*K1 - 2*K2 - (3544)/(2565)*K3 + (1859)/(4104)*K4 - (11)/(40)*K5, psi)\n",
        "  rChi = np.dot(c0 + (8)/(27)*K1 - 2*K2 - (3544)/(2565)*K3 + (1859)/(4104)*K4 - (11)/(40)*K5, rpsi)\n",
        "  rrChi = np.dot(c0 + (8)/(27)*K1 - 2*K2 - (3544)/(2565)*K3 + (1859)/(4104)*K4 - (11)/(40)*K5, rrpsi)\n",
        "  Matrix_Krr = 2*rChi*SB1 + rSB1 + 3/r*SB1 \n",
        "  inv_matrix_krr = np.linalg.inv(Matrix_Krr)\n",
        "  rhsk = - Pi*rPhi*np.exp(4*Chi)\n",
        "  ck0 = np.dot(rhsk, inv_matrix_krr)\n",
        "  Krr = np.dot(ck0, SB1) \n",
        "  rKrr = np.dot(ck0, rSB1)\n",
        "  Matrix_Alpha = rrpsi + 2*(1/r + rChi)*rpsi - 3/2*np.exp(-4*Chi)*Krr**2*psi - np.exp(4*Chi)*(Pi**2 - V)*psi \n",
        "  inv_matrix_alpha = np.linalg.inv(Matrix_Alpha)\n",
        "  rhsal = 3/2*np.exp(-4*Chi)*Krr**2 + np.exp(4*Chi)*(Pi**2-V)\n",
        "  al0 = np.dot(rhsal, inv_matrix_alpha)\n",
        "  Alpha = 1 + np.dot(al0, psi)\n",
        "  rAlpha = np.dot(al0, rpsi)\n",
        "  rrAlpha = np.dot(al0, rrpsi)\n",
        "  Matrix_Beta = rSB2/r - SB2/r**2\n",
        "  inv_matrix_beta = np.linalg.inv(Matrix_Beta)\n",
        "  rhsbe = 3/2*Alpha*np.exp(-4*Chi)*Krr/r\n",
        "  be0 = np.dot(rhsbe , inv_matrix_beta)\n",
        "  Beta = np.dot(be0, SB2)\n",
        "  rBeta = np.dot(be0, rSB2)\n",
        "  db = np.dot(Beta*rPi + np.exp(-4*Chi)*(2*Alpha/r + rAlpha + 2*rChi*Alpha)*rPhi + np.exp(-4*Chi)*Alpha*rrPhi - Alpha* V, inv_psi)   \n",
        "  dc = np.dot(Beta*rChi + Beta/2/r + Alpha/4*np.exp(-4*Chi)*Krr, inv_psi)    \n",
        "  da = np.dot(Alpha*Pi + Beta*rPhi, inv_psi)   \n",
        "  K6 = h*(dc)\n",
        "  L6 = h*(da)\n",
        "  N6 = h*(db) \n",
        "\n",
        " # print(i)\n",
        "\n",
        "#  Error_R_1 = []\n",
        "#  for n in range(len(a0)):\n",
        "#    Error_R_1.append((1/360)*L1[n]-(128/4275)*L3[n]-(2197/75240)*L4[n]+(1/50)*L5[n]+(2/55)*L6[n])\n",
        "#  Error_R = max(Error_R_1)\n",
        "    \n",
        "  Error_R_1 = (1/360)*L1 - (128/4275)*L3 - (2197/75240)*L4 + (1/50)*L5 + (2/55)*L6\n",
        "  Error_R = max(Error_R_1)\n",
        "  out_erro = open('Error_RKF.txt', 'a')\n",
        "  out_erro.write(str(Error_R)+\"\\n\")\n",
        "\n",
        "  print(t)\n",
        "  print('Error max = ',Error_R)\n",
        "  print('h = ', h)\n",
        "\n",
        "  print('Steps:', It)\n",
        "\n",
        "  if Error_R <= tol or h == h_min:\n",
        "#    a = []\n",
        "#    b = []\n",
        "#    c = []\n",
        "#    for j in range(len(a0)):\n",
        "#     a.append(a0[j] + (16)/(135)*L1[j] + (6656)/(12825)*L3[j] + (28561)/(56430)*L4[j] - 9/(50)*L5[j] + 2/(55)*L6[j])\n",
        "#   for j in range(len(b0)):\n",
        "#     b.append(b0[j] + (16)/(135)*N1[j] + (6656)/(12825)*N3[j] + (28561)/(56430)*N4[j] - 9/(50)*N5[j] + 2/(55)*N6[j])\n",
        "#    for j in range(len(c0)):\n",
        "#     c.append(c0[j] + (16)/(135)*K1[j] + (6656)/(12825)*K3[j] + (28561)/(56430)*K4[j] - 9/(50)*K5[j] + 2/(55)*K6[j])\n",
        "    a0 = a0 + (16)/(135)*L1 + (6656)/(12825)*L3 + (28561)/(56430)*L4 - 9/(50)*L5 + 2/(55)*L6                                 # mudança\n",
        "    b0 = b0 + (16)/(135)*N1 + (6656)/(12825)*N3 + (28561)/(56430)*N4 - 9/(50)*N5 + 2/(55)*N6\n",
        "    c0 = c0 + (16)/(135)*K1 + (6656)/(12825)*K3 + (28561)/(56430)*K4 - 9/(50)*K5 + 2/(55)*K6\n",
        "    t = t + h\n",
        "    print('a =', a0)\n",
        "#    a0 = a\n",
        "#    b0 = b\n",
        "#    c0 = c\n",
        "    out_a = open('a_30_L02.txt', 'a')\n",
        "    out_a.write(' ' +' '.join(str('%.18f'%n) for n in a0)+'\\n')\n",
        "    out_b = open('b_30_L02.txt', 'a')\n",
        "    out_b.write(' ' +' '.join(str('%.18f'%n) for n in b0)+'\\n')\n",
        "    out_c = open('c_30_L02.txt', 'a')\n",
        "    out_c.write(' ' +' '.join(str('%.18f'%n) for n in c0)+'\\n')\n",
        " #     out_H.write(t4 +' ' +' '.join(str('%.18f'%n) for n in H)+'\\n')\n",
        "    h = h_max\n",
        "  \n",
        "\n",
        "  else:\n",
        "    h = h*0.01*(tol/(Error_R))**(1/4)\n",
        "    if h >= h_max:\n",
        "      h = h_max\n",
        "    if h < h_min: \n",
        "#      h = h_min                     # mudança\n",
        "      break\n",
        "\n",
        "  \n",
        "out_a.close()\n",
        "a = np.loadtxt(\"a_30_L02.txt\", dtype = \"float\")\n",
        "\n",
        "\n",
        "  # Evolution functions  \n",
        "  # phi_set[i,:] = np.dot(a, psiplot)\n",
        "  # pi_set[i,:] = np.dot(b, psiplot)\n",
        "  # chi_set[i,:] = np.dot(c, psiplot)\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jceVGyZxN6Ox",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "np.shape(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXuk1rHsERqk"
      },
      "outputs": [],
      "source": [
        "for i in range(It):\n",
        "  plt.plot(rplot, phi_set[i,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKVocj2YERql"
      },
      "outputs": [],
      "source": [
        "np.shape(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4yuBNl-ERqm"
      },
      "outputs": [],
      "source": [
        "for i in range(It):\n",
        "    phi_set.append(np.dot(a[i,:], psiplot))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjR-BUFmjyqK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Animation plot for Phi: Scalar Field\n",
        "\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(xlim=(0, 10),ylim = (-0.5, 1.3))\n",
        "line, = ax.plot([], [], lw=2)\n",
        "\n",
        "x = rplot\n",
        "\n",
        "def init():\n",
        "    line.set_data([], [])\n",
        "    return line,\n",
        "\n",
        "def animate(i):\n",
        "  y = phi_set[i,:]\n",
        "  line.set_data(x, y)\n",
        "  return line,\n",
        "\n",
        "anim = FuncAnimation(fig, animate, init_func=init,\n",
        "                               frames=It, interval=0.8, blit=True)\n",
        "\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OBiYkaKccJW"
      },
      "outputs": [],
      "source": [
        "# Erro L2 of Hamiltonian constraint\n",
        "\n",
        "plt.plot(t,L2HC)\n",
        "plt.yscale(\"log\")\n",
        "plt.ylabel(\"log(Error RMS)\")\n",
        "plt.xlabel(\"t\")\n",
        "plt.title(\"log(L2Hc) para $N = 30$, $L_0 = 6$ e $A_0 = 0.05$\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bK6jqV8WERqn"
      },
      "outputs": [],
      "source": [
        "# Plot 3D from Phi initial:\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(18,6))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122,projection='3d')\n",
        "\n",
        "y = phi_set[0,:]\n",
        "x = rplot\n",
        "theta = np.linspace(0, 2*np.pi, M)    # Revolution of f(phi,r)\n",
        "\n",
        "xn = np.outer(x, np.cos(theta))\n",
        "yn = np.outer(x, np.sin(theta))\n",
        "zn = np.zeros_like(xn)\n",
        "\n",
        "for i in range(len(x)):\n",
        "    zn[i,:] = np.full_like(zn[i,:], y[i])\n",
        "\n",
        "ax1.plot(x, y)\n",
        "ax2.plot_surface(xn, yn, zn,cmap='viridis')\n",
        "ax2.set_xlim(-9,9)\n",
        "ax2.set_ylim(-9,9)\n",
        "ax2.set_zlim(0,0.5)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}